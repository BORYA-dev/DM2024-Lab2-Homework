{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2IEN4R5eIpV"
      },
      "source": [
        "### Student Information\n",
        "Name:  李博業\n",
        "\n",
        "Student ID: 410978058\n",
        "\n",
        "GitHub ID: BORYA-dev\n",
        "\n",
        "Kaggle name:\n",
        "\n",
        "Kaggle private scoreboard snapshot:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axp8m_GOeIpY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPFyVCS4eIpZ"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvvJToPSeIpZ"
      },
      "source": [
        "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook.\n",
        "\n",
        "\n",
        "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking:\n",
        "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
        "\n",
        "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
        "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
        "    \n",
        "\n",
        "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained.\n",
        "\n",
        "\n",
        "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
        "\n",
        "\n",
        "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
        "\n",
        "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- emotion\n",
        "  - The emotion(answer) of data\n",
        "    - sadness\n",
        "    - disgust\n",
        "    - anticipation\n",
        "    - joy\n",
        "    - trust\n",
        "    - anger\n",
        "    - fear\n",
        "    - surprise\n",
        "\n",
        "- data_identification :\n",
        "  - identify the id is train or test\n",
        "  \n",
        "- tweets_DM.json : Main Data\n",
        "  - type : list\n",
        "  - length = 1867535\n",
        "  - record :\n",
        "    {\n",
        "    '_score': 391,\n",
        "    '_index': 'hashtag_tweets',\n",
        "    '_source': {'tweet': {'hashtags': ['Snapchat'],\n",
        "      'tweet_id': '0x376b20',\n",
        "      'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}},\n",
        "    '_crawldate': '2015-05-23 11:42:47',\n",
        "    '_type': 'tweets'\n",
        "    }"
      ],
      "metadata": {
        "id": "cpnJO_hwi94i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "import stringprep\n",
        "nltk.download('punkt_tab')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# NN\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import ReLU, Softmax\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "## BERT Embedding + Fine Tuning\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjzwLlJkcxuz",
        "outputId": "99339498-6456-488e-b309-00389dbe916a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "bXFjgQW9emYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare Data"
      ],
      "metadata": {
        "id": "-yEXg33dfgcK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK2s-26ceIpa"
      },
      "outputs": [],
      "source": [
        "### Begin Assignment Here\n",
        "\n",
        "### 準備資料\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Data_Lab2_HW/tweets_DM.json'\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line_number, line in enumerate(file, start=1):\n",
        "        try:\n",
        "            data.append(json.loads(line))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error in line {line_number}: {e}\")\n",
        "\n",
        "\n",
        "emotion_data = pd.read_csv('/content/drive/MyDrive/Data_Lab2_HW/emotion.csv')\n",
        "data_id = pd.read_csv('/content/drive/MyDrive/Data_Lab2_HW/data_identification.csv')\n",
        "\n",
        "# 生成DataFrame\n",
        "\n",
        "temp = []\n",
        "for sub_d in data:\n",
        "  temp.append(sub_d['_source']['tweet'])\n",
        "data_df = pd.DataFrame(temp)\n",
        "\n",
        "\n",
        "data_df = data_df.merge(data_id, on = \"tweet_id\", how=\"left\")\n",
        "data_df = data_df.merge(emotion_data, on = \"tweet_id\", how = \"left\")\n",
        "\n",
        "data_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練集、測試集\n",
        "training_data = data_df.query(\"identification == 'train'\").reset_index(drop =True)\n",
        "testing_data = data_df.query(\"identification == 'test'\").reset_index(drop =True)"
      ],
      "metadata": {
        "id": "QTorysaJdxLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sample"
      ],
      "metadata": {
        "id": "3H3jink7NJ7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 抽等量\n",
        "\n",
        "#  min_class_num = training_data.emotion.value_counts().min()\n",
        "\n",
        "# 訓練集抽樣\n",
        "# sampled_training = training_data.groupby('emotion').apply(lambda x: x.sample(n=min_class_num, random_state = 42) )\n",
        "# sampled_training = sampled_training.reset_index(drop=True)\n",
        "# x_train = sampled_training.drop(columns = \"emotion\")\n",
        "# y_train = sampled_training.emotion\n",
        "\n",
        "\n",
        "# # 分層抽樣\n",
        "# # Strafied sampling\n",
        "# x_train, x_test, y_train, y_test = train_test_split(\n",
        "#     x_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "# )\n",
        "\n",
        "# x_train.reset_index(drop=True, inplace = True)\n",
        "# y_train.reset_index(drop=True, inplace = True)\n",
        "# x_test.reset_index(drop=True, inplace=True)\n",
        "# y_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "NFVoSBTnNaLQ",
        "outputId": "ffd495ce-688c-42b1-f94a-44e9f93df3f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-304cfdb7fe4c>:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampled_training = training_data.groupby('emotion').apply(lambda x: x.sample(n=min_class_num, random_state = 42) )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 先掠過\n",
        "\n",
        "train_data_sample = training_data.sample(frac=0.25, random_state=20)\n",
        "train_data_sample = train_data_sample.reset_index(drop=True)\n",
        "\n",
        "x_train = train_data_sample.drop(columns = [\"emotion\", \"identification\"])\n",
        "y_train = train_data_sample.emotion\n",
        "\n",
        "# 分層抽樣\n",
        "# Strafied sampling\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=20, stratify=y_train\n",
        ")\n",
        "\n",
        "x_train.reset_index(drop=True, inplace = True)\n",
        "y_train.reset_index(drop=True, inplace = True)\n",
        "x_test.reset_index(drop=True, inplace = True)\n",
        "y_test.reset_index(drop=True, inplace = True)"
      ],
      "metadata": {
        "id": "WqXpPHlTfpGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pre-processing"
      ],
      "metadata": {
        "id": "4ZjClEiAeKug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dict = {\n",
        "    '😂': '[joy]',\n",
        "    '❤️': '[love]',\n",
        "    '😍': '[adoration]',\n",
        "    '😭': '[cry]',\n",
        "    '❤': '[care]',\n",
        "    '😊': '[happy]',\n",
        "    '🙏': '[pray]',\n",
        "    '😘': '[kiss]',\n",
        "    '💕': '[love_each_other]',\n",
        "    '🔥': '[fire]',\n",
        "    '😩': '[weary]',\n",
        "    '🤔': '[think]',\n",
        "    '💯': '[perfect]',\n",
        "    '💙': '[loyalty]',\n",
        "    '🙄': '[annoyed]',\n",
        "    '😁': '[happy]',\n",
        "    '🙌': '[celebrate]',\n",
        "    '🙏🏾': '[pray]',\n",
        "    '👍': '[approve]',\n",
        "    '🙏🏽': '[pray]',\n",
        "    '♡':'[love]',\n",
        "    '🕘':'[time]',\n",
        "    '🙋':'[hi]',\n",
        "    '😃': '[smile]'\n",
        "}"
      ],
      "metadata": {
        "id": "k9hbD6OueJuh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emoji\n",
        "def trans_emoji(text):\n",
        "  for key, value in emoji_dict.items():\n",
        "    text = text.replace(key, value)\n",
        "  return text\n",
        "\n",
        "def cleaning(text):\n",
        "\n",
        "    text = text.replace(\"<lh>\", \"\")\n",
        "    text = text.replace(\"<LH>\", \"\")\n",
        "\n",
        "    text = trans_emoji(text)\n",
        "\n",
        "    text = re.sub(r'[@#$%^&*()_+{}[\\]:;\"\\'<>,.~\\\\/\\-|=]', '', text)\n",
        "\n",
        "    # remove some common words\n",
        "    text = re.sub(r'\\b(?:and|is|in|the|on|of|to|for)\\b', '', text, flags=re.IGNORECASE)\n",
        "    # remove numbers\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
        "    # remove blank space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # \\s+ 一個或多個空白字符\n",
        "    # remove links\n",
        "    text = re.sub('((www.[^s]+)|(https?://[^s]+))',' ',text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# Stemming\n",
        "# st = nltk.PorterStemmer()\n",
        "\n",
        "# def stemming_on_text(data):\n",
        "#     '''\n",
        "#     input should be tokenized words : list\n",
        "#     '''\n",
        "#     text = [st.stem(word) for word in data]\n",
        "#     return text\n",
        "\n",
        "# # Lemmatization\n",
        "# lm = nltk.WordNetLemmatizer()\n",
        "# def lemmatizer_on_text(data):\n",
        "#     text = [lm.lemmatize(word) for word in data]\n",
        "#     return text\n",
        "\n",
        "\n",
        "def pre_processing(data):\n",
        "\n",
        "  '''\n",
        "  data:DataFrame with text\n",
        "  '''\n",
        "\n",
        "  dataset = data['text']\n",
        "\n",
        "\n",
        "  # 轉小寫\n",
        "  dataset = dataset.apply(lambda text: text.lower().strip())\n",
        "\n",
        "  # 移除 removing\n",
        "\n",
        "  # original tokens\n",
        "  only_tokens = dataset.apply(lambda x: nltk.word_tokenize(x) )\n",
        "  only_tokens.name = \"tokens\"\n",
        "\n",
        "  # cleaning\n",
        "  dataset = dataset.apply(lambda x: cleaning(x) )\n",
        "  dataset.name = \"pre_processing_text\"\n",
        "\n",
        "  # cleaning + tokens\n",
        "  tt = dataset.apply(lambda x: nltk.word_tokenize(x))\n",
        "  tt.name = \"pre_processing_tokens\"\n",
        "\n",
        "\n",
        "  pre_df = pd.concat([pd.DataFrame(only_tokens), pd.DataFrame(dataset),pd.DataFrame(tt)], axis=1)\n",
        "\n",
        "  return pre_df"
      ],
      "metadata": {
        "id": "I2-PzQJkheau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine tje columns with pro-processing & original text\n",
        "\n",
        "x_train = pd.concat([x_train, pre_processing(x_train)], axis=1)\n",
        "x_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "x_test = pd.concat([x_test, pre_processing(x_test)], axis=1)\n",
        "x_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "testing_data = pd.concat([testing_data, pre_processing(testing_data)], axis=1)\n",
        "testing_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "yi7qO8rChan2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head(5)"
      ],
      "metadata": {
        "id": "AKf7eT5bkIt4",
        "outputId": "efaa8a78-e192-403a-f759-a2cf65c9c96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           hashtags  tweet_id  \\\n",
              "0                             [God]  0x231c61   \n",
              "1               [everyday, special]  0x330e2f   \n",
              "2                                []  0x30eca8   \n",
              "3  [payforplay, thatmeansyou, scum]  0x20e851   \n",
              "4                                []  0x254bff   \n",
              "\n",
              "                                                text  \\\n",
              "0  Not the ones that want commitment... patiently...   \n",
              "1  31 Push the <LH> #everyday. Be some #special. ...   \n",
              "2  @AADaddario @lotstar @michaellonghair loved to...   \n",
              "3  I AM IN <LH> THAT MEANS Y O U P A Y M E FOR AN...   \n",
              "4  Father God you are faithful. Be Lord of my lif...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [not, the, ones, that, want, commitment, ..., ...   \n",
              "1  [31, push, the, <, lh, >, #, everyday, ., be, ...   \n",
              "2  [@, aadaddario, @, lotstar, @, michaellonghair...   \n",
              "3  [i, am, in, <, lh, >, that, means, y, o, u, p,...   \n",
              "4  [father, god, you, are, faithful, ., be, lord,...   \n",
              "\n",
              "                                 pre_processing_text  \\\n",
              "0  not ones that want commitment patiently waitin...   \n",
              "1     push everyday be some special august at 0515pm   \n",
              "2  aadaddario lotstar michaellonghair loved watch...   \n",
              "3  i am that means y o u p a y m e any servise i ...   \n",
              "4  father god you are faithful be lord my life today   \n",
              "\n",
              "                               pre_processing_tokens  \n",
              "0  [not, ones, that, want, commitment, patiently,...  \n",
              "1  [push, everyday, be, some, special, august, at...  \n",
              "2  [aadaddario, lotstar, michaellonghair, loved, ...  \n",
              "3  [i, am, that, means, y, o, u, p, a, y, m, e, a...  \n",
              "4  [father, god, you, are, faithful, be, lord, my...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4e47c9a-aa3a-4436-ba98-80dd82c4caf5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hashtags</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>pre_processing_text</th>\n",
              "      <th>pre_processing_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[God]</td>\n",
              "      <td>0x231c61</td>\n",
              "      <td>Not the ones that want commitment... patiently...</td>\n",
              "      <td>[not, the, ones, that, want, commitment, ..., ...</td>\n",
              "      <td>not ones that want commitment patiently waitin...</td>\n",
              "      <td>[not, ones, that, want, commitment, patiently,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[everyday, special]</td>\n",
              "      <td>0x330e2f</td>\n",
              "      <td>31 Push the &lt;LH&gt; #everyday. Be some #special. ...</td>\n",
              "      <td>[31, push, the, &lt;, lh, &gt;, #, everyday, ., be, ...</td>\n",
              "      <td>push everyday be some special august at 0515pm</td>\n",
              "      <td>[push, everyday, be, some, special, august, at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[]</td>\n",
              "      <td>0x30eca8</td>\n",
              "      <td>@AADaddario @lotstar @michaellonghair loved to...</td>\n",
              "      <td>[@, aadaddario, @, lotstar, @, michaellonghair...</td>\n",
              "      <td>aadaddario lotstar michaellonghair loved watch...</td>\n",
              "      <td>[aadaddario, lotstar, michaellonghair, loved, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[payforplay, thatmeansyou, scum]</td>\n",
              "      <td>0x20e851</td>\n",
              "      <td>I AM IN &lt;LH&gt; THAT MEANS Y O U P A Y M E FOR AN...</td>\n",
              "      <td>[i, am, in, &lt;, lh, &gt;, that, means, y, o, u, p,...</td>\n",
              "      <td>i am that means y o u p a y m e any servise i ...</td>\n",
              "      <td>[i, am, that, means, y, o, u, p, a, y, m, e, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[]</td>\n",
              "      <td>0x254bff</td>\n",
              "      <td>Father God you are faithful. Be Lord of my lif...</td>\n",
              "      <td>[father, god, you, are, faithful, ., be, lord,...</td>\n",
              "      <td>father god you are faithful be lord my life today</td>\n",
              "      <td>[father, god, you, are, faithful, be, lord, my...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4e47c9a-aa3a-4436-ba98-80dd82c4caf5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4e47c9a-aa3a-4436-ba98-80dd82c4caf5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4e47c9a-aa3a-4436-ba98-80dd82c4caf5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ed5d450-9d8d-401d-b186-be60a19002a6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ed5d450-9d8d-401d-b186-be60a19002a6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ed5d450-9d8d-401d-b186-be60a19002a6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_train"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TFIDF + Random Forest"
      ],
      "metadata": {
        "id": "xkeXJkOGhmsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tweet_tokenizer = nltk.tokenize.TweetTokenizer() # 本來有用 max_df=0.9, tokenizer = tweet_tokenizer.tokenize\n",
        "TF_IDF_vectorizer = TfidfVectorizer(max_features=1000) # 3000 2500 2000 都會爆\n",
        "output_vectorizer = TF_IDF_vectorizer.fit_transform(x_train.text.values)  # fit + transform"
      ],
      "metadata": {
        "id": "dfxtlnS5KBrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_vectorizer_test = TF_IDF_vectorizer.transform(x_test.text.values)  # only transform"
      ],
      "metadata": {
        "id": "DsfWcyxLoJAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_vectorizer_true_test = TF_IDF_vectorizer.transform(testing_data.text.values)  # only transform"
      ],
      "metadata": {
        "id": "rFawxeGZnOs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 寫出\n",
        "\n",
        "#訓練+測試\n",
        "with open('/content/drive/MyDrive/Data_Lab2_HW/tf-idf-trained.pkl', 'wb') as file:  # 'wb' 表示以二進位寫入模式\n",
        "    pickle.dump([TF_IDF_vectorizer, output_vectorizer, y_train, output_vectorizer_test, y_test], file)\n",
        "\n",
        "# 真正測試資料\n",
        "with open('/content/drive/MyDrive/Data_Lab2_HW/testing_data.pkl', 'wb') as file:  # 'wb' 表示以二進位寫入模式\n",
        "    pickle.dump([testing_data, output_vectorizer_true_test], file)\n"
      ],
      "metadata": {
        "id": "ZvIwAKl-nkeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#讀入\n",
        "\n",
        "with open('/content/drive/MyDrive/Data_Lab2_HW/tf-idf-trained.pkl', 'rb') as file:  # 'rb' 表示以二進位讀取模式\n",
        "    tfidf_list = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/Data_Lab2_HW/testing_data.pkl', 'rb') as file:  # 'rb' 表示以二進位讀取模式\n",
        "    testing_list = pickle.load(file)"
      ],
      "metadata": {
        "id": "SUp1uHJvViq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf_list[1]\n",
        "y_train = tfidf_list[2].values"
      ],
      "metadata": {
        "id": "RxXT-MxQou83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "## training!\n",
        "DT_model = model.fit(output_vectorizer, y_train)\n",
        "\n",
        "## predict! training"
      ],
      "metadata": {
        "id": "gNGYxGzKLtw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load"
      ],
      "metadata": {
        "id": "1lOFT0__OWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 寫出模型\n",
        "dump(DT_model, '/content/drive/MyDrive/Data_Lab2_HW/random_forest_3000.joblib')  # 儲存模型"
      ],
      "metadata": {
        "id": "N2fVs0lILHxJ",
        "outputId": "09d503d5-12f3-4800-846b-1fd6451640bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Data_Lab2_HW/random_forest_3000.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 讀入模型\n",
        "DT_model = load('/content/drive/MyDrive/Data_Lab2_HW/random_forest.joblib')"
      ],
      "metadata": {
        "id": "aXN6OIqqO9FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOavcjbZnds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training Accuracy\n",
        "\n",
        "y_train_pred = DT_model.predict(output_vectorizer)\n",
        "\n",
        "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
        "\n",
        "print('training accuracy: {}'.format(round(acc_train, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7iDCh66MXKD",
        "outputId": "3613560e-0c2e-46df-8cd8-5665e9057cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf_list[3]"
      ],
      "metadata": {
        "id": "CnaYfdzO7MAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini-Testing\n",
        "# output_vectorizer_testing = TF_IDF_vectorizer.fit_transform(mini_X_test['preprocess_text'])\n",
        "\n",
        "# Predict Mini-Testing (by Random Forest)\n",
        "y_test_result = DT_model.predict( output_vectorizer_test )\n",
        "\n",
        "acc_train = accuracy_score(y_true= y_test, y_pred= y_test_result)\n",
        "\n",
        "print('Mini-testing accuracy: {}'.format(round(acc_train, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocdsU-ioMpH8",
        "outputId": "a6664a22-c8ba-456c-ee1c-c51c19f89415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-testing accuracy: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DT_model = load('/content/drive/MyDrive/Data_Lab2_HW/random_forest.joblib')"
      ],
      "metadata": {
        "id": "6zffER9I9isn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_result = DT_model.predict( output_vectorizer_true_test )"
      ],
      "metadata": {
        "id": "YQXq9RZiHB9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 寫出結果\n",
        "result = pd.DataFrame( {\n",
        "   \"id\" : testing_data.tweet_id,\n",
        "   \"emotion\" : y_test_result\n",
        "} )\n",
        "result.to_csv(\"/content/drive/MyDrive/submission_test_v9.csv\", index = 0)\n",
        "result.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gor8Gv6EB8zl",
        "outputId": "b8f7a2ac-d3b7-471c-f00a-e0256b5fdc86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  emotion\n",
              "0  0x1c7f0f  disgust\n",
              "1  0x1c7f12    anger\n",
              "2  0x1c7f13    trust\n",
              "3  0x1c7f17    trust\n",
              "4  0x1c7f18    anger"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3d8ee0-1c8c-41de-b3e2-0293092dd4e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x1c7f0f</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x1c7f12</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x1c7f13</td>\n",
              "      <td>trust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x1c7f17</td>\n",
              "      <td>trust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x1c7f18</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3d8ee0-1c8c-41de-b3e2-0293092dd4e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b3d8ee0-1c8c-41de-b3e2-0293092dd4e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b3d8ee0-1c8c-41de-b3e2-0293092dd4e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23c14304-3238-47f1-b9b2-b1f06b6652b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23c14304-3238-47f1-b9b2-b1f06b6652b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23c14304-3238-47f1-b9b2-b1f06b6652b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TFIDF + NN"
      ],
      "metadata": {
        "id": "s7toCnDRdPox"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bheUVy5QdlLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Word2Vec"
      ],
      "metadata": {
        "id": "rvccTJ-kVM2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = x_train.pre_processing_tokens.values"
      ],
      "metadata": {
        "id": "3ukCmcy0ttUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Word2Vec\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# setting\n",
        "vector_dim = 100\n",
        "window_size = 5\n",
        "min_count = 1\n",
        "workers = 2\n",
        "\n",
        "word2vec_model = Word2Vec(sentences=train_corpus,\n",
        "              vector_size = vector_dim,\n",
        "              window=window_size,\n",
        "              min_count=min_count,\n",
        "              workers = workers)"
      ],
      "metadata": {
        "id": "GdtgykNnVGTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_word2vec(text_list):\n",
        "  result = np.zeros(vector_dim, dtype = np.float64)\n",
        "  len = 0\n",
        "  for i in text_list:\n",
        "    if i in word2vec_model.wv:\n",
        "      result = result + word2vec_model.wv[i]\n",
        "      len = len + 1\n",
        "\n",
        "  return result/len if len != 0 else  result"
      ],
      "metadata": {
        "id": "p7YOp3veb0d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[\"word2vec_100\"] = x_train.apply(lambda x: mean_word2vec(x['tokens']), axis = 1)\n",
        "x_test[\"word2vec_100\"] = x_test.apply(lambda x: mean_word2vec(x['tokens']), axis = 1)\n",
        "testing_data[\"word2vec_100\"] = testing_data.apply(lambda x: mean_word2vec(x['tokens']), axis = 1)"
      ],
      "metadata": {
        "id": "DyNesjSxb3jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL Y\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)"
      ],
      "metadata": {
        "id": "5qoxyySysu2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Random Forest\n",
        "\n",
        "X = list(x_train.word2vec_100.values)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "## training!\n",
        "DT_model = model.fit(X, y_train_encoded)"
      ],
      "metadata": {
        "id": "8bj7yex6b9qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing Accuracy\n",
        "\n",
        "x_test[\"word2vec_100\"] = x_test.apply(lambda x: mean_word2vec(x['tokens']), axis = 1)\n",
        "X = list(x_test.word2vec_100.values)\n",
        "\n",
        "y_test_pred = DT_model.predict(X)\n",
        "\n",
        "acc_train = accuracy_score(y_true = y_test_encoded, y_pred = y_test_pred)\n",
        "\n",
        "print('testing accuracy: {}'.format(round(acc_train, 2)))"
      ],
      "metadata": {
        "id": "ys601X3bb-jB",
        "outputId": "3f35b07f-d188-4950-d32a-1d2cf4dcdf10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "\n",
        "X = list(testing_data.word2vec_100.values)\n",
        "\n",
        "y_test_result = DT_model.predict(X)\n",
        "\n",
        "y_test_result = le.inverse_transform( y_test_result )\n",
        "\n",
        "result = pd.DataFrame( {\n",
        "   \"id\" : testing_data.tweet_id,\n",
        "   \"emotion\" : y_test_result\n",
        "} )\n",
        "\n",
        "result.to_csv(\"/content/drive/MyDrive/submission_test_v4.csv\", index = 0)\n",
        "result.head(5)"
      ],
      "metadata": {
        "id": "uI2pPcWScHn_",
        "outputId": "cdc2b1fd-0d62-423f-b0cb-15622e2a699a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id       emotion\n",
              "0  0x28b412           joy\n",
              "1  0x2de201  anticipation\n",
              "2  0x218443       sadness\n",
              "3  0x2939d5           joy\n",
              "4  0x26289a  anticipation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9fe26e2-8900-411d-9b58-e150b7715fed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28b412</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x2de201</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x218443</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2939d5</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x26289a</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9fe26e2-8900-411d-9b58-e150b7715fed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9fe26e2-8900-411d-9b58-e150b7715fed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9fe26e2-8900-411d-9b58-e150b7715fed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-351d3a83-4108-4795-9978-c059f4f1395c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-351d3a83-4108-4795-9978-c059f4f1395c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-351d3a83-4108-4795-9978-c059f4f1395c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NN"
      ],
      "metadata": {
        "id": "NlaXJGJM1GvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding\n",
        "\n",
        "## deal with label (string -> one-hot)\n",
        "\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "print('check label: ', label_encoder.classes_)\n",
        "print('\\n## Before convert')\n",
        "print('y_train[0:4]:\\n', y_train[0:4])\n",
        "print('\\ny_train.shape: ', y_train.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n",
        "\n",
        "def label_encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def label_decode(le, one_hot_label):\n",
        "    dec = np.argmax(one_hot_label, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "y_train_one_hot = label_encode(label_encoder, y_train)\n",
        "y_test_one_hot = label_encode(label_encoder, y_test)\n",
        "\n",
        "print('\\n\\n## After convert')\n",
        "print('y_train[0:4]:\\n', y_train_one_hot[0:4])\n",
        "print('\\ny_train.shape: ', y_train_one_hot.shape)\n",
        "print('y_test.shape: ', y_test_one_hot.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "ow410Lx40RL3",
        "outputId": "b3d31d97-d908-4f4a-8b91-7e6e1776e6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
            " 'trust']\n",
            "\n",
            "## Before convert\n",
            "y_train[0:4]:\n",
            " 0    anticipation\n",
            "1             joy\n",
            "2             joy\n",
            "3         sadness\n",
            "Name: emotion, dtype: object\n",
            "\n",
            "y_train.shape:  (349335,)\n",
            "y_test.shape:  (87334,)\n",
            "\n",
            "\n",
            "## After convert\n",
            "y_train[0:4]:\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\n",
            "y_train.shape:  (349335, 8)\n",
            "y_test.shape:  (87334, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I/O size check\n",
        "input_shape = output_vectorizer.shape[1]\n",
        "output_shape = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "2ltYF8t00Sp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input layer\n",
        "model_input = Input(shape=(input_shape, ))  # 500\n",
        "X = model_input\n",
        "\n",
        "# 1st hidden layer\n",
        "X_W1 = Dense(units=64)(X)  # 64\n",
        "H1 = ReLU()(X_W1)\n",
        "\n",
        "# 2nd hidden layer\n",
        "H1_W2 = Dense(units=64)(H1)  # 64\n",
        "H2 = ReLU()(H1_W2)\n",
        "\n",
        "# output layer\n",
        "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
        "H3 = Softmax()(H2_W3)\n",
        "\n",
        "model_output = H3\n",
        "\n",
        "# create model\n",
        "model = Model(inputs=[model_input], outputs=[model_output])\n",
        "\n",
        "# loss function & optimizer\n",
        "model.compile(optimizer='adam',\n",
        "       loss='categorical_crossentropy',\n",
        "       metrics=['accuracy'])\n",
        "\n",
        "# show model construction\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Fth9ZjP00TV1",
        "outputId": "0e143585-ae0d-48a4-c62c-9789021089e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m64,064\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">64,064</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,744\u001b[0m (268.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,744</span> (268.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,744\u001b[0m (268.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,744</span> (268.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x_train.word2vec_100)"
      ],
      "metadata": {
        "id": "CmEng0IQ4079",
        "outputId": "d2bfb69c-00c5-459c-b118-bdbd66982683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349335,)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_one_hot.shape"
      ],
      "metadata": {
        "id": "sH-GITks5w5_",
        "outputId": "3e70abd8-455d-4f55-f825-0e8b5abe030c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349335, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "x_train_nn = K.cast_to_floatx(x_train.word2vec_100.values)\n",
        "y_train_nn = K.cast_to_floatx(y_train_one_hot)"
      ],
      "metadata": {
        "id": "5npGeT4I4XzS",
        "outputId": "3c78516c-dbd5-49b5-caef-ecbb81f22b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras.api.backend' has no attribute 'cast_to_floatx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-5eb2e36b434f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api.backend' has no attribute 'cast_to_floatx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "2nINStz64sAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor(x_train.word2vec_100.values[0])"
      ],
      "metadata": {
        "id": "l62DzCgQ7Stc",
        "outputId": "02b4e476-53be-46d2-c32c-fadb7ef53da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float64, numpy=\n",
              "array([-0.28891157, -0.51392198, -1.2580553 , -0.07961606,  0.78792557,\n",
              "       -1.01779029, -0.4315294 , -0.3566817 ,  0.1275314 , -0.93393448,\n",
              "       -0.97445206, -0.52523305,  0.46085551,  0.01323835,  1.11242473,\n",
              "       -0.11519837, -2.39290107, -0.137721  ,  1.55165731,  0.3262168 ,\n",
              "        0.31253075, -0.40876732, -1.04998667, -0.31491014,  0.14218648,\n",
              "        0.32194564, -0.24623724, -1.36981471,  0.07970582,  0.60668447,\n",
              "        0.92419443,  0.60009167,  0.30457177,  0.5232327 , -0.77669291,\n",
              "        1.29563875, -0.90363368, -0.1206033 , -0.55609911, -1.11152058,\n",
              "        1.41376781, -1.31118262,  0.8427708 ,  0.28585574,  0.62808239,\n",
              "        0.59105415, -0.03813672, -0.90437077,  0.0426878 ,  0.06495104,\n",
              "        0.89675321, -1.12385925, -0.11752596, -1.59556571, -0.36668717,\n",
              "        0.69645377, -1.07754941,  0.83813685,  0.50564614,  0.19888692,\n",
              "        0.24486466, -0.42000695,  0.1279143 ,  1.61156959,  0.14878466,\n",
              "        0.51675746,  0.49122154, -0.01154648, -0.74202556, -0.04172752,\n",
              "       -0.91941207, -1.24758212,  0.65176398,  0.26773154,  0.29886004,\n",
              "        0.76847719,  0.11653491, -0.70734312, -0.34119703,  0.91804297,\n",
              "       -0.46840473,  0.63307973, -0.62122699,  1.34771543, -0.08773763,\n",
              "       -0.06424718,  0.5979283 ,  1.26133602,  1.54925461, -0.37962277,\n",
              "        0.95030359,  0.44277762,  1.04717184, -0.50958436,  1.02921324,\n",
              "       -0.05875853,  0.12529353,  0.36622271,  0.8290568 ,  0.03360242])>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.word2vec_100.values.astype(dtype = [(np.float64)])"
      ],
      "metadata": {
        "id": "_XB2122X7EJU",
        "outputId": "2e4c5718-49fd-409d-c850-bc8fd6cce7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Field elements must be 2- or 3-tuples, got '<class 'numpy.float64'>'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-9531fbe4e8ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Field elements must be 2- or 3-tuples, got '<class 'numpy.float64'>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "# from keras.callbacks import CSVLogger\n",
        "# csv_logger = CSVLogger('logs/training_log.csv')\n",
        "\n",
        "# training setting\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "# training!\n",
        "history = model.fit(output_vectorizer, y_train_one_hot,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data = (output_vectorizer_test, y_test_one_hot))\n",
        "print('training finish')"
      ],
      "metadata": {
        "id": "PTDZSoHh3oc9",
        "outputId": "e8d45f77-5185-48d8-8c1f-65fc73b1b016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.4612 - loss: 1.4912 - val_accuracy: 0.4957 - val_loss: 1.3904\n",
            "Epoch 2/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.5043 - loss: 1.3691 - val_accuracy: 0.5030 - val_loss: 1.3706\n",
            "Epoch 3/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4ms/step - accuracy: 0.5194 - loss: 1.3271 - val_accuracy: 0.5049 - val_loss: 1.3612\n",
            "Epoch 4/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - accuracy: 0.5274 - loss: 1.3029 - val_accuracy: 0.5068 - val_loss: 1.3592\n",
            "Epoch 5/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.5364 - loss: 1.2818 - val_accuracy: 0.5056 - val_loss: 1.3592\n",
            "Epoch 6/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4ms/step - accuracy: 0.5419 - loss: 1.2670 - val_accuracy: 0.5012 - val_loss: 1.3685\n",
            "Epoch 7/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - accuracy: 0.5466 - loss: 1.2508 - val_accuracy: 0.5030 - val_loss: 1.3667\n",
            "Epoch 8/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.5510 - loss: 1.2430 - val_accuracy: 0.5014 - val_loss: 1.3720\n",
            "Epoch 9/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - accuracy: 0.5553 - loss: 1.2317 - val_accuracy: 0.5011 - val_loss: 1.3821\n",
            "Epoch 10/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.5573 - loss: 1.2238 - val_accuracy: 0.4973 - val_loss: 1.3891\n",
            "Epoch 11/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.5605 - loss: 1.2168 - val_accuracy: 0.4963 - val_loss: 1.3999\n",
            "Epoch 12/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.5647 - loss: 1.2069 - val_accuracy: 0.4970 - val_loss: 1.4015\n",
            "Epoch 13/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.5654 - loss: 1.2023 - val_accuracy: 0.4927 - val_loss: 1.4088\n",
            "Epoch 14/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.5680 - loss: 1.1975 - val_accuracy: 0.4947 - val_loss: 1.4142\n",
            "Epoch 15/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 1.1922 - val_accuracy: 0.4927 - val_loss: 1.4211\n",
            "Epoch 16/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.5727 - loss: 1.1867 - val_accuracy: 0.4945 - val_loss: 1.4202\n",
            "Epoch 17/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 1.1808 - val_accuracy: 0.4920 - val_loss: 1.4364\n",
            "Epoch 18/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - accuracy: 0.5749 - loss: 1.1791 - val_accuracy: 0.4909 - val_loss: 1.4355\n",
            "Epoch 19/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4ms/step - accuracy: 0.5764 - loss: 1.1739 - val_accuracy: 0.4895 - val_loss: 1.4386\n",
            "Epoch 20/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.5776 - loss: 1.1739 - val_accuracy: 0.4923 - val_loss: 1.4451\n",
            "Epoch 21/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - accuracy: 0.5796 - loss: 1.1707 - val_accuracy: 0.4892 - val_loss: 1.4485\n",
            "Epoch 22/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - accuracy: 0.5804 - loss: 1.1670 - val_accuracy: 0.4912 - val_loss: 1.4577\n",
            "Epoch 23/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.5795 - loss: 1.1681 - val_accuracy: 0.4877 - val_loss: 1.4696\n",
            "Epoch 24/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - accuracy: 0.5824 - loss: 1.1610 - val_accuracy: 0.4904 - val_loss: 1.4697\n",
            "Epoch 25/25\n",
            "\u001b[1m10917/10917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 1.1581 - val_accuracy: 0.4879 - val_loss: 1.4685\n",
            "training finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## predict\n",
        "pred_result_test = model.predict(output_vectorizer_test, batch_size=128)\n",
        "pred_result_test[:5]"
      ],
      "metadata": {
        "id": "jxtk469p3xId",
        "outputId": "a867ed74-0093-4c4c-f6e1-edbfe501e9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.8271632e-04, 1.0990217e-01, 4.6986011e-03, 7.5955922e-03,\n",
              "        6.0794413e-01, 2.6080755e-03, 2.5845398e-03, 2.6388413e-01],\n",
              "       [3.3740713e-03, 9.8723710e-02, 3.4478102e-02, 1.4036582e-01,\n",
              "        5.9580362e-01, 2.9223016e-02, 2.6972406e-02, 7.1059316e-02],\n",
              "       [3.4210362e-02, 1.4242639e-01, 1.5957287e-01, 1.6857922e-02,\n",
              "        2.0275207e-01, 2.7755481e-01, 7.5862952e-02, 9.0762660e-02],\n",
              "       [3.1009625e-10, 1.8502025e-08, 8.4229852e-11, 2.8260108e-11,\n",
              "        9.9999994e-01, 3.6594061e-10, 4.7375298e-10, 1.4810303e-08],\n",
              "       [9.5373005e-02, 5.8587644e-02, 3.9580223e-01, 2.4893282e-02,\n",
              "        1.2639330e-01, 2.5650522e-01, 2.1018080e-02, 2.1427071e-02]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result_test = label_decode(label_encoder, pred_result_test)\n",
        "pred_result_test[:5]"
      ],
      "metadata": {
        "id": "bH09Wv42GKEk",
        "outputId": "6ce5c411-4537-45b5-8690-254c2d81b784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joy', 'joy', 'sadness', 'joy', 'disgust'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'testing accuracy: { round(accuracy_score(y_test.values, pred_result_test),2) }')"
      ],
      "metadata": {
        "id": "-UA-RMHqGPj1",
        "outputId": "69e2f431-1751-4007-8e6d-b8a6c23b5f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing accuracy: 0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## predict\n",
        "pred_result_test = model.predict(output_vectorizer_true_test, batch_size=128)\n",
        "pred_result_test = label_decode(label_encoder, pred_result_test)\n",
        "pred_result_test[:5]"
      ],
      "metadata": {
        "id": "atLz7-zKGXa1",
        "outputId": "a5837a34-2297-4bdb-895f-3e416e22cb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3219/3219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anticipation', 'anticipation', 'joy', 'joy', 'anticipation'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame( {\n",
        "   \"id\" : testing_data.tweet_id,\n",
        "   \"emotion\" : pred_result_test\n",
        "} )\n",
        "\n",
        "result.to_csv(\"/content/drive/MyDrive/submission_test_v4.csv\", index = 0)\n",
        "result.head(5)"
      ],
      "metadata": {
        "id": "FZ0vVvFVG9fH",
        "outputId": "aae9d708-f4a4-4774-df78-cfafd43eea3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id       emotion\n",
              "0  0x28b412  anticipation\n",
              "1  0x2de201  anticipation\n",
              "2  0x218443           joy\n",
              "3  0x2939d5           joy\n",
              "4  0x26289a  anticipation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b196e0d-cec1-4b23-baaa-305f0e6e27b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x28b412</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x2de201</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x218443</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x2939d5</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x26289a</td>\n",
              "      <td>anticipation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b196e0d-cec1-4b23-baaa-305f0e6e27b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b196e0d-cec1-4b23-baaa-305f0e6e27b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b196e0d-cec1-4b23-baaa-305f0e6e27b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02125602-1d6e-46bf-869e-21997e923e5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02125602-1d6e-46bf-869e-21997e923e5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02125602-1d6e-46bf-869e-21997e923e5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT Embedding\n",
        "  - 所需Input\n",
        "    - token id : 每個單字在字典裡對應的一個 index\\\n",
        "    - attention mask : padding成相同長度後，attention mask 讓self-attention知道哪些是該注意的字\n",
        "    - segment id : 如果一次Input兩個句子, segment id 區分兩個句子的Index。"
      ],
      "metadata": {
        "id": "zFrTNXDdMPWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "# y_train\n",
        "y_train_trans = label_encoder.transform(y_train)  # +1 避免label有 0 # 不然會有CUDA error\n",
        "\n",
        "# y_test\n",
        "y_test_trans = label_encoder.transform(y_test)\n",
        "\n",
        "print( f\"After labeling : {y_train_trans}\")"
      ],
      "metadata": {
        "id": "djM1jePQsk3m",
        "outputId": "585e20cf-f2bb-416e-e930-42d5bce5003e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After labeling : [6 4 4 ... 7 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "2P7sdOblXmBY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import 相關套件 & download tokenizers and model\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "wT6niqA7MRR0",
        "outputId": "3c7b6b00-dd3e-40c0-81f5-31403024ec3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AdamW' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ed5b4e6a8e64>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AdamW' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_trans.max()"
      ],
      "metadata": {
        "id": "ZV2uPp6pNsU4",
        "outputId": "fe8d1c9b-f798-4a49-abc0-83dce3820b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 可以跳過 這只是 pre_trained tokenizer 內部的步驟\n",
        "\n",
        "# 1. tokenize sentence\n",
        "\n",
        "sentence = training_data.text[0]\n",
        "print(f\"Original_text : {sentence}\")\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(f\"Tokenized_text : {tokens}\")\n",
        "\n",
        "# 2. Add [CLS] and [SEP] tokens\n",
        "tokens = ['CLS'] + tokens + ['SEP']\n",
        "\n",
        "# 3. Padding the input 每個句子padding成一樣的長度\n",
        "\n",
        "T = 45 # 給定長度]\n",
        "\n",
        "padded_tokens = tokens + ['[PAD]' for _ in range(0,T-len(tokens))]\n",
        "# attention_mask padding成相同長度後，讓self-attention layer 知道哪些是padding 哪些是要關注的字\n",
        "attn_mask = [ 1 if i != '[PAD]' else 0 for i in padded_tokens]\n",
        "\n",
        "seg_ids = [ 0 for _ in range(0, len(padded_tokens))]\n",
        "\n",
        "sent_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "\n",
        "print(f\"Tokens id : {sent_ids}\")\n",
        "print(f\"Attention mask : {attn_mask}\")\n",
        "print(f\"Segment_id : {seg_ids}\")\n",
        "\n",
        "# * 4. Input tensor 轉tensor\n",
        "# token_ids = torch.tensor(sent_ids).unsqueeze(0)\n",
        "# attn_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
        "# seg_ids   = torch.tensor(seg_ids).unsqueeze(0)\n",
        "\n",
        "# print(f\"Tensor-Tokens id : {token_ids}\")\n",
        "# print(f\"Tensor-Attention mask : {attn_mask}\")\n",
        "# print(f\"Tensor-Segment_id : {seg_ids}\")"
      ],
      "metadata": {
        "id": "sY3WjZdXXaJ-",
        "outputId": "0da5ab5f-77bb-4591-e0ba-96864f1963ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original_text : People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's <LH>\n",
            "Tokenized_text : ['people', 'who', 'post', '\"', 'add', 'me', 'on', '#', 'snap', '##cha', '##t', '\"', 'must', 'be', 'de', '##hy', '##dra', '##ted', '.', 'cu', '##z', 'man', '.', '.', '.', '.', 'that', \"'\", 's', '<', 'l', '##h', '>']\n",
            "Tokens id : [100, 2111, 2040, 2695, 1000, 5587, 2033, 2006, 1001, 10245, 7507, 2102, 1000, 2442, 2022, 2139, 10536, 7265, 3064, 1012, 12731, 2480, 2158, 1012, 1012, 1012, 1012, 2008, 1005, 1055, 1026, 1048, 2232, 1028, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Attention mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segment_id : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tensor-Tokens id : tensor([[  100,  2111,  2040,  2695,  1000,  5587,  2033,  2006,  1001, 10245,\n",
            "          7507,  2102,  1000,  2442,  2022,  2139, 10536,  7265,  3064,  1012,\n",
            "         12731,  2480,  2158,  1012,  1012,  1012,  1012,  2008,  1005,  1055,\n",
            "          1026,  1048,  2232,  1028,   100,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "Tensor-Attention mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "Tensor-Segment_id : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(training_data.text[0], add_special_tokens=True, truncation=True,\n",
        "     padding='max_length', return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "LUe2rKa7LBjy",
        "outputId": "d6c6579f-29ee-4526-ae1b-3e95b2be3d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d35618722e7d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tokenizer(training_data.text[0], add_special_tokens=True, truncation=True, \n\u001b[0m\u001b[1;32m      2\u001b[0m        padding='max_length', return_tensors=\"pt\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model inference\n",
        "\n",
        "output = model( input_ids = token_ids, attention_mask = attn_mask, token_type_ids = seg_ids)\n",
        "\n",
        "last_hidden_state, pooler_output = output[0], output[1]\n",
        "\n",
        "# last_hidden_state: hiddenstate of each tokens\n",
        "# pooler_output: sentence embedding 就是句子開頭的[CLS](代表該句子的摘要信息)\n",
        "\n",
        "print(f\"last_hidden_state shape:{last_hidden_state.shape}\") # [batch_size, sequence_length, hidden_size]\n",
        "print(f\"pooler_output shape:{pooler_output.shape}\") # [batch_size, hidden_size]"
      ],
      "metadata": {
        "id": "MCSrLHj1cE_a",
        "outputId": "5e657c38-3fad-4565-ffc0-46501e5886c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f878c2c07e52>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1669\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJ1zcTlCLAW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 進Pytorch前 Dataset定義\n",
        "\n",
        "class TweetData(Dataset):  # Dataset 是 torch 來的\n",
        "\n",
        "  def __init__(self, inputs, targets, tokenizer, max_len): # 處理資料讀取\n",
        "    self.texts = inputs\n",
        "    self.labels = targets\n",
        "    self.tokenizers = tokenizer\n",
        "    self.len = max_len\n",
        "\n",
        "\n",
        "  def __len__(self):  # 回傳dataset長度\n",
        "\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, index): # 特定資料回傳 # 可做数据增强、normalize\n",
        "\n",
        "    sentence = self.texts[index]\n",
        "\n",
        "    t = self.tokenizers(sentence, max_length = self.len, add_special_tokens=True, truncation=True,\n",
        "       padding='max_length', return_tensors=\"pt\")\n",
        "\n",
        "    result = {\n",
        "       'input_ids' : t['input_ids'].squeeze(0),\n",
        "       'token_type_ids': t['token_type_ids'].squeeze(0), # 要squeeze(0) 不然維度少一個報錯\n",
        "       'attention_mask': t['attention_mask'].squeeze(0),\n",
        "       'labels' : torch.tensor( self.labels[index], dtype = torch.long )\n",
        "    }\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "7lGIyGpWlJxM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "max_len = 128\n",
        "train_loader = DataLoader(TweetData(x_train.text.tolist(), y_train_trans, tokenizer, max_len), batch_size=32, shuffle=True, num_workers=1) # new_workers 用多少線程處理\n",
        "test_loader = DataLoader(TweetData(x_test.text.tolist(), y_test_trans, tokenizer, max_len ), batch_size =32, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "6FJgumy-qtpI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PH375ESaZVXy",
        "outputId": "0e50257d-edb1-43fd-e456-e7154efe84a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "tt = tqdm(train_loader)\n",
        "for data in tt:\n",
        "  t = t+1\n",
        "  print(data)\n",
        "  if t > 1 :\n",
        "    break"
      ],
      "metadata": {
        "id": "HHl_8Rp_FL4f",
        "outputId": "ec50a800-4c3d-4f19-956f-3831158ab8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816,
          "referenced_widgets": [
            "6703ccbf4328454eb8da2a9fb495f7e6",
            "182ff35d4be24861add60dc153a5e93d",
            "c96438e5b002451a80b94e6683edcdd0",
            "3b3131efd76b4fd0ba83c8275f48d390",
            "e95a7add77b54a8e97ffc1c86423505f",
            "0a00141c0c2341c3940f61f703b634e4",
            "2d115e544a3946238202785edaa6784b",
            "78c1d3fa81c14b759fa11b21c8f376dc",
            "da825e65ca9c424096affe8c10d1e01b",
            "5381c92b0caa4583b937fd1d3a1f4ec8",
            "d0f7b01ec4d442418560ea5132c0430e"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4549 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6703ccbf4328454eb8da2a9fb495f7e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1030, 24264,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2293,  ...,     0,     0,     0],\n",
            "        [  101,  2131,  7629,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1030,  2585,  ...,     0,     0,     0],\n",
            "        [  101,  2067,  2013,  ...,     0,     0,     0],\n",
            "        [  101,  1030,  5925,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([3, 6, 6, 5, 6, 2, 8, 5, 6, 5, 6, 3, 7, 3, 6, 8, 3, 7, 2, 2, 5, 5, 2, 2,\n",
            "        8, 2, 8, 6, 5, 3, 3, 5, 1, 5, 5, 5, 4, 6, 5, 5, 6, 5, 2, 2, 1, 5, 5, 5,\n",
            "        5, 5, 5, 6, 2, 5, 5, 8, 6, 1, 5, 5, 2, 6, 5, 6])}\n",
            "{'input_ids': tensor([[  101,  1030,  4748,  ...,     0,     0,     0],\n",
            "        [  101, 13451, 10216,  ...,     0,     0,     0],\n",
            "        [  101,  2551,  2041,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  1523,  2296,  ...,     0,     0,     0],\n",
            "        [  101,  1059, 24475,  ...,     0,     0,     0],\n",
            "        [  101,  1001, 13896,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([6, 5, 2, 8, 8, 6, 7, 6, 6, 8, 6, 2, 5, 5, 5, 4, 5, 2, 5, 8, 8, 3, 5, 2,\n",
            "        5, 4, 8, 3, 6, 5, 8, 3, 5, 6, 6, 5, 1, 6, 5, 5, 8, 5, 7, 6, 8, 2, 3, 3,\n",
            "        5, 5, 6, 6, 2, 2, 3, 7, 5, 8, 8, 8, 2, 2, 4, 2])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SequenceClassifierOutput(loss=tensor(0.4921, device='cuda:0', grad_fn= NllLossBackward0 ), logits=tensor([[-0.0726, -0.5257]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3tg-mUJ8B7bE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gZHGWHxQZad"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr = 1e-4)\n",
        "\n",
        "for epoch in range(0):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # train = tqdm(train_loader)\n",
        "\n",
        "    for data in train_loader:\n",
        "\n",
        "        for key in data.keys():\n",
        "\n",
        "            data[key] = data[key].to(device)\n",
        "\n",
        "        outputs = model(**data)\n",
        "        print(outputs)\n",
        "        loss = outputs.loss # SequenceClassifierOutput 的 loss\n",
        "        train.set_description(f'Epoch {epoch}')\n",
        "        train.set_postfix({'Loss': loss.item()})\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    # 模型fine tune 完成\n",
        "    # 驗證資料\n",
        "    model.eval()\n",
        "    # test = tqdm(test_loader)\n",
        "    correct = 0\n",
        "    for data in test_loader:\n",
        "        for key in data.keys():\n",
        "            data[key] = data[key].to(device)\n",
        "        outputs = model(**data)\n",
        "        _,predict_label = torch.max(outputs.logits,1) # 1 是 代表取col最大值\n",
        "        correct += (predict_label==data['labels']).sum()\n",
        "        test.set_description(f'Epoch {epoch}')\n",
        "        test.set_postfix({'acc':'{:.4f}'.format(correct / len(test_set) * 100)})\n",
        "    model.save_pretrained('model_{}'.format(epoch))"
      ],
      "metadata": {
        "id": "Di4w3NGPyaHe",
        "outputId": "757bcda5-08ff-4843-aa85-1e335e2c5267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c4eecfed84af49e8a30b36b6a2c0db3d",
            "1ecc45e1bf364ee9bfb8d9843b8a60c0",
            "c6790381cee24193a3d869f48214e408",
            "d762dd1be6ff47cd8ca6b337aa86d5d4",
            "d796d2053d2840618961e3255d61143e",
            "ea18ed9a9ba946ccbeba9da73ba47da9",
            "1a8acd02a9af4a06b1a265cd095c1cc1",
            "b7dbe13e6f994bfcb58838744620356e",
            "20dc5b1088d547c59021203e13bbeedd",
            "9f5ef46325d64e66a4ccc81bc2c1148a",
            "6f1f4806474c47d890a16b874154ac18"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9098 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4eecfed84af49e8a30b36b6a2c0db3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "        [-6.7287e-01, -1.2993e-01,  1.1753e-01, -3.2371e-01,  1.0047e+00,\n",
            "          1.5445e+00, -1.1782e+00, -3.1304e-01],\n",
            "        [-2.2944e+00,  1.8071e+00, -1.6645e+00, -1.0171e+00,  1.4205e+00,\n",
            "         -1.2756e+00, -1.2875e+00,  2.5773e+00],\n",
            "        [-2.6811e+00,  2.3908e+00, -1.9402e+00, -1.5071e+00,  2.7144e+00,\n",
            "         -5.4187e-01, -1.6911e+00,  1.7098e+00],\n",
            "        [-2.5043e+00, -2.2318e-01, -5.7364e-01, -1.8724e+00,  3.9804e+00,\n",
            "          2.9317e-01, -1.5377e-01,  7.2100e-01],\n",
            "        [-1.7449e+00, -1.6899e-01, -4.0628e-01, -1.2566e+00,  5.0578e-01,\n",
            "          6.3270e+00, -1.2060e+00, -8.9701e-01],\n",
            "        [-2.3667e+00,  2.8203e+00, -5.7506e-01, -1.1423e+00,  1.1359e+00,\n",
            "         -5.0807e-01, -1.9847e+00,  7.6865e-01],\n",
            "        [-6.8844e-01, -4.2733e-01,  1.2231e-01, -3.5238e-01,  1.4648e+00,\n",
            "          3.4316e-01, -9.1254e-01,  1.0694e-01],\n",
            "        [-1.8598e-01, -5.6997e-01,  6.4199e-01,  2.1539e-02,  6.7888e-01,\n",
            "          7.2518e-01, -7.3786e-01, -4.9998e-01],\n",
            "        [-2.6123e+00,  2.8012e+00, -1.6811e+00, -1.5093e+00,  1.9796e+00,\n",
            "         -7.4238e-01, -1.9026e+00,  1.3678e+00],\n",
            "        [-2.7932e+00,  1.0656e+00, -1.8888e+00, -1.5742e+00,  6.1488e-01,\n",
            "         -1.5839e+00, -1.0739e+00,  5.7780e+00],\n",
            "        [-1.6660e+00, -4.9913e-01,  3.5719e+00, -1.6720e+00, -7.3369e-01,\n",
            "          2.2536e+00, -3.7156e-01, -9.4730e-01],\n",
            "        [-3.2851e+00, -1.0517e+00, -1.2209e-01, -8.3858e-01,  2.8827e-01,\n",
            "          2.6345e+00,  4.4325e+00, -7.4934e-01],\n",
            "        [-1.5880e+00,  3.4581e-01,  2.1097e+00, -1.8092e+00, -2.7869e-01,\n",
            "          1.2421e+00, -6.8336e-01,  3.5753e-01],\n",
            "        [-1.3708e+00,  3.8196e-01,  6.5057e-03, -1.0665e+00,  9.0540e-01,\n",
            "          8.0657e-01, -1.2827e+00,  1.1496e+00],\n",
            "        [-1.9662e+00, -6.2312e-01, -1.8410e+00, -2.1614e+00,  6.6236e+00,\n",
            "          8.7347e-02, -1.0536e+00, -4.3783e-01],\n",
            "        [-1.7185e+00, -9.5471e-01, -1.6715e+00, -1.9726e+00,  7.0115e+00,\n",
            "         -1.1523e-01, -1.2423e+00, -3.9173e-01],\n",
            "        [ 5.3419e-01, -8.1669e-01,  6.4431e-01, -7.3710e-01,  1.2808e+00,\n",
            "          1.3051e+00, -1.0655e+00, -7.2715e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.0008, -0.5534,  0.6245, -0.9208,  1.0118,  2.3412, -0.8666, -0.3299],\n",
            "        [-2.4611,  3.4010, -1.6317, -1.9347,  1.8666, -0.6014, -1.9722,  1.2602],\n",
            "        [-2.1300,  0.4425, -0.3559, -0.1368,  1.8560,  0.4681, -0.5720,  0.1902],\n",
            "        [-2.7909,  1.0468, -2.0223, -1.0527,  3.1747, -0.7539, -1.1859,  2.0938],\n",
            "        [-2.6686,  1.9900, -2.2553, -2.4873,  4.1961, -0.3001, -1.9648,  1.1289],\n",
            "        [-0.7714, -0.4947,  0.1948, -0.7678,  1.8122,  0.3870, -0.6375,  0.2104],\n",
            "        [-0.7648, -0.0630, -0.2233, -1.1707,  1.9853,  0.5328, -0.9482,  0.4800],\n",
            "        [-1.5962, -0.1520, -0.3809, -0.7987,  2.2321,  0.2694, -0.7780,  0.7818],\n",
            "        [-0.3291, -0.8078,  1.5106,  0.4001, -0.0537,  1.7067, -0.2665, -1.0240],\n",
            "        [-1.3506, -0.3135,  0.4225, -0.1995,  1.0722,  1.0999, -0.2315, -0.3693],\n",
            "        [-3.0955,  5.8130, -1.7725, -2.3530,  1.4378, -1.1841, -2.4342,  0.5844],\n",
            "        [-0.0463, -0.0553,  0.7413, -1.2460,  0.6606,  0.5684, -0.6660, -0.4621],\n",
            "        [-2.5155,  2.4408, -1.2091, -1.3072,  1.4310, -0.2137, -2.0678,  1.9817],\n",
            "        [-1.8678,  0.2092, -1.0472, -1.5945,  2.7543, -0.1348, -1.0134,  1.3829],\n",
            "        [-0.7505, -0.8003,  2.2172, -0.6489, -0.3748,  2.3130, -0.4702, -0.8615],\n",
            "        [-1.6636,  1.4713, -0.5795, -1.5869,  1.8916,  0.1777, -1.2598,  0.8681],\n",
            "        [-0.8212, -0.1975,  0.4667, -1.5329,  1.6105,  0.6242, -0.8042,  0.3715],\n",
            "        [-2.1136,  1.1281, -1.4108, -1.9716,  3.1069,  0.7682, -1.3958,  0.6775],\n",
            "        [-0.4363, -0.6729,  1.7106, -0.6544,  0.0899,  1.4927,  0.3998, -1.0108],\n",
            "        [-0.9605, -0.5781,  0.7491, -1.2299,  1.1648,  0.2172,  0.7416, -0.0711],\n",
            "        [-2.4974,  1.7374, -1.2688, -1.1392,  2.9329, -0.4054, -1.2441,  0.8952],\n",
            "        [-2.6034,  0.4903, -1.1457, -1.4080,  3.2352, -0.0449, -0.6756,  1.1395],\n",
            "        [-3.3497,  2.2100, -2.4678, -2.7183,  3.3208, -0.7370, -1.7827,  2.6720],\n",
            "        [-2.6483,  0.7882, -1.2980, -1.4066,  2.9375, -0.3391, -0.7090,  1.7207],\n",
            "        [-1.5687,  0.8896,  0.1292, -1.1411,  1.5362,  0.2092, -0.4144,  0.1982],\n",
            "        [-2.0342,  0.5782, -0.5153, -1.3087,  2.2453,  0.5909, -0.4388,  0.3924],\n",
            "        [-1.8316,  0.2093,  4.9305, -2.2091, -1.1039,  0.5667, -0.8744, -0.4133],\n",
            "        [-1.8245,  0.1575, -0.2780, -1.1278,  2.3168,  0.6409, -0.6825,  0.5130],\n",
            "        [-2.7622,  1.2638, -1.8407,  5.3724, -0.8042, -1.1298, -1.1653,  1.1324],\n",
            "        [-2.2283, -0.0471, -0.1220, -1.3229,  0.2316,  6.1487, -1.3970, -0.5823],\n",
            "        [-0.6479, -0.7220,  0.5069, -0.0305,  1.1938,  0.9267, -0.6248, -0.3133],\n",
            "        [-2.1125, -1.1216, -0.1956, -0.2230,  0.1683, -0.2445,  5.9371, -0.3109]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1397, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.6572e+00,  1.2343e+00, -1.3639e+00, -1.2796e+00,  3.0904e+00,\n",
            "         -3.7681e-01, -1.1446e+00,  1.3779e+00],\n",
            "        [ 9.9236e-01, -4.1038e-01,  1.1733e+00, -7.0784e-01, -7.8156e-03,\n",
            "          1.4538e+00, -7.5004e-01, -1.0560e+00],\n",
            "        [-1.5700e+00,  1.9522e-01,  2.3038e-01, -4.9802e-01,  1.5625e+00,\n",
            "          1.1004e+00, -3.5049e-01, -2.8245e-01],\n",
            "        [-2.1829e+00,  2.9155e-01,  2.4742e-01, -4.7984e-01,  1.3195e+00,\n",
            "          1.0197e+00,  1.2684e-02, -1.0530e-01],\n",
            "        [-2.9932e+00,  2.6666e+00, -2.3337e+00, -1.9606e+00,  2.7985e+00,\n",
            "         -1.1127e+00, -1.8810e+00,  2.1667e+00],\n",
            "        [-2.7449e+00,  8.5953e-01, -2.1545e+00, -1.8924e+00,  3.2908e+00,\n",
            "         -1.5230e+00, -1.4553e+00,  3.6124e+00],\n",
            "        [-1.6171e+00, -8.2417e-01, -2.5925e-01,  8.6741e-01,  1.4216e+00,\n",
            "          1.6494e+00, -7.2129e-01, -9.7007e-02],\n",
            "        [-2.5157e+00,  1.7794e-01, -1.2922e+00, -6.5608e-01,  2.7271e+00,\n",
            "         -2.4570e-01, -1.0044e+00,  1.6733e+00],\n",
            "        [-7.5321e-01, -9.3950e-02,  1.0816e+00, -9.8339e-01,  2.6726e-01,\n",
            "          7.2383e-01, -7.2686e-02,  2.4389e-02],\n",
            "        [-2.7836e+00,  9.1211e-01, -1.6473e+00, -1.5409e+00,  2.5070e+00,\n",
            "         -1.0041e+00, -1.1394e+00,  2.9400e+00],\n",
            "        [-1.2553e+00, -6.2907e-01,  1.7382e+00,  1.2776e-02,  4.9144e-03,\n",
            "          1.7399e+00,  1.7911e-01, -1.0146e+00],\n",
            "        [-1.9003e+00, -2.0602e-01, -9.8827e-01, -1.3397e+00,  2.9649e+00,\n",
            "          7.3573e-01, -8.3519e-01,  1.0594e+00],\n",
            "        [-2.9503e+00,  2.6102e+00, -2.3283e+00, -1.2263e+00,  2.8046e+00,\n",
            "         -1.3405e+00, -1.7152e+00,  2.2885e+00],\n",
            "        [-8.4941e-01, -4.4126e-01,  1.0582e+00, -2.7635e-01,  5.1639e-01,\n",
            "          6.6518e-01, -3.5767e-01, -1.3679e-01],\n",
            "        [-1.6562e+00,  3.9541e-01, -7.7998e-01, -1.3579e+00,  2.5700e+00,\n",
            "         -1.2357e-01, -1.3154e+00,  9.6127e-01],\n",
            "        [-3.1405e+00,  5.8522e+00, -2.1832e+00, -2.4362e+00,  1.6536e+00,\n",
            "         -1.4099e+00, -2.1398e+00,  7.5243e-01],\n",
            "        [-7.0623e-01, -8.8603e-01,  5.9363e-01,  3.9078e-02,  1.1846e+00,\n",
            "          1.0124e+00, -4.2071e-01, -4.3512e-01],\n",
            "        [-2.0754e+00,  2.3212e+00, -1.6550e-01, -1.2178e+00,  8.1598e-01,\n",
            "          3.8340e-02, -1.0880e+00,  4.2395e-01],\n",
            "        [-2.5976e+00,  6.6777e-01, -1.7055e+00, -1.3789e+00,  2.4956e+00,\n",
            "         -8.9484e-01, -1.6027e+00,  3.5893e+00],\n",
            "        [-9.2304e-01, -1.2249e-01,  1.1587e+00, -2.1389e-01,  6.8401e-01,\n",
            "          1.2280e+00, -6.9033e-01, -5.9196e-01],\n",
            "        [-1.4898e+00, -1.3625e-01,  1.8990e-01, -1.1927e+00,  1.8855e+00,\n",
            "          4.3037e-01, -3.5094e-01,  5.1150e-01],\n",
            "        [-2.3202e+00,  5.5311e-01, -1.2353e+00, -1.6601e+00,  3.0021e+00,\n",
            "         -7.9934e-03, -1.0496e+00,  1.0857e+00],\n",
            "        [-2.4002e+00,  1.0055e-01, -4.0519e-01, -1.1318e+00,  6.1968e-01,\n",
            "          6.5187e+00, -1.1292e+00, -6.0498e-01],\n",
            "        [-1.0212e+00,  6.2891e-01,  8.4570e-01, -1.7319e+00,  1.2309e+00,\n",
            "          3.6804e-01, -6.9042e-01,  2.7966e-02],\n",
            "        [-7.7077e-01, -4.0524e-01,  1.1725e+00, -1.4016e+00,  1.0253e+00,\n",
            "          1.3777e+00, -8.2307e-01, -9.7021e-03],\n",
            "        [-1.9934e+00,  1.0050e+00, -8.9681e-01, -1.1119e+00,  1.4143e+00,\n",
            "          4.8021e-01, -2.1261e+00,  1.8044e+00],\n",
            "        [-1.8950e+00,  8.9792e-01, -4.2014e-01, -1.1867e+00,  2.1586e+00,\n",
            "          8.0999e-03, -8.2192e-01,  5.0010e-01],\n",
            "        [-1.9710e+00,  5.6017e-01, -1.0668e+00, -1.8018e+00,  3.5327e+00,\n",
            "          1.1828e+00, -1.3437e+00,  2.5904e-01],\n",
            "        [-9.5491e-01,  2.1889e-01, -1.9309e-02, -1.0065e+00,  1.8920e+00,\n",
            "          3.4857e-01, -8.9183e-01,  1.7048e-01],\n",
            "        [-2.8648e+00,  5.7450e+00, -1.7868e+00, -2.6886e+00,  1.4410e+00,\n",
            "         -1.1475e+00, -2.2610e+00,  5.4142e-01],\n",
            "        [-1.7365e-01, -1.0057e+00,  1.9436e+00, -3.1324e-01,  7.8085e-02,\n",
            "          1.7698e+00, -1.7148e-01, -9.5450e-01],\n",
            "        [-1.6622e+00,  7.9926e-01, -2.2439e-01,  3.0369e-01,  1.3325e+00,\n",
            "          1.1876e-01, -9.5165e-01,  2.5372e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8201,  2.5902, -1.4284, -1.8962,  1.4483, -0.5617, -1.5095,  2.6847],\n",
            "        [-1.0012, -0.3698,  2.0307, -1.4027, -0.1623,  1.5065, -0.6931,  0.2790],\n",
            "        [-2.7725, -0.6065, -2.4309, -2.6497,  7.1495, -0.8152, -1.2957,  0.6044],\n",
            "        [-0.4384, -0.4315,  0.8309, -0.3269,  0.2205,  1.8820, -0.3637, -0.6129],\n",
            "        [-0.1015, -0.3932,  0.8588, -1.5039,  1.1012,  0.4418, -0.9713,  0.1765],\n",
            "        [-2.4027,  1.7379, -1.5683, -1.4999,  2.8492, -0.6327, -1.0569,  1.4641],\n",
            "        [-2.9247,  2.8661, -1.9143, -1.5188,  2.0298, -0.9467, -1.4153,  1.8274],\n",
            "        [-2.3708,  0.9598, -1.8979, -1.9503,  3.5222, -0.3577, -1.1402,  1.4679],\n",
            "        [-1.9002,  0.0359, -0.4395, -1.6081,  0.5660,  6.1407, -1.6117, -0.7022],\n",
            "        [-3.2304,  0.1778, -2.0478, -1.7205,  2.3022, -1.6435,  0.0753,  5.1523],\n",
            "        [-1.9905,  0.2942, -1.5272,  5.6787, -0.3343, -0.4190, -0.4079, -0.8514],\n",
            "        [-2.0069, -0.9350, -1.6589, -1.6286,  7.0530, -0.0753, -1.1800, -0.3681],\n",
            "        [-2.9743,  3.3683, -2.2586, -2.2626,  2.8345, -1.0080, -1.7824,  1.5621],\n",
            "        [-1.1825, -0.1146,  0.7646, -0.9352,  0.8638,  0.7833,  0.2778, -0.4754],\n",
            "        [-2.5282,  1.8740, -1.6551, -2.3012,  3.5340,  0.0461, -1.4360,  0.9035],\n",
            "        [-1.6904,  0.4240, -0.7975, -1.1109,  2.0657, -0.2601, -0.7808,  1.0472],\n",
            "        [-1.8984,  0.0742, -0.4655, -1.0149,  2.2570,  0.5339, -0.0671,  0.3695],\n",
            "        [-2.9551,  1.1882, -2.1640, -2.0565,  3.6528, -0.7733, -1.5039,  2.7983],\n",
            "        [-3.0010,  1.4423, -1.6795,  1.3752,  1.6050, -0.8849, -1.2619,  1.5769],\n",
            "        [-0.2131, -0.8270,  1.1276, -0.8502,  0.4509,  2.1820, -0.8039, -0.6534],\n",
            "        [-1.6393, -0.4570, -0.2925, -1.0311,  2.4480,  0.3878, -0.2078,  0.7616],\n",
            "        [-2.3872,  1.1203, -0.0694, -0.3654,  0.6028,  0.4502,  0.2065,  0.3922],\n",
            "        [-1.9185, -0.3413, -0.7506, -1.4142,  2.8109,  0.4659, -0.8190,  0.8640],\n",
            "        [-2.9063,  2.2181, -1.6258, -1.8662,  2.6935, -0.4881, -1.3401,  1.6846],\n",
            "        [-1.0032, -0.9057,  1.2329, -0.9334,  0.7702,  1.8845, -0.2060, -0.4464],\n",
            "        [-2.4090,  1.6206, -1.9881, -1.8348,  3.2738, -0.8933, -1.5415,  1.5530],\n",
            "        [-0.8876, -0.5901, -0.4183, -0.7392,  2.3267,  1.0184, -0.7218, -0.0202],\n",
            "        [-2.0049,  0.7348, -0.9692, -2.0561,  3.3888,  0.3398, -1.0025,  0.6533],\n",
            "        [-1.5988, -0.5291,  1.4586, -0.9498,  1.1013,  1.0863,  0.0873, -0.3028],\n",
            "        [-1.1659,  0.0740, -0.1922, -0.9697,  1.9910,  0.5786, -0.6464,  0.3984],\n",
            "        [-2.4203,  0.1516, -1.4957, -2.1331,  4.1918, -0.4836, -0.6224,  1.0330],\n",
            "        [-0.7997, -0.3050,  0.3489,  0.0490,  0.8627,  1.2962, -0.6296, -0.4439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1853, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.5496,  2.8051,  0.0142, -1.2755,  0.3114,  0.5211, -1.0807, -0.4585],\n",
            "        [-2.7105,  1.6779, -1.9648, -1.4153,  2.2433, -1.7480, -1.7032,  3.4729],\n",
            "        [-1.3496,  0.2068,  0.7040, -0.5995,  1.0429,  0.5950, -0.0402, -0.3258],\n",
            "        [-2.1341,  1.3445, -1.4157, -1.4133,  2.0198, -1.0371, -1.1846,  2.3507],\n",
            "        [-2.1063,  0.8598, -0.3431, -0.7993,  1.1523, -0.0925,  0.7171,  0.1343],\n",
            "        [-1.0460, -0.2843, -0.4114, -1.2771,  2.5061,  0.7706, -0.9992,  0.3340],\n",
            "        [-1.6876, -1.2736, -1.0296, -1.6759,  6.6354, -0.3880, -1.4233, -0.5237],\n",
            "        [-2.7511,  2.2715, -1.6067, -0.8176,  2.2774, -0.5943, -1.2117,  1.2320],\n",
            "        [-2.5498,  4.0937, -1.9154, -1.4201,  1.9689, -0.7255, -2.6026,  0.9958],\n",
            "        [-1.6636,  1.0451, -0.2154, -1.0031,  1.7504,  0.0375, -1.0294,  0.1556],\n",
            "        [-1.4469, -0.7096, -1.6228, -1.5328,  6.6817,  0.0909, -1.2226, -0.7756],\n",
            "        [-3.3298,  4.6471, -1.8354, -2.4257,  2.2330, -1.0397, -2.0588,  0.7307],\n",
            "        [-0.7578, -1.0131,  2.1192, -1.2587,  0.8957,  0.5264, -0.4547, -0.2080],\n",
            "        [-2.5106,  1.4221, -0.9764, -1.1884,  2.0617, -0.3842, -1.2391,  1.5627],\n",
            "        [-0.8701, -0.5767,  0.3316, -0.5619,  1.4654,  0.9343, -0.3926, -0.0928],\n",
            "        [-1.3445, -0.3040,  1.0966, -1.2318,  0.7759,  1.2984,  0.2237, -0.0757],\n",
            "        [-1.1509, -0.3384, -0.0443, -1.0027,  1.9540,  0.8362, -0.6576,  0.0841],\n",
            "        [-2.9629,  1.1087, -2.1068, -1.4322,  3.6164, -0.9886, -1.1290,  1.5504],\n",
            "        [-2.9710,  1.1296, -1.2995, -1.5375,  2.9003, -0.1641, -1.1822,  1.4549],\n",
            "        [-1.9643,  1.3865, -0.6728, -1.0572,  1.8624,  0.0529, -1.0024,  0.3592],\n",
            "        [-1.4196,  1.3025, -0.6595, -0.4851,  1.4137,  0.1126, -1.1767,  0.4237],\n",
            "        [-1.1633, -0.2631,  0.4729, -1.5148,  2.2351, -0.2091, -0.8513,  0.7765],\n",
            "        [-2.5996,  0.5875, -1.7033, -1.7325,  3.7871, -0.5569, -1.0769,  2.0345],\n",
            "        [-2.2604,  0.6201, -0.6519, -1.3466,  2.4704, -0.4753, -0.8915,  1.3161],\n",
            "        [-2.0092,  1.3493, -1.2650, -1.7842,  2.1712, -0.7915, -1.0913,  2.2429],\n",
            "        [-2.7571,  4.1953, -2.0298, -1.2396,  1.6809, -1.2319, -2.7793,  1.3871],\n",
            "        [-2.8449,  1.5447, -2.2792, -2.4891,  3.9403, -0.8679, -1.6419,  1.9465],\n",
            "        [-0.8198, -0.4315,  0.5588,  0.2020,  0.2850,  1.4829, -0.6050, -0.3042],\n",
            "        [-2.5998,  2.6838, -1.2281, -1.8918,  1.9419, -0.3575, -1.3945,  1.1601],\n",
            "        [-2.6430,  1.2362, -2.0382, -2.0218,  3.7914, -0.6868, -1.2789,  1.7470],\n",
            "        [-2.5261,  0.4488, -1.9345, -1.3082,  3.3800, -0.7671, -1.1292,  2.5660],\n",
            "        [-2.3081,  0.2771, -0.7667, -1.1674,  2.7881,  0.3784, -0.6420,  0.7436]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1461,  1.0672,  0.0247, -1.1808,  1.1951,  0.9670, -0.8666, -0.3848],\n",
            "        [-2.8716,  0.6586, -1.9127, -1.2715,  2.8555, -1.3998, -1.4679,  3.4243],\n",
            "        [-1.6786,  0.1237, -0.8726, -1.6823,  2.7188,  0.2285, -1.0926,  1.3598],\n",
            "        [ 0.1454, -0.7501,  2.3690, -0.5356, -0.7141,  1.8194, -0.5401, -1.2307],\n",
            "        [-2.0729,  0.8767, -0.9410, -1.6046,  2.7494,  0.2022, -0.7147,  0.8648],\n",
            "        [-2.1194, -0.0917, -0.7193, -0.9772,  2.6884, -0.1508, -0.0961,  0.7713],\n",
            "        [-1.4092,  0.7000, -0.7914, -1.7099,  2.0459,  0.4959, -1.0142,  0.6117],\n",
            "        [-3.1724,  2.8901, -2.0581, -1.9290,  2.6283, -0.9326, -1.6575,  1.9742],\n",
            "        [-3.1115,  1.3481, -2.0473, -0.2988,  0.1282, -1.2551, -1.8567,  5.8525],\n",
            "        [-2.4836,  2.5018, -1.6829, -1.8916,  3.2579, -0.6351, -2.1073,  0.9584],\n",
            "        [-0.7298, -0.6437,  0.6438, -0.1861,  0.9848,  1.5061, -0.4822, -0.3896],\n",
            "        [-1.5903, -0.3545, -0.0869, -0.9499,  1.8832,  0.9322, -0.4495,  0.3482],\n",
            "        [-2.8918,  2.7327, -2.2389, -1.8746,  2.8833, -1.2053, -1.6753,  1.8673],\n",
            "        [-3.1738,  1.2693, -2.2359, -1.5012,  2.9748, -1.3218, -1.4854,  3.4178],\n",
            "        [-1.5167,  0.9530, -0.6057, -1.2456,  2.1885, -0.2823, -1.1544,  0.8572],\n",
            "        [-0.6790,  0.2438,  0.1733, -1.5200,  1.9116, -0.0886, -0.7663,  0.1364],\n",
            "        [-1.4169,  0.0903, -0.2427, -0.2876,  1.5628,  0.1922, -0.5322,  0.4089],\n",
            "        [-2.9633, -0.0639, -2.5562, -2.3634,  7.0064, -0.8924, -1.1754,  0.8196],\n",
            "        [-2.6677,  1.6391, -2.0159, -2.1410,  3.2398, -0.8641, -1.3211,  2.1233],\n",
            "        [-1.7188,  1.7582, -0.6824, -0.2366,  1.0538,  0.1188, -1.3007,  0.3191],\n",
            "        [-3.1721,  1.6928, -2.5704, -2.4851,  4.0987, -0.9260, -1.6211,  2.1638],\n",
            "        [-1.8880,  0.3472,  0.1138, -1.1549,  1.8701,  0.1831, -0.2751,  0.3065],\n",
            "        [-2.7010,  2.0219, -1.7710, -0.9406,  2.3295, -0.7669, -1.2023,  1.3924],\n",
            "        [ 1.1735, -0.5680,  0.8891, -1.1674,  0.3300,  1.3321, -0.7630, -0.8532],\n",
            "        [-1.6997, -0.1939, -0.8216, -1.6894,  3.1172, -0.2934, -0.5382,  0.8838],\n",
            "        [-1.8563, -1.1669, -1.6258, -1.6513,  7.1306, -0.4488, -1.4438, -0.0765],\n",
            "        [-1.2967, -0.1802, -0.1370, -0.3580,  1.4163,  1.2736, -0.6295,  0.0925],\n",
            "        [-2.0168,  0.3348, -0.6618, -1.3218,  0.5837,  6.1875, -1.3788, -0.4620],\n",
            "        [-2.0524,  0.2568, -1.3323, -2.0381,  3.7221, -0.0675, -0.9924,  1.4591],\n",
            "        [-2.6814,  1.1750, -1.1468, -1.2893,  2.3646, -0.5370, -0.5927,  1.4825],\n",
            "        [-3.0561,  0.0422, -1.8242, -1.8807,  4.6584, -0.2318, -0.4746,  1.1320],\n",
            "        [-2.5243,  0.5015, -1.5258, -1.8725,  3.2144, -0.7782, -1.0485,  2.5300]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3868, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.6862e+00,  6.2271e+00, -1.8821e+00, -2.2982e+00,  9.0072e-01,\n",
            "         -1.7804e+00, -1.9193e+00,  9.3565e-01],\n",
            "        [-1.7080e+00,  2.0740e+00, -4.2094e-01, -9.1970e-01,  7.4258e-01,\n",
            "          4.0260e-01, -1.0834e+00,  4.0838e-01],\n",
            "        [-9.8502e-01,  4.5842e-01,  1.1789e+00, -7.8332e-01,  1.2096e-01,\n",
            "          1.0965e+00, -1.9208e-01, -6.9796e-01],\n",
            "        [-2.6166e+00,  1.1543e+00, -2.0625e+00, -2.3477e+00,  3.6634e+00,\n",
            "          5.2116e-02, -1.3123e+00,  1.8958e+00],\n",
            "        [-2.8779e+00,  2.5437e+00, -2.2231e+00, -2.6105e+00,  2.3721e+00,\n",
            "         -9.3946e-01, -1.7412e+00,  2.7029e+00],\n",
            "        [-1.7777e+00,  3.6644e-01,  5.0223e-03, -1.5784e+00,  1.8744e+00,\n",
            "          1.2944e-01, -2.3906e-01,  1.0647e+00],\n",
            "        [-2.2067e+00,  3.4984e-01, -1.3379e+00, -2.0038e+00,  3.9732e+00,\n",
            "         -8.2753e-01, -8.1950e-01,  1.6333e+00],\n",
            "        [-2.4740e+00,  2.9696e-01,  5.2743e+00, -2.4494e+00, -7.9634e-01,\n",
            "          2.6408e-02, -6.9299e-01, -9.1078e-02],\n",
            "        [-6.9501e-01, -3.3545e-01,  1.6183e+00, -1.5006e+00,  2.5604e-01,\n",
            "          1.3995e+00, -1.0477e-01, -1.2093e-01],\n",
            "        [-1.7464e+00,  1.0236e+00, -1.3050e+00, -8.1048e-01,  2.0653e+00,\n",
            "         -2.7611e-01, -9.3077e-01,  1.3999e+00],\n",
            "        [-1.0755e+00, -3.5166e-01,  3.9694e-01, -1.0376e+00,  1.2636e+00,\n",
            "          1.4947e+00, -6.4234e-01, -3.4994e-02],\n",
            "        [-2.5948e+00,  8.8320e-01, -1.4434e+00, -1.9793e+00,  3.6131e+00,\n",
            "         -3.5860e-01, -4.7178e-02,  8.4830e-01],\n",
            "        [-1.1160e+00, -2.3110e-01, -4.2488e-01, -1.0553e+00,  2.4377e+00,\n",
            "          1.4315e+00, -1.4465e+00,  1.0305e-02],\n",
            "        [-2.8730e+00,  8.5098e-01, -1.9347e+00, -2.3798e+00,  4.1748e+00,\n",
            "         -1.0305e+00, -7.9943e-01,  1.9798e+00],\n",
            "        [-3.2385e+00,  4.5182e-01, -2.1679e+00, -2.3443e+00,  4.6135e+00,\n",
            "         -9.8371e-01, -5.0656e-01,  1.8951e+00],\n",
            "        [-6.9963e-01, -8.8296e-01,  1.2478e+00, -9.9496e-01,  3.7010e-01,\n",
            "          1.8369e+00, -1.5344e-01, -4.6906e-01],\n",
            "        [-2.6594e-01,  1.1760e-01,  7.4496e-01, -1.2179e+00,  6.2152e-01,\n",
            "          9.1869e-01, -7.3657e-01, -1.2127e-01],\n",
            "        [-2.0131e+00,  6.0739e-01,  4.2481e-02, -1.5473e+00,  1.8936e+00,\n",
            "          6.6187e-01,  6.1238e-03,  4.7806e-01],\n",
            "        [-1.0558e+00, -3.4407e-01,  1.4552e-02, -4.8128e-01,  1.3217e+00,\n",
            "          1.2268e+00, -4.5558e-01, -3.6277e-01],\n",
            "        [-1.3600e+00,  5.2088e-01, -7.2069e-01, -5.7925e-01,  1.2024e+00,\n",
            "          3.1408e-01, -3.9766e-01,  5.8312e-01],\n",
            "        [ 2.9723e-01, -7.9835e-01,  1.9721e+00, -1.5360e+00,  9.2851e-02,\n",
            "          1.8846e+00, -6.7064e-01, -5.1154e-01],\n",
            "        [-2.0817e+00,  5.2734e-01, -7.8072e-01, -1.0027e+00,  2.4220e+00,\n",
            "          1.1755e-01, -7.8448e-01,  6.3979e-01],\n",
            "        [-4.6302e-01,  4.2789e-02,  6.1225e-01, -6.6644e-01,  4.5596e-01,\n",
            "          1.2470e+00, -1.8541e-01, -7.2828e-01],\n",
            "        [-7.5597e-01, -5.8548e-01,  5.7734e-01, -1.4364e+00,  1.9805e+00,\n",
            "          3.9593e-01, -8.2809e-01,  2.4682e-01],\n",
            "        [-2.7517e+00,  1.9733e+00, -2.0993e+00, -1.8294e+00,  3.1926e+00,\n",
            "         -8.4991e-01, -1.4866e+00,  1.6685e+00],\n",
            "        [-3.2462e+00,  2.0587e+00, -2.7228e+00, -2.1957e+00,  3.5850e+00,\n",
            "         -1.3501e+00, -1.8425e+00,  2.5782e+00],\n",
            "        [-3.1420e+00,  1.3803e+00, -2.5525e+00, -2.5953e+00,  4.4049e+00,\n",
            "         -1.1511e+00, -1.1386e+00,  2.7126e+00],\n",
            "        [-2.6449e+00,  1.5968e+00, -1.7478e+00, -1.6790e+00,  2.7941e+00,\n",
            "         -6.6611e-01, -1.2310e+00,  2.2238e+00],\n",
            "        [-1.4905e+00, -9.1666e-01, -1.8881e+00, -1.7178e+00,  6.8074e+00,\n",
            "         -2.7851e-01, -1.2434e+00, -3.5149e-01],\n",
            "        [-2.8340e+00,  3.9374e+00, -1.7290e+00, -2.1205e+00,  1.9993e+00,\n",
            "         -8.9656e-01, -2.1968e+00,  1.2493e+00],\n",
            "        [-1.6843e+00,  8.1150e-01, -8.9154e-01, -9.9178e-01,  2.3081e+00,\n",
            "         -2.5229e-01, -9.2071e-01,  8.9659e-01],\n",
            "        [-2.3774e+00,  7.1689e-02,  4.8475e+00, -2.4138e+00, -9.3189e-01,\n",
            "          1.0434e+00, -5.2668e-01, -2.3595e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.7835,  4.2098, -2.3244, -2.2310,  2.3178, -1.0792, -2.3019,  1.6459],\n",
            "        [-2.3209,  0.3245, -0.3393, -1.3937,  1.6719,  0.1545, -0.4603,  1.5341],\n",
            "        [-2.8379,  0.7401, -1.3384, -1.0659,  2.7237, -0.8743, -0.5539,  2.3230],\n",
            "        [-0.7282,  0.6545, -0.0875, -0.5772,  1.2005,  0.4771, -1.1358, -0.1800],\n",
            "        [-1.5450, -0.0328, -1.3174,  4.4163,  0.1324, -0.0966, -1.2380, -0.2812],\n",
            "        [-1.8399,  0.6261,  0.0437, -1.9762,  1.5760,  0.2347, -0.6472,  1.0304],\n",
            "        [-2.0504,  2.7918, -1.1170, -0.4111,  0.7304, -0.0995, -1.4861,  0.4077],\n",
            "        [-1.7152,  0.0908, -0.3494, -0.3836,  1.9351,  0.3970, -0.6781,  0.5488],\n",
            "        [-3.2717,  1.8759, -2.5045, -2.4669,  4.2675, -1.1373, -1.4105,  1.9621],\n",
            "        [-1.7409,  0.4216, -0.7659, -1.7414,  2.5387,  0.5563, -0.9239,  0.9265],\n",
            "        [-1.4037, -0.4389, -0.0393, -0.4093,  1.7063,  0.5627, -0.2667,  0.0339],\n",
            "        [-1.3663,  0.1804,  0.7622, -0.9070,  0.8503,  1.0229, -0.4046, -0.0830],\n",
            "        [ 0.1189, -0.4808,  2.0297, -0.9378, -0.2902,  1.2292, -0.4392, -0.7778],\n",
            "        [-1.5889,  0.0486, -0.1128, -0.8177,  1.4524,  1.2213, -0.4821,  0.0389],\n",
            "        [-1.5708,  0.6265,  0.3130, -0.5620,  0.6791,  0.6082, -0.1770,  0.0964],\n",
            "        [-2.3271, -0.4176, -0.1018, -1.8686,  3.1223,  0.7686, -0.3169,  0.7194],\n",
            "        [-1.8687,  1.1968, -1.3499, -0.7686,  2.0546,  0.0948, -1.0888,  0.6007],\n",
            "        [-2.7755,  2.2908, -2.0253, -1.5873,  2.5384, -0.9050, -1.6223,  1.8176],\n",
            "        [-2.4705,  1.0848, -1.3270, -1.1811,  2.1053, -0.8525, -0.8149,  2.4121],\n",
            "        [-0.3370, -0.4520,  0.1419, -0.5196,  1.3427,  1.0571, -0.9005, -0.0481],\n",
            "        [-2.4759,  0.8485, -1.1897, -1.5474,  2.4878, -0.8201, -0.6709,  2.2430],\n",
            "        [-3.3560,  1.3029, -2.1430, -2.0443,  3.5151, -1.3750, -0.8886,  3.0064],\n",
            "        [-0.2799, -0.4717,  0.4874, -0.7781,  1.4199,  0.8787, -0.7999, -0.1346],\n",
            "        [-3.2629,  2.0821, -3.1219, -2.4921,  4.4433, -1.6036, -1.6453,  2.8335],\n",
            "        [-2.2692,  0.1885,  5.5000, -2.2267, -0.7343,  0.2928, -0.4530, -0.5790],\n",
            "        [-2.2433,  1.6474, -1.4434, -0.7000,  2.3268, -0.7021, -1.0813,  1.2608],\n",
            "        [-3.3813,  2.0815, -2.8617, -2.3562,  4.6792, -1.3965, -1.7502,  2.3819],\n",
            "        [-2.8878,  1.1535, -2.3488, -1.1295,  2.4391, -1.8134, -1.5305,  3.9119],\n",
            "        [-1.3344,  0.2141, -0.5910, -1.4331,  2.6721,  0.0381, -1.0914,  0.8007],\n",
            "        [-1.9984,  2.4136, -1.2746, -1.7694,  1.8161, -0.5558, -1.1893,  1.3054],\n",
            "        [-2.8370,  0.8733, -2.4288, -1.9527,  4.1958, -1.2194, -1.2733,  2.8379],\n",
            "        [ 0.2957, -0.0445,  0.5017, -0.1551,  0.0633,  1.6579, -0.6159, -0.8688]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1169, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.1999e-01, -1.7522e+00, -2.7023e-01, -1.1941e-01, -4.7179e-01,\n",
            "         -1.4567e+00,  6.8642e+00, -9.3570e-01],\n",
            "        [-2.8740e+00,  2.2659e+00, -2.6084e+00, -2.3635e+00,  3.9642e+00,\n",
            "         -1.1849e+00, -1.9291e+00,  2.0212e+00],\n",
            "        [-1.2037e+00, -9.2397e-01,  6.7634e-01, -5.3499e-01,  1.2326e+00,\n",
            "          5.9823e-01,  9.4436e-01, -2.4929e-01],\n",
            "        [-1.5761e+00, -1.3128e+00, -1.3285e+00, -1.5366e+00,  6.8201e+00,\n",
            "         -4.2306e-01, -8.6790e-01, -5.7664e-01],\n",
            "        [-1.6371e+00, -1.1568e-01,  1.0867e-01, -9.6539e-01,  1.5892e+00,\n",
            "          6.3529e-01, -3.1305e-01,  5.1835e-01],\n",
            "        [-2.3491e+00,  1.5886e+00, -2.2104e+00, -1.0967e-01,  2.5083e+00,\n",
            "         -6.2782e-01, -1.8725e+00,  9.8504e-01],\n",
            "        [-1.1275e+00, -1.1267e+00,  2.2880e+00, -1.4195e+00, -7.3375e-02,\n",
            "          1.9127e+00,  9.1034e-02, -5.4413e-01],\n",
            "        [-2.4067e+00, -1.6909e-01, -1.6039e+00, -1.6167e+00,  3.5096e+00,\n",
            "         -3.0872e-01, -3.9417e-01,  1.6499e+00],\n",
            "        [-1.4039e+00,  1.0210e+00,  5.2153e-01, -9.6462e-01,  6.1252e-01,\n",
            "          8.0681e-01, -2.0265e-01, -1.2699e-01],\n",
            "        [-1.8057e+00, -6.9352e-01,  6.4603e-01, -4.2702e-01,  2.1587e-02,\n",
            "          3.4515e-02,  3.9946e+00, -5.1927e-01],\n",
            "        [-3.0752e+00,  5.1816e+00, -1.9530e+00, -2.1229e+00,  1.6921e+00,\n",
            "         -1.1877e+00, -2.4893e+00,  7.4665e-01],\n",
            "        [-2.6938e+00,  1.0460e+00, -1.5831e+00, -9.5793e-01,  2.4290e+00,\n",
            "         -8.0474e-01, -9.6982e-01,  2.4922e+00],\n",
            "        [-1.2642e+00,  4.4711e-01, -5.7691e-01, -1.3066e+00,  2.2369e+00,\n",
            "          7.9387e-01, -1.0001e+00,  5.0786e-01],\n",
            "        [-1.9723e+00,  4.5827e-01, -1.3584e+00, -1.5953e+00,  2.9916e+00,\n",
            "         -4.2618e-02, -1.2059e+00,  1.6826e+00],\n",
            "        [-1.2538e+00, -1.1783e-01,  1.4184e+00, -6.7373e-01, -3.0553e-01,\n",
            "          2.0972e+00,  4.9730e-02, -5.0868e-01],\n",
            "        [-1.8620e+00, -2.5199e-01,  4.2503e-02, -1.6323e+00,  1.9383e+00,\n",
            "          9.9201e-02,  2.4430e-01,  1.0331e+00],\n",
            "        [-2.9478e+00,  8.2271e-01, -1.9850e+00, -1.6426e+00,  2.8553e+00,\n",
            "         -1.3474e+00, -1.6701e+00,  4.4191e+00],\n",
            "        [-1.4397e+00,  6.5359e-01, -3.1471e-01, -8.6693e-01,  1.8711e+00,\n",
            "         -1.0087e-01, -8.3028e-01,  4.8608e-01],\n",
            "        [-2.5385e+00,  4.0467e+00, -1.5200e+00, -1.4613e+00,  1.6114e+00,\n",
            "         -7.4609e-01, -2.1412e+00,  9.1397e-01],\n",
            "        [-2.7036e+00,  3.5234e+00, -1.3702e+00, -1.8934e+00,  1.7632e+00,\n",
            "         -5.4599e-01, -1.8866e+00,  9.7544e-01],\n",
            "        [-7.2792e-01, -7.6704e-01, -1.2347e-01, -1.3813e+00,  2.2365e+00,\n",
            "          9.1327e-01, -5.8380e-01,  4.4080e-01],\n",
            "        [-1.1214e+00,  2.4716e-01,  1.0762e-01,  6.5027e-01,  6.2526e-01,\n",
            "          7.9136e-01, -1.1307e-01, -5.1130e-01],\n",
            "        [-3.1633e-01, -6.4048e-02,  8.1860e-01, -7.2172e-01,  3.4647e-01,\n",
            "          1.2998e+00, -3.7087e-01, -4.1697e-01],\n",
            "        [-2.8198e+00,  6.5325e+00, -2.2612e+00, -2.5612e+00,  1.0882e+00,\n",
            "         -1.5701e+00, -1.9732e+00,  7.7096e-01],\n",
            "        [-2.7201e+00,  1.3884e+00, -1.8955e+00, -1.3699e+00,  1.7088e+00,\n",
            "         -1.1836e+00, -1.1737e+00,  3.9749e+00],\n",
            "        [-2.7218e+00,  3.5774e-01, -1.4918e+00, -1.0708e+00,  3.0718e+00,\n",
            "         -8.0541e-01, -5.6001e-01,  2.1729e+00],\n",
            "        [-1.1895e+00, -1.2503e-01, -3.8688e-01, -9.0341e-01,  1.8505e+00,\n",
            "          3.3232e-01, -6.8384e-01,  5.8536e-01],\n",
            "        [-2.7919e+00,  1.8285e+00, -1.9572e+00, -2.1035e+00,  3.9871e+00,\n",
            "         -9.8163e-01, -1.5203e+00,  1.4490e+00],\n",
            "        [-1.0068e+00, -1.6576e+00, -6.8227e-01,  1.1695e-01, -1.6756e-01,\n",
            "         -1.2819e+00,  6.8163e+00, -6.9916e-01],\n",
            "        [-9.3952e-01,  3.8248e-05, -2.9219e-01, -5.6377e-01,  1.4545e+00,\n",
            "          1.1524e+00, -8.1262e-01,  2.0262e-01],\n",
            "        [-1.8200e+00,  1.9398e+00, -7.6742e-01, -1.0698e+00,  1.7901e+00,\n",
            "         -2.9515e-01, -1.5407e+00,  8.8164e-01],\n",
            "        [-1.4667e+00, -1.0236e+00, -2.0637e+00, -2.0219e+00,  6.8376e+00,\n",
            "         -4.8472e-01, -1.2125e+00, -5.2867e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1063, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.6360,  6.3672, -1.5888, -2.1271,  0.6572, -1.4667, -1.7836,  0.6473],\n",
            "        [-2.6694,  0.2270, -1.7574, -1.3797,  3.4661, -0.7764, -0.7403,  2.0167],\n",
            "        [-2.8271,  1.3717, -2.3370, -2.7494,  4.6923, -0.3349, -1.5557,  1.2174],\n",
            "        [-2.4250,  1.4393, -0.9497,  0.0240,  1.8528, -0.6302, -0.9185,  0.9415],\n",
            "        [-2.6646,  0.1497, -2.1677, -1.9304,  3.5816, -1.0923, -1.3306,  3.5378],\n",
            "        [-2.2747,  0.9698, -2.1744, -1.7374,  1.5600, -1.9838, -1.1085,  5.7253],\n",
            "        [-1.5283, -0.0949, -0.3561, -1.4149,  2.6072, -0.2417, -0.6879,  0.7806],\n",
            "        [-3.0224,  0.2952, -1.5702, -1.1861,  3.0955, -0.7788, -1.0230,  2.7299],\n",
            "        [-3.1169,  3.8830, -2.6020, -2.4867,  2.7493, -1.3413, -2.5569,  1.8820],\n",
            "        [-1.1024, -0.5211,  0.3014, -0.6929,  1.6695,  0.4015, -0.3466,  0.4749],\n",
            "        [-3.0725,  0.8858, -2.1460, -2.2560,  4.3216, -0.9792, -1.2476,  2.2440],\n",
            "        [-2.9528,  2.2494, -2.0874, -1.8326,  2.4966, -1.2377, -1.8754,  3.1783],\n",
            "        [-1.1384, -0.1488,  0.4791, -0.8131,  0.2290,  1.2561, -0.9657,  0.7179],\n",
            "        [-2.3532,  0.7540, -1.3046, -1.2802,  2.7330, -0.6671, -1.1113,  2.0418],\n",
            "        [-1.3248, -0.2176, -0.1142, -1.6680,  2.1440, -0.0159, -0.2816,  0.6547],\n",
            "        [-1.4996, -0.1418, -0.5517, -1.7553,  2.6864,  0.3612, -0.2478,  0.2364],\n",
            "        [-1.8937,  2.1512, -0.5714, -0.7125,  1.2314, -0.3384, -1.2350,  0.7704],\n",
            "        [-2.6968,  2.6778, -1.5040, -1.4089,  1.8138, -1.1541, -1.4288,  1.7056],\n",
            "        [-1.4877,  0.1617, -0.8850, -1.1745,  2.3298,  0.1799, -0.3068,  0.6649],\n",
            "        [-1.8881,  1.4140, -0.7823,  0.3422,  1.4266, -0.4740, -1.0824,  0.6541],\n",
            "        [-0.9291, -0.9633,  1.6220, -0.7179, -0.0916,  2.1393,  0.0420, -0.5818],\n",
            "        [-0.0509, -0.5863,  0.5496, -0.7554,  0.9831,  0.7876, -0.3108, -0.2407],\n",
            "        [-0.2721, -0.9696,  1.1929, -1.0078,  1.1946,  0.7765, -0.4777, -0.0757],\n",
            "        [-2.4765,  3.1753, -1.5142, -1.0097,  1.5540, -0.7424, -1.9769,  0.5185],\n",
            "        [ 6.1072, -0.5085, -0.8119, -1.5439, -0.5267, -1.4885, -0.4748, -1.1423],\n",
            "        [-2.6542,  0.0274, -1.4191, -1.6781,  3.6529, -0.1583, -0.1577,  1.5119],\n",
            "        [-1.1667,  1.0073, -0.1998, -0.4492,  1.1331, -0.1622, -0.4235, -0.0263],\n",
            "        [-3.0022,  1.4039, -1.9370, -1.5653,  3.2927, -0.7773, -1.1435,  2.4327],\n",
            "        [-2.8278,  1.4717, -2.1670, -1.8866,  3.5064, -0.9362, -1.3351,  2.2465],\n",
            "        [ 0.3863, -0.8209,  1.0437, -1.1797,  0.6086,  1.0300, -0.2495, -0.6309],\n",
            "        [-2.9054,  1.4210, -2.2790, -1.8075,  3.1259, -1.2770, -1.4081,  2.9962],\n",
            "        [-1.6830,  0.6837, -0.7738, -0.7623,  2.2247, -0.1152, -0.8982,  0.7338]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5423, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.3024, -0.2224,  0.7680, -0.3494,  0.1683,  1.1704, -0.2812, -0.3579],\n",
            "        [-1.0509, -0.1760, -0.1000, -1.3179,  1.9919,  0.3312, -0.7953,  0.6447],\n",
            "        [-1.7237, -0.2967,  0.8249, -1.3454,  1.0587,  1.0136,  0.1885,  0.2988],\n",
            "        [-2.7571,  0.3038, -1.8636,  2.5674,  1.7464, -0.8288, -1.3111,  1.6935],\n",
            "        [-1.1954, -1.0261,  0.6028, -1.1686,  1.6743,  0.9792, -0.1103,  0.2333],\n",
            "        [-1.3513, -0.5172,  1.7114, -0.8964, -0.1944,  2.6862, -0.4067, -0.4329],\n",
            "        [-1.4460,  0.5712, -0.6094, -1.0009,  1.9528,  0.0184, -0.5109,  0.4768],\n",
            "        [-1.5232,  0.9361, -0.8872, -1.4948,  2.0010,  0.6823, -0.8098,  0.6297],\n",
            "        [-2.4411,  1.0131, -1.2497,  0.6243,  2.0167, -0.6904, -0.9344,  1.0712],\n",
            "        [-1.8989,  1.2035, -1.1059, -0.4624,  1.7705, -0.0145, -1.1128,  0.8367],\n",
            "        [-2.8418,  1.5383, -2.3153, -2.2031,  4.2208, -0.7001, -1.4788,  1.8397],\n",
            "        [-1.7272,  0.8305, -0.5170, -0.9214,  1.7005, -0.0799, -0.5303,  0.7300],\n",
            "        [-2.7011, -0.7842, -0.6686, -0.9384,  1.8498, -1.4006,  2.9360,  1.1581],\n",
            "        [-1.5680,  1.1020, -0.5518, -0.6842,  1.6431, -0.1303, -0.9184,  0.5725],\n",
            "        [-2.4521,  1.2090, -1.5537, -1.1932,  0.4994, -1.5213, -0.8500,  5.2991],\n",
            "        [-0.8651, -0.1409,  1.2147, -0.7397,  0.4042,  0.8901, -0.3371, -0.3490],\n",
            "        [-2.9224,  2.5630, -2.1813, -1.2853,  1.9886, -1.1945, -1.5633,  2.0316],\n",
            "        [-2.9065,  2.3023, -2.7719, -2.5877,  4.3452, -1.1053, -1.6361,  1.7570],\n",
            "        [-1.5649,  0.2890, -0.7492, -1.5867,  2.3315,  0.1561, -1.0064,  1.3051],\n",
            "        [-2.5972,  1.4829, -1.9653, -1.5302,  2.7263, -1.2484, -1.8246,  2.9775],\n",
            "        [-1.7281,  0.4611, -1.1183, -1.0006,  2.4830, -0.2380,  0.0486,  0.4839],\n",
            "        [-1.0192, -0.2490,  0.3669, -0.8636,  0.9825,  1.1500, -0.4566,  0.4381],\n",
            "        [-2.2126,  0.0248, -0.9364, -1.7849,  2.8110,  0.2603, -1.0262,  1.7668],\n",
            "        [-2.4136,  3.2370, -1.3146, -1.3493,  1.8421, -0.5431, -1.8944,  0.6771],\n",
            "        [-1.1921, -0.8698,  0.2987, -1.3089,  1.5465,  0.6953, -0.9351,  0.9870],\n",
            "        [-2.3828,  0.5111, -1.6037, -1.9610,  3.6692, -0.3683, -0.6600,  1.2120],\n",
            "        [-2.1872,  1.5891, -1.1759, -0.6777,  1.8851, -0.1280, -0.8637,  1.0878],\n",
            "        [-1.7786, -0.8355,  0.5943, -0.8902,  0.7406,  0.7827,  1.6286, -0.1547],\n",
            "        [-2.9616,  3.5578, -1.9364, -2.1361,  2.1819, -1.2047, -1.9034,  2.0465],\n",
            "        [-0.3685, -1.2586,  2.7196, -0.8341, -0.9939,  2.4365, -0.1432, -0.8871],\n",
            "        [-1.0402, -0.4388,  1.6480, -0.9479,  0.0510,  1.5483, -0.1445,  0.0543],\n",
            "        [-3.2830,  5.2646, -2.3153, -2.7087,  1.9546, -1.3525, -2.5759,  1.4097]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2348, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.7224,  0.5040, -1.7176, -1.4392,  3.8483, -0.6947, -1.0383,  1.8406],\n",
            "        [-2.8387,  0.3575, -1.9403, -1.7902,  3.9882, -0.8009, -0.8204,  2.4014],\n",
            "        [-1.7183, -0.0730, -0.5679, -1.2291,  0.3495,  6.1105, -0.9768, -0.3812],\n",
            "        [-2.7997,  3.2400, -1.3730, -0.7710,  1.5740, -0.4402, -1.9873,  1.3420],\n",
            "        [-0.9015, -0.8395,  1.3764, -0.2234,  0.0683,  1.7249,  0.4497, -0.9256],\n",
            "        [-1.2861, -0.3587,  1.0608, -0.8589, -0.1080,  2.1899, -0.2859, -0.2356],\n",
            "        [-2.6248,  2.0111, -2.2209, -1.4134,  2.7965, -1.2732, -1.5723,  2.3741],\n",
            "        [-1.6597,  0.6516,  0.0749, -0.8384,  0.9549,  0.9541, -0.1201,  0.0746],\n",
            "        [-0.0191, -0.5623,  0.3812, -0.2224,  0.9010,  1.1290, -0.9141, -0.2203],\n",
            "        [-2.5712,  0.6416, -1.9811, -1.3809,  3.5862, -0.5226, -1.0554,  1.9833],\n",
            "        [-0.0543,  0.9035, -0.0140, -0.4489,  0.5125,  0.1496, -0.4656, -0.8066],\n",
            "        [-2.7344,  1.1150, -1.7875, -1.4035,  2.8421, -0.6318, -1.1718,  2.2935],\n",
            "        [-0.6923,  0.4869,  0.3431, -0.5200,  0.7213,  0.2569, -0.3265, -0.0413],\n",
            "        [-1.3697, -0.4984,  0.8250, -0.5732,  0.3377,  1.9858,  0.0984, -0.6169],\n",
            "        [-1.3166, -0.2415,  0.9016,  1.6524, -0.4522,  0.8113, -0.3036, -0.4906],\n",
            "        [ 0.3043, -0.5768,  0.8577, -0.4828,  0.2126,  1.4684, -0.6167, -0.6688],\n",
            "        [-1.7709, -1.3893, -1.1281, -1.8354,  6.5749, -0.3927, -1.0168, -0.4713],\n",
            "        [-1.4954, -0.3193,  1.7168, -0.5783, -0.5714,  2.8155, -0.0665, -0.6221],\n",
            "        [-2.4255,  1.9035, -1.7294, -1.9738,  2.8431, -0.3076, -1.5944,  1.6701],\n",
            "        [-1.8651,  0.8175, -0.6962, -1.6606,  2.3376,  0.0381, -0.8547,  1.2930],\n",
            "        [-2.3517,  1.8121, -1.5230, -1.5368,  2.3547, -0.4252, -1.3956,  1.6889],\n",
            "        [ 0.3216, -0.8989,  1.5801, -1.1740, -0.3379,  1.3248, -0.9859,  0.4876],\n",
            "        [-1.1549, -0.4138,  0.0229, -0.2054,  0.8524,  1.2541, -0.6512,  0.6715],\n",
            "        [-2.5359, -0.0654, -2.3826, -3.1104,  6.7029, -0.4006, -0.8747,  0.9291],\n",
            "        [-2.2550,  0.4522, -1.0385, -0.5349,  2.4524, -0.2246, -1.0763,  1.3355],\n",
            "        [-2.4647,  0.4328, -1.5340, -1.2998,  3.0406, -0.7410, -0.9362,  2.4175],\n",
            "        [-3.0132,  1.2786, -2.2962, -2.3938,  4.8108, -0.8702, -1.3346,  1.0810],\n",
            "        [-0.6906, -0.8473,  0.8178, -1.5339,  1.4619,  0.8714, -0.1247, -0.1583],\n",
            "        [-3.6444,  1.9581, -2.6510, -1.5152,  3.5005, -1.6251, -1.7294,  3.2190],\n",
            "        [-1.6372,  0.0602, -0.3807, -1.3166,  2.0408,  0.1242, -0.6825,  1.0216],\n",
            "        [-0.6950, -1.2203,  0.4853, -0.1203,  0.7149,  2.2704, -0.9636, -0.5274],\n",
            "        [-3.1003,  2.8842, -2.0515, -1.6701,  2.8028, -0.9155, -1.7447,  1.6237]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8143,  0.9078, -2.7960, -1.7472,  3.1271, -1.6130, -1.4897,  4.4741],\n",
            "        [-0.1967, -1.1550,  1.0266,  0.0474,  0.2026,  2.2412, -0.8169, -0.6696],\n",
            "        [-1.4648,  0.8311, -0.6736, -0.9475,  1.9521, -0.3637, -1.0609,  1.1985],\n",
            "        [-0.3804, -0.4093,  1.5402, -0.9005,  0.7259,  0.5193, -0.4580, -0.1115],\n",
            "        [-2.4065,  1.2785, -1.7506, -1.7639,  3.0987, -0.7969, -1.4629,  2.4262],\n",
            "        [-1.6725,  0.5281, -0.4607, -0.2878,  1.0946,  0.2972, -0.6420,  0.7107],\n",
            "        [-2.9966,  1.4214, -1.4572, -1.3353,  1.1507, -0.6791, -1.8747,  4.2665],\n",
            "        [-0.4381,  1.9645,  0.0300, -0.8709,  0.3139, -0.1675, -1.2179,  0.2820],\n",
            "        [-0.2690, -0.6115,  0.6925, -1.3904,  0.9837,  1.1052, -0.5739, -0.1726],\n",
            "        [-2.9675,  1.5933, -2.2050, -2.6784,  5.0344, -0.2967, -1.4307,  1.0949],\n",
            "        [-1.2233,  0.0699,  0.9934, -1.3064,  0.4074,  1.1623, -0.4270,  0.4493],\n",
            "        [-3.1274,  5.4389, -2.1231, -2.4215,  1.5289, -1.7130, -2.0150,  1.0159],\n",
            "        [-0.2595,  0.3450,  0.0741, -0.4858,  0.7825,  1.2201, -1.1419, -0.3334],\n",
            "        [-2.2228,  1.0775, -1.4885, -0.7919,  2.7793, -0.1223, -1.0205,  1.0191],\n",
            "        [-1.8411,  0.1909, -0.4623, -0.8827,  1.9390, -0.1960, -0.7484,  1.5199],\n",
            "        [-2.5214,  0.4863, -1.8463, -1.5369,  3.1910, -0.6417, -1.4209,  2.6195],\n",
            "        [-1.9327,  0.1900, -0.2727, -0.8974,  0.1573,  6.0371, -1.1585, -0.5172],\n",
            "        [-1.6578, -0.1173, -0.6028, -0.2275,  2.0767, -0.2361, -0.3719,  0.7205],\n",
            "        [-1.9801,  0.7483, -0.9029, -0.8238,  1.8192, -0.4253, -0.5616,  1.3685],\n",
            "        [-2.2631,  2.8657, -1.0369, -0.9841,  1.3675, -0.4384, -1.8840,  0.9913],\n",
            "        [-2.5642,  0.6783, -1.6395, -1.6899,  3.3478, -0.7302, -1.0687,  2.3080],\n",
            "        [-0.2484, -0.5131,  1.5507, -0.1620, -0.6379,  2.0444, -0.2886, -0.8423],\n",
            "        [-1.4438, -1.4480, -1.4074, -1.7321,  6.5151, -0.2391, -1.2779, -0.7792],\n",
            "        [-2.4780, -0.0968, -0.9245, -1.2105,  2.6928, -0.1834, -0.8026,  2.0617],\n",
            "        [-1.4538, -0.3007, -0.1224, -0.5055,  1.9192,  0.7817, -0.4071,  0.2236],\n",
            "        [-0.3598, -0.5151,  1.0195, -0.5920, -0.1530,  3.3282, -0.8814, -0.8505],\n",
            "        [-1.4893, -0.0559,  0.4760, -0.3942, -0.1745, -0.6872,  4.6211, -0.1302],\n",
            "        [-1.1179, -0.6238, -0.0777, -1.0149,  2.0693,  0.4778, -0.3801,  0.6954],\n",
            "        [-1.1390, -0.9801,  1.2628,  1.6073, -0.1937,  1.1219, -0.0757, -0.6054],\n",
            "        [-1.2263, -0.4888, -0.2743, -1.2219,  2.4002,  0.6714, -0.5433,  0.3992],\n",
            "        [-2.1615,  2.4792, -0.7951, -1.4667,  1.4685, -0.3093, -0.8609,  0.5557],\n",
            "        [-2.5779,  0.7226, -0.6996, -1.0262,  2.1653,  0.1841, -0.6605,  1.3299]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.9211,  0.6362, -1.0163, -0.7365,  2.4908, -0.3115, -0.6094,  0.9463],\n",
            "        [-0.2732, -0.7294,  1.9194, -0.6769, -0.2911,  2.1028, -0.1896, -0.7028],\n",
            "        [-2.1466,  0.4454, -0.5993, -1.6519,  2.8539,  0.4097, -1.0033,  0.7357],\n",
            "        [-0.4289, -0.7877,  1.5664, -0.7411,  0.9378,  0.7131, -0.5672, -0.1463],\n",
            "        [-2.5308,  0.7164, -1.7616, -2.2236,  4.1034, -0.0192, -0.9262,  0.9289],\n",
            "        [-2.9764,  0.4249, -2.0168, -1.1073,  3.0779, -1.1385, -1.2862,  3.4305],\n",
            "        [-1.6685, -0.1892, -0.4844, -0.7096,  2.1933,  0.0738, -0.5802,  0.8340],\n",
            "        [-1.0136, -0.3633,  0.8901, -0.3265,  0.6101,  1.4016, -0.3529, -0.1358],\n",
            "        [ 0.3623, -0.9108,  0.2184, -1.2188,  1.5548,  1.4122, -1.3484, -0.3315],\n",
            "        [-1.4444, -0.1096, -0.8378, -0.3271,  1.9127,  0.2039, -0.8122,  0.6189],\n",
            "        [-2.4538,  0.7792, -0.8661, -0.4319,  1.8976,  0.0841, -0.7903,  0.9694],\n",
            "        [ 1.0640, -0.4779,  1.3008, -0.8937, -0.4399,  1.5544, -0.3963, -0.8376],\n",
            "        [-1.2798,  0.3957, -0.3698, -0.9195,  1.5412,  0.1809, -0.9544,  0.8689],\n",
            "        [-1.6806, -1.4097, -0.2893,  0.0339, -0.1628, -0.8425,  6.7497, -0.5974],\n",
            "        [-3.2070,  1.7042, -2.1113, -1.8923,  3.5211, -0.8670, -0.9759,  2.0764],\n",
            "        [-1.3398, -0.2405,  1.0877, -0.1038,  0.2131,  1.8192, -0.0372, -0.5934],\n",
            "        [-1.4372, -0.3125,  0.4595, -0.7721,  1.6740,  0.6967,  0.0122,  0.2863],\n",
            "        [-0.8777, -0.2661, -0.1843, -0.9307,  1.2206,  1.0873, -1.3749,  0.2875],\n",
            "        [-2.6259,  1.2067, -1.4885, -0.2906,  1.5702, -0.7867, -1.3150,  2.2536],\n",
            "        [-2.6104,  0.7422, -2.3650, -1.2165,  1.2345, -1.5247, -1.3311,  5.3747],\n",
            "        [-0.1069, -0.2267,  0.4908,  0.2195,  0.2937,  1.5178, -0.4277, -0.8098],\n",
            "        [-2.6503,  2.6080, -1.1335, -0.8842,  1.4472, -0.2562, -1.4076,  1.3378],\n",
            "        [-1.2811,  0.0210, -0.3677, -0.3191,  1.5223,  0.4768, -0.8139,  0.4638],\n",
            "        [-1.0732, -0.0298,  1.3808, -0.8802,  0.0368,  0.7341, -0.0187,  0.3845],\n",
            "        [-2.5108,  3.8701, -1.3386, -2.1009,  1.2434, -0.4827, -1.7928,  1.1016],\n",
            "        [-1.5592,  0.6726, -0.3892, -1.4191,  2.0437,  0.0986, -0.7886,  0.6222],\n",
            "        [-2.5298,  2.4378, -1.5581, -1.0245,  1.6453, -0.9189, -1.6024,  1.9600],\n",
            "        [-2.7757,  4.2897, -1.8392, -1.4959,  1.9459, -1.0007, -2.1564,  1.1991],\n",
            "        [-1.9174, -0.3029,  0.8222, -0.5504,  1.4756,  0.5686,  0.5931, -0.0435],\n",
            "        [-2.9701,  2.1663, -2.2983, -2.7528,  4.5408, -0.6065, -1.7804,  1.3574],\n",
            "        [ 0.0971, -0.8357,  0.9854, -1.2141,  1.2071,  0.8470, -0.6503, -0.2946],\n",
            "        [-0.4034,  0.6678,  0.6050, -0.8831,  0.3979,  0.7543, -0.7657, -0.1718]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.3831e+00,  2.1319e+00, -1.9295e+00, -2.8280e-02,  1.4241e+00,\n",
            "         -9.9427e-01, -1.8029e+00,  1.7917e+00],\n",
            "        [-2.9405e+00,  3.2609e+00, -1.6896e+00, -1.3903e+00,  1.8122e+00,\n",
            "         -7.7248e-01, -1.8063e+00,  1.9189e+00],\n",
            "        [-2.7685e+00,  3.9723e+00, -1.3407e+00, -1.9372e+00,  1.5383e+00,\n",
            "         -7.0628e-01, -1.9074e+00,  9.7871e-01],\n",
            "        [-2.4418e+00, -5.1060e-01, -7.1683e-01, -1.8496e+00,  4.1072e+00,\n",
            "          4.8742e-01,  7.1803e-02,  4.4876e-01],\n",
            "        [-1.4899e+00,  1.5255e-01, -2.0599e-01, -9.0878e-01,  1.6801e+00,\n",
            "          4.0282e-01, -3.3243e-01,  5.0545e-01],\n",
            "        [-1.0986e+00, -1.2975e-01,  1.1699e+00, -1.4228e+00,  5.8790e-01,\n",
            "          1.1311e+00, -2.5810e-01,  2.6441e-01],\n",
            "        [-2.9097e+00,  3.1254e+00, -1.6809e+00, -1.4912e+00,  1.7659e+00,\n",
            "         -9.3672e-01, -1.8552e+00,  1.8405e+00],\n",
            "        [-1.5298e+00, -4.4033e-01,  9.4008e-01, -9.3073e-01,  7.0379e-01,\n",
            "          5.7879e-01,  1.9581e+00, -1.2873e-01],\n",
            "        [-3.0846e-01, -8.3485e-01,  9.5224e-01, -3.5248e-01,  6.0474e-01,\n",
            "          1.4635e+00, -3.4187e-01, -3.2995e-01],\n",
            "        [-1.8842e+00,  1.2885e+00, -9.7622e-01, -5.3332e-01,  1.7452e+00,\n",
            "          1.3883e-01, -1.2119e+00,  7.2389e-01],\n",
            "        [-1.8788e+00, -1.6083e-01, -6.9904e-01, -9.2705e-01,  2.4704e+00,\n",
            "          4.2041e-01, -7.8883e-01,  1.1313e+00],\n",
            "        [-2.2717e+00,  1.9735e+00, -7.1384e-01, -5.5124e-01,  1.1919e+00,\n",
            "         -3.8257e-01, -1.0831e+00,  9.5576e-01],\n",
            "        [-2.4614e+00,  6.4056e+00, -1.7420e+00, -1.8240e+00,  4.6798e-01,\n",
            "         -1.8875e+00, -1.5688e+00,  7.3921e-01],\n",
            "        [-2.7350e+00,  1.9405e+00, -1.9438e+00, -1.7625e+00,  2.9522e+00,\n",
            "         -7.7417e-01, -1.5923e+00,  2.1054e+00],\n",
            "        [-1.2525e+00,  1.2744e+00, -3.3425e-01, -2.5050e-01,  6.0827e-01,\n",
            "          7.7352e-01, -1.2454e+00,  1.2321e-01],\n",
            "        [-1.0956e+00, -3.7261e-01,  6.1639e-01, -8.8275e-01,  1.1545e+00,\n",
            "          7.6052e-01, -4.0685e-01,  4.1241e-01],\n",
            "        [-2.7769e+00,  2.4977e+00, -1.5365e+00, -9.9934e-01,  1.8521e+00,\n",
            "         -8.4221e-01, -1.2708e+00,  1.4190e+00],\n",
            "        [-1.5069e+00, -4.9817e-01, -1.0372e-01, -1.2264e-02,  1.5180e+00,\n",
            "          1.3727e+00, -6.9195e-02, -4.1640e-01],\n",
            "        [-1.1469e+00, -2.1774e-01,  4.2687e-01, -6.2032e-01,  1.1511e+00,\n",
            "          1.2520e+00, -3.0071e-01, -1.0773e-02],\n",
            "        [-2.1989e+00,  3.0781e-01, -9.5079e-02, -1.4147e+00,  2.1098e+00,\n",
            "          5.0831e-01, -1.3486e-01,  8.3662e-01],\n",
            "        [-2.4991e+00,  1.9256e+00, -1.4408e+00, -1.5149e+00,  2.5027e+00,\n",
            "         -4.0034e-01, -7.9959e-01,  1.3509e+00],\n",
            "        [-5.9720e-01, -3.4440e-01,  2.9815e-01, -1.0777e+00,  1.3229e+00,\n",
            "          6.6966e-01, -4.7235e-01,  3.2535e-01],\n",
            "        [-1.5158e-01, -1.6906e-01,  7.4772e-01,  1.6701e-02,  1.5755e-01,\n",
            "          1.3732e+00, -7.7967e-01, -6.7997e-01],\n",
            "        [-1.9312e+00, -1.1410e+00, -1.8713e+00, -2.0971e+00,  7.0598e+00,\n",
            "         -1.7902e-01, -9.2934e-01, -2.7162e-01],\n",
            "        [ 3.8583e-02, -4.2727e-01,  1.0495e+00, -1.1687e+00,  6.1437e-01,\n",
            "          1.2549e+00, -6.7201e-01, -2.7165e-01],\n",
            "        [-1.5230e+00,  4.9290e-01, -4.6944e-01, -8.2383e-01,  2.0357e+00,\n",
            "          2.8326e-01, -9.9790e-01,  4.8380e-01],\n",
            "        [ 9.6666e-02, -5.2012e-01,  6.8587e-01, -1.2498e+00,  8.6859e-01,\n",
            "          7.6875e-01, -8.4345e-01,  4.0336e-01],\n",
            "        [-2.5955e+00, -3.3561e-01, -3.7339e-01, -2.0089e+00,  2.9593e+00,\n",
            "         -1.5988e-01, -3.6855e-01,  2.2285e+00],\n",
            "        [-4.7672e-01, -7.3593e-01,  1.6592e+00, -9.2268e-01,  2.5012e-01,\n",
            "          1.2347e+00,  3.3006e-03, -6.0411e-01],\n",
            "        [-1.3103e+00, -8.5957e-01,  1.7553e+00, -4.6189e-01, -3.5179e-01,\n",
            "          2.7592e+00, -6.5233e-02, -4.6603e-01],\n",
            "        [ 7.5575e-01, -4.2073e-01,  1.0345e+00, -7.2264e-01, -1.6738e-01,\n",
            "          1.5251e+00, -5.6321e-01, -7.6104e-01],\n",
            "        [-1.0484e+00, -8.4817e-01,  3.0993e-01, -5.2105e-01,  1.2057e+00,\n",
            "          1.5601e+00, -8.8913e-01,  3.1905e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.8361e+00,  1.6012e+00, -2.3300e-01, -1.2116e+00,  1.2121e+00,\n",
            "          7.6548e-01, -1.1251e+00,  4.9232e-01],\n",
            "        [-1.3027e+00, -9.3874e-01, -2.2502e-01, -1.6140e+00,  2.7480e+00,\n",
            "          4.0251e-01, -6.1438e-01,  1.0646e+00],\n",
            "        [-2.9312e+00,  6.0101e+00, -1.6085e+00, -2.4669e+00,  6.6468e-01,\n",
            "         -1.2538e+00, -1.8553e+00,  9.3328e-01],\n",
            "        [-1.6248e+00,  1.4236e-01,  1.3853e+00, -7.7976e-01, -6.8510e-02,\n",
            "          1.5570e+00, -7.2625e-03, -1.7697e-01],\n",
            "        [-1.3925e+00, -3.8649e-01,  1.2830e+00, -5.3166e-01,  4.2593e-01,\n",
            "          1.2108e+00,  3.2695e-02, -5.3774e-02],\n",
            "        [ 6.1765e-02, -9.6673e-01,  1.3180e+00, -1.1033e+00,  1.1788e+00,\n",
            "          7.9599e-01, -6.5947e-01, -1.8416e-01],\n",
            "        [-1.9352e+00,  8.4560e-01, -3.1085e-01, -6.1403e-01,  1.4736e+00,\n",
            "          3.9125e-01, -8.2551e-01,  5.6515e-01],\n",
            "        [-1.7451e+00, -1.0949e-01,  9.3788e-02, -1.1267e+00,  1.7703e+00,\n",
            "          5.3921e-01, -6.4485e-01,  8.7560e-01],\n",
            "        [-1.8275e+00, -1.1230e+00, -1.3007e+00, -1.7537e+00,  6.8860e+00,\n",
            "         -5.7237e-01, -9.9018e-01, -3.3243e-01],\n",
            "        [-1.9739e+00,  1.0440e-01, -6.6314e-01, -1.4044e+00,  2.6805e+00,\n",
            "         -9.0886e-02, -9.4802e-01,  1.0919e+00],\n",
            "        [-1.8219e+00, -9.1434e-01, -1.6427e+00, -2.3914e+00,  7.0221e+00,\n",
            "         -1.1736e-01, -7.4425e-01, -1.5521e-01],\n",
            "        [-2.2723e+00,  4.1383e-01, -7.2214e-01, -9.3234e-01,  2.3982e+00,\n",
            "         -1.5621e-01, -4.2717e-01,  1.0398e+00],\n",
            "        [-2.4787e+00,  4.0742e+00, -1.3847e+00, -1.1937e+00,  1.3017e+00,\n",
            "         -5.5923e-01, -2.4232e+00,  8.7074e-01],\n",
            "        [-2.7705e+00,  3.2920e+00, -1.6332e+00, -2.1281e+00,  2.1758e+00,\n",
            "         -7.5750e-01, -2.0084e+00,  1.7395e+00],\n",
            "        [ 3.3622e-01, -1.3595e-03,  8.7086e-01, -3.6948e-01,  1.2760e-01,\n",
            "          1.2667e+00, -1.0475e+00, -6.5724e-01],\n",
            "        [-1.1524e+00, -1.1515e+00,  1.4019e+00,  1.1701e+00, -6.8491e-01,\n",
            "          1.7583e+00, -1.9486e-01, -7.9205e-01],\n",
            "        [-2.1133e+00,  2.6424e+00, -4.7351e-01, -1.5543e+00,  1.0040e+00,\n",
            "         -5.2547e-02, -1.6039e+00,  1.0515e+00],\n",
            "        [-2.4932e+00,  3.3257e+00, -1.4292e+00, -1.6640e+00,  1.7098e+00,\n",
            "         -5.5391e-01, -1.6103e+00,  1.1273e+00],\n",
            "        [-1.3323e+00,  6.8054e-01, -1.3840e-01, -9.0643e-01,  1.1923e+00,\n",
            "          3.2656e-01, -1.0148e+00,  7.6899e-01],\n",
            "        [ 5.9629e-02, -4.3946e-01,  1.2979e+00, -9.0525e-01,  3.6317e-01,\n",
            "          9.8351e-01, -1.9912e-01, -4.9712e-01],\n",
            "        [-2.6857e+00,  7.6373e-01, -1.8189e+00, -1.1545e+00,  3.1044e+00,\n",
            "         -1.0505e+00, -1.2381e+00,  1.9580e+00],\n",
            "        [-2.5643e+00,  1.3392e-01, -1.0453e+00, -1.2467e+00,  2.2680e+00,\n",
            "          2.9044e-02, -1.1142e+00,  2.2478e+00],\n",
            "        [-1.9538e+00,  5.1853e-01,  4.4107e-01, -8.7077e-01,  1.2464e+00,\n",
            "          5.6398e-01, -3.5769e-01,  2.4461e-01],\n",
            "        [-1.1893e+00, -1.1808e-01, -3.8809e-01, -1.2139e+00,  2.0658e+00,\n",
            "          7.7287e-01, -8.6151e-01,  5.1189e-01],\n",
            "        [-2.5650e+00,  1.6797e-01, -1.4999e+00, -1.3484e+00,  2.4719e+00,\n",
            "         -7.5663e-01, -1.3235e+00,  4.1275e+00],\n",
            "        [-2.4339e+00, -5.7937e-01,  8.4313e-02, -1.3440e+00,  2.7714e+00,\n",
            "          3.5335e-01, -1.2504e-01,  8.0815e-01],\n",
            "        [-3.3610e+00,  6.2794e+00, -1.9329e+00, -2.5613e+00,  1.1514e+00,\n",
            "         -1.4909e+00, -2.0812e+00,  8.1932e-01],\n",
            "        [-2.0738e+00, -2.5774e-01, -1.0890e+00, -1.1992e+00,  2.9050e+00,\n",
            "          1.6909e-01, -9.5530e-01,  1.4157e+00],\n",
            "        [-4.5551e-01,  3.5909e-02,  7.2609e-01, -4.6294e-01,  1.8015e-01,\n",
            "          1.5085e+00, -3.2710e-01, -2.9512e-01],\n",
            "        [-1.1645e+00, -2.9036e-02,  1.3979e-01,  9.7799e-03,  1.2074e+00,\n",
            "          6.1828e-01, -5.5777e-01, -8.7903e-02],\n",
            "        [-1.2838e+00, -1.4941e-01,  5.1203e-01, -6.8120e-01,  9.5713e-01,\n",
            "          1.3513e+00, -8.2161e-01,  2.1006e-01],\n",
            "        [-1.7417e+00, -1.5126e+00, -2.4475e-01, -3.7610e-01, -2.0591e-01,\n",
            "         -8.6755e-01,  6.6637e+00, -2.6076e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.8983, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8408e-02,  6.3217e-02,  1.1233e+00,  2.1961e-01, -5.2711e-01,\n",
            "          1.5438e+00, -1.8421e-01, -1.0519e+00],\n",
            "        [-1.5565e+00, -1.2615e+00, -1.2866e+00, -1.9323e+00,  6.6087e+00,\n",
            "          3.5079e-02, -1.0650e+00, -5.8068e-01],\n",
            "        [-2.5042e+00,  3.8084e+00, -1.4963e+00, -1.8730e+00,  1.3936e+00,\n",
            "         -7.8174e-01, -2.0263e+00,  1.0156e+00],\n",
            "        [-2.0023e+00, -2.0911e-01, -2.6471e-01, -7.0136e-01,  1.8473e+00,\n",
            "          1.0486e+00, -8.1820e-01,  1.0541e+00],\n",
            "        [-1.0231e+00, -5.1461e-01,  1.1983e+00, -6.4037e-01,  2.8043e-01,\n",
            "          1.9857e+00, -1.6925e-01, -5.9209e-01],\n",
            "        [-1.4085e+00, -5.7277e-01,  2.0341e+00, -1.0378e+00, -4.7219e-01,\n",
            "          2.1158e+00, -1.3008e-01, -9.4114e-02],\n",
            "        [-1.8660e+00, -3.2276e-01, -5.8196e-01, -1.4006e+00,  2.6123e+00,\n",
            "          2.5940e-02, -1.4277e-01,  1.3478e+00],\n",
            "        [-1.8324e+00,  1.2502e+00, -6.9517e-01, -1.1254e+00,  1.6867e+00,\n",
            "          1.8192e-01, -9.7740e-01,  8.5448e-01],\n",
            "        [-2.8425e+00,  3.7948e+00, -1.8931e+00, -2.1936e+00,  2.1928e+00,\n",
            "         -5.3401e-01, -2.2031e+00,  1.5000e+00],\n",
            "        [-1.6064e+00,  6.2569e-01, -8.4198e-01, -1.0872e+00,  1.7620e+00,\n",
            "          1.8057e-01, -6.7177e-01,  8.8155e-01],\n",
            "        [-2.5502e+00, -4.2477e-01, -2.0106e+00, -2.8412e+00,  6.3019e+00,\n",
            "         -1.1734e-02, -1.1593e+00,  8.2165e-01],\n",
            "        [-2.2349e+00,  1.2316e+00, -1.1917e+00, -2.8097e-01,  2.2262e+00,\n",
            "         -3.8512e-01, -1.0463e+00,  9.4253e-01],\n",
            "        [-2.7536e+00,  1.3001e+00, -1.6694e+00, -1.1702e+00,  2.6717e+00,\n",
            "         -7.4664e-01, -1.2550e+00,  2.1586e+00],\n",
            "        [-1.3635e+00, -6.6006e-01,  4.7601e-01, -4.0575e-01,  1.2190e+00,\n",
            "          1.0133e+00, -8.9801e-02,  2.0161e-01],\n",
            "        [-2.4096e+00,  3.5492e-01, -6.2743e-01, -2.0932e+00,  3.0390e+00,\n",
            "         -5.3521e-02, -5.2122e-01,  1.3611e+00],\n",
            "        [-2.0275e+00, -1.1817e-02, -5.3791e-01, -1.2800e+00,  1.7443e+00,\n",
            "         -2.8971e-03, -9.6031e-01,  2.5715e+00],\n",
            "        [-2.3104e+00,  4.0106e+00, -1.5249e+00, -1.2279e+00,  1.1424e+00,\n",
            "         -5.9019e-01, -2.1709e+00,  5.9102e-01],\n",
            "        [-1.5394e+00, -1.3043e-01,  8.6278e-02, -5.3451e-01,  1.7736e+00,\n",
            "          1.0060e+00, -7.4215e-01,  3.5456e-01],\n",
            "        [-2.2920e+00, -3.1203e-01, -1.0042e+00, -1.5367e+00,  3.8077e+00,\n",
            "         -8.7295e-02, -3.3110e-01,  1.0299e+00],\n",
            "        [-9.7778e-01, -6.1429e-01,  1.6622e+00, -9.3219e-01, -9.7406e-02,\n",
            "          1.5409e+00, -2.2525e-01,  5.3276e-02],\n",
            "        [-4.9483e-01, -6.2521e-01,  7.7332e-01,  1.6523e-01,  9.1337e-01,\n",
            "          3.5303e-01, -2.3869e-01, -2.7757e-01],\n",
            "        [-2.2773e+00,  3.1010e+00, -1.4206e+00, -1.7666e+00,  1.7776e+00,\n",
            "         -7.0606e-01, -2.0829e+00,  1.6773e+00],\n",
            "        [-2.8862e+00,  6.1066e-01, -1.7373e+00, -2.2444e+00,  4.3665e+00,\n",
            "         -5.1550e-01, -3.9682e-01,  1.3563e+00],\n",
            "        [-1.0096e+00,  3.2152e-02, -2.5346e-01, -7.4701e-01,  1.8683e+00,\n",
            "          4.1161e-01, -8.3413e-01,  5.2703e-01],\n",
            "        [-1.4288e-02, -6.6069e-01,  6.9901e-01, -3.3973e-01,  8.4085e-01,\n",
            "          1.7880e+00, -9.1215e-01, -6.0829e-01],\n",
            "        [-1.5829e+00,  3.9623e-01,  2.0796e-01, -1.3975e+00,  1.3027e+00,\n",
            "         -3.1867e-01, -5.6278e-01,  1.1252e+00],\n",
            "        [-1.7784e+00, -6.2795e-02,  9.2760e-01, -8.4058e-01,  5.6621e-01,\n",
            "          1.5790e+00, -6.5556e-01,  3.7149e-01],\n",
            "        [-3.1960e+00,  2.6465e+00, -1.7138e+00, -1.2855e+00,  1.3837e-01,\n",
            "         -1.0549e+00, -1.7010e+00,  4.0831e+00],\n",
            "        [-1.0091e+00,  7.9966e-01,  7.2413e-01, -1.2293e+00,  5.1705e-01,\n",
            "          1.2436e+00, -1.0714e+00, -3.5066e-02],\n",
            "        [-3.0074e+00,  2.4749e+00, -1.0481e+00, -2.2629e+00,  1.8728e+00,\n",
            "         -4.1178e-01, -1.3398e+00,  1.9537e+00],\n",
            "        [-4.8814e-01, -3.9695e-01,  1.5143e+00, -4.4036e-01, -2.0432e-01,\n",
            "          2.1110e+00, -4.3989e-01, -5.6695e-01],\n",
            "        [-2.0019e+00, -7.7575e-01, -1.9377e+00, -2.5009e+00,  7.0514e+00,\n",
            "         -3.5528e-01, -1.0720e+00,  8.1269e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2104, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8658e-01, -3.2802e-01,  4.1206e+00, -2.0872e+00, -1.4406e+00,\n",
            "          2.3775e+00, -7.5096e-01, -7.5460e-01],\n",
            "        [-2.6057e-01, -5.0016e-01,  1.1383e+00, -6.5557e-01,  2.3795e-01,\n",
            "          1.4916e+00, -7.1412e-01, -1.1750e-01],\n",
            "        [-4.3991e-01, -6.6474e-01,  2.2002e+00, -1.0684e+00, -4.1650e-01,\n",
            "          2.4986e+00, -6.3795e-01, -6.6934e-01],\n",
            "        [-2.7006e+00,  3.6312e+00, -1.2953e+00, -2.1973e+00,  1.6647e+00,\n",
            "         -5.2374e-01, -1.8007e+00,  1.2675e+00],\n",
            "        [-1.1808e+00,  1.4756e+00, -2.5655e-01, -7.6634e-01,  1.0376e+00,\n",
            "          1.2521e-01, -1.3603e+00,  3.8425e-01],\n",
            "        [ 4.1988e-02,  9.5037e-01,  6.5081e-01, -4.7739e-01, -2.3810e-01,\n",
            "          9.6774e-01, -3.6535e-01, -8.4636e-01],\n",
            "        [-2.9718e+00,  4.7376e+00, -1.5877e+00, -2.1750e+00,  1.3252e+00,\n",
            "         -1.0807e+00, -1.9578e+00,  9.8531e-01],\n",
            "        [-6.5954e-01, -2.0729e-01,  2.5122e-01, -6.9407e-01,  1.1742e+00,\n",
            "          1.4493e+00, -9.0118e-01,  4.5620e-03],\n",
            "        [-1.2128e+00, -5.9120e-01,  2.1107e-01, -2.9260e-01,  1.6349e+00,\n",
            "          2.4705e-01,  1.9115e-01,  1.2750e-01],\n",
            "        [-2.4554e+00,  6.9969e-01, -9.5474e-01, -1.8413e+00,  2.8758e+00,\n",
            "         -1.0077e-01, -8.4270e-01,  1.3976e+00],\n",
            "        [-2.7779e+00,  1.5958e+00, -1.7828e+00, -1.5687e+00,  2.2722e+00,\n",
            "         -1.1095e+00, -1.8721e+00,  3.2188e+00],\n",
            "        [-1.8110e+00,  1.1442e+00, -5.2932e-01, -1.6054e+00,  1.5786e+00,\n",
            "          5.7108e-01, -9.7614e-01,  9.1324e-01],\n",
            "        [ 3.7990e-02, -3.2162e-01,  6.9678e-01, -1.2486e+00,  9.2763e-01,\n",
            "          1.6178e+00, -8.4846e-01, -4.2827e-01],\n",
            "        [-2.1390e+00,  2.7904e+00, -3.5085e-01, -1.5259e+00,  9.2360e-01,\n",
            "         -2.0341e-01, -8.7278e-01,  3.8065e-01],\n",
            "        [-2.3087e-01, -3.2386e-01,  1.5101e+00, -3.1345e-01, -4.1112e-01,\n",
            "          1.9789e+00, -3.1626e-01, -9.0954e-01],\n",
            "        [-2.2756e+00,  4.0783e-01, -5.2610e-01, -1.5537e+00,  2.6735e+00,\n",
            "         -5.6123e-02, -5.5444e-01,  1.2252e+00],\n",
            "        [-1.7606e+00,  4.4091e-01, -4.2674e-01, -7.7174e-01,  1.9210e+00,\n",
            "          6.7342e-01, -8.1272e-01,  5.9582e-01],\n",
            "        [-8.4082e-01,  5.4647e-01,  1.2220e-01, -4.2854e-01,  7.4339e-01,\n",
            "          9.2082e-01, -5.7541e-01, -1.8710e-01],\n",
            "        [-4.6252e-01,  1.3677e+00,  2.7899e-01, -2.8498e-01, -3.4038e-01,\n",
            "          1.3099e+00, -8.5368e-01, -5.1495e-01],\n",
            "        [-2.7976e+00,  2.3897e+00, -1.3685e+00, -2.9505e-01,  1.4127e+00,\n",
            "         -5.2264e-01, -1.3502e+00,  1.4958e+00],\n",
            "        [-1.1104e+00, -2.3294e-01, -5.2532e-02, -1.2974e+00,  1.9521e+00,\n",
            "          6.6339e-01, -6.6820e-01,  5.1761e-01],\n",
            "        [-1.8002e+00,  1.4658e-01, -1.0389e-01,  1.1487e+00,  1.0432e+00,\n",
            "          1.1034e-01, -4.6408e-01,  1.3580e-01],\n",
            "        [-1.9721e+00,  8.1481e-01,  3.1039e-01, -9.8489e-01,  5.4103e-01,\n",
            "          5.1609e-01, -1.1181e+00,  1.4693e+00],\n",
            "        [-4.2778e-01, -6.5245e-01,  6.8116e-01, -6.8947e-01,  1.3631e+00,\n",
            "          9.9845e-01, -5.3399e-01, -1.6345e-01],\n",
            "        [-2.5940e+00,  2.3965e+00, -1.1501e+00, -6.7122e-01,  1.4133e+00,\n",
            "         -6.0024e-02, -1.2633e+00,  1.0026e+00],\n",
            "        [-2.4373e+00,  3.5189e-01,  5.3236e+00, -1.9618e+00, -9.7368e-01,\n",
            "         -2.5214e-01, -9.2036e-01,  1.0971e-01],\n",
            "        [-2.4938e+00,  4.3565e+00, -1.2197e+00, -1.0220e+00,  7.1259e-01,\n",
            "         -6.4961e-02, -2.3221e+00,  2.9884e-01],\n",
            "        [-2.4662e+00,  2.9015e+00, -1.1326e+00, -2.0696e+00,  1.6031e+00,\n",
            "         -3.1453e-01, -1.9338e+00,  1.6005e+00],\n",
            "        [-6.7308e-01,  7.7794e-01,  9.4532e-03, -3.4883e-02,  5.6666e-01,\n",
            "          1.0776e+00, -1.0935e+00, -3.4300e-01],\n",
            "        [ 6.3175e+00, -2.0842e-01, -8.6425e-01, -1.1925e+00, -1.0285e+00,\n",
            "         -1.3222e+00, -1.0722e+00, -8.2758e-01],\n",
            "        [-1.4738e+00, -1.0635e-01,  2.4909e+00, -7.4396e-01, -7.3251e-01,\n",
            "          2.2456e+00, -4.5286e-02, -1.0059e+00],\n",
            "        [-1.3842e+00,  6.0237e-02,  4.0808e-01, -1.2298e+00,  7.2372e-01,\n",
            "          1.1005e+00,  4.2815e-01,  4.0484e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.2447e+00,  4.7150e-01, -1.0987e+00, -7.8464e-01,  1.8891e+00,\n",
            "         -9.1648e-01, -7.1750e-01,  2.6484e+00],\n",
            "        [-1.9298e+00, -8.1300e-01, -1.6245e+00, -2.1267e+00,  6.8821e+00,\n",
            "         -2.0804e-01, -1.0551e+00, -1.2749e-01],\n",
            "        [-2.3724e+00,  1.4073e-01, -1.2461e+00, -1.5324e+00,  3.0526e+00,\n",
            "          2.3851e-01, -8.3892e-01,  1.3205e+00],\n",
            "        [-5.1106e-03, -6.2109e-01,  1.0868e+00, -9.2136e-02, -1.2529e-01,\n",
            "          1.7466e+00, -4.5658e-01, -7.9227e-01],\n",
            "        [-9.3858e-01, -3.1548e-01,  1.3570e+00,  2.0672e-03,  2.6731e-01,\n",
            "          1.0402e+00, -1.8813e-01, -5.7339e-01],\n",
            "        [-5.7841e-01, -5.2948e-01,  9.9150e-01,  2.0612e+00, -6.2507e-01,\n",
            "          1.5008e+00, -4.1305e-01, -1.2782e+00],\n",
            "        [-2.8184e+00,  7.9648e-01, -1.3553e+00, -7.5544e-01,  2.0240e+00,\n",
            "         -6.6548e-01, -1.1493e+00,  2.6361e+00],\n",
            "        [-2.4021e+00,  4.9086e-01, -1.2474e+00, -6.7798e-01,  2.4074e+00,\n",
            "         -7.2976e-01, -1.2746e+00,  2.2453e+00],\n",
            "        [-3.2603e-01, -8.3716e-01,  8.7290e-01, -6.2569e-01,  1.2009e+00,\n",
            "          6.8753e-01, -8.7175e-01,  1.6553e-02],\n",
            "        [ 8.4204e-01, -5.4062e-01,  1.1230e+00, -8.8437e-01,  2.6057e-01,\n",
            "          1.2523e+00, -5.6900e-01, -7.7255e-01],\n",
            "        [-2.2527e+00,  8.9160e-01, -9.9435e-01,  1.0317e-02, -8.3780e-01,\n",
            "         -1.1186e+00, -1.0982e+00,  4.6623e+00],\n",
            "        [-1.7625e+00,  7.6339e-02,  2.1116e-01, -1.6859e+00,  1.8244e+00,\n",
            "          8.6901e-01, -6.3935e-01,  7.0557e-01],\n",
            "        [-7.1014e-02, -8.6266e-01,  6.4415e-01, -5.3986e-01,  1.0033e+00,\n",
            "          1.1698e+00, -1.2858e+00, -3.6968e-02],\n",
            "        [-4.2095e-01, -1.1119e-01,  4.1552e-01, -7.1661e-01,  1.0607e+00,\n",
            "          1.6151e+00, -5.7682e-01, -4.7824e-01],\n",
            "        [-2.6769e+00,  4.5034e-01, -1.5189e+00, -1.5984e+00,  3.2031e+00,\n",
            "         -5.8346e-01, -1.2493e+00,  2.4515e+00],\n",
            "        [-8.9733e-01,  6.8142e-01,  2.9825e-01,  8.9254e-02,  6.6731e-02,\n",
            "          8.1495e-01, -8.4571e-01,  9.7817e-02],\n",
            "        [-2.5656e-01, -2.2042e-01,  7.4010e-01, -1.1828e+00,  1.1067e+00,\n",
            "          8.1093e-01, -9.6162e-01, -5.6569e-03],\n",
            "        [-2.2081e+00,  3.5067e+00, -7.5651e-01, -1.2726e+00,  6.4240e-01,\n",
            "         -7.2488e-01, -1.6592e+00,  7.4692e-01],\n",
            "        [-2.6985e+00,  6.4784e+00, -1.8533e+00, -2.2250e+00,  4.7172e-01,\n",
            "         -1.1784e+00, -1.8121e+00,  4.5890e-01],\n",
            "        [-1.1691e+00,  6.9837e-01, -2.5933e-01, -1.3375e+00,  1.3952e+00,\n",
            "         -1.7663e-01, -1.0358e+00,  8.9078e-01],\n",
            "        [-1.3033e+00, -4.5641e-01,  1.8986e+00, -4.4230e-01, -3.3335e-01,\n",
            "          2.5530e+00, -1.0678e-01, -6.0017e-01],\n",
            "        [-1.6281e+00, -4.0352e-01,  7.8321e-01, -7.9514e-01,  6.5301e-01,\n",
            "          6.6108e-01,  8.9517e-01,  1.1235e-02],\n",
            "        [-2.1374e-01, -1.2230e+00,  1.3915e+00, -5.2080e-01,  2.2051e-01,\n",
            "          1.6797e+00, -5.2306e-01, -4.1517e-01],\n",
            "        [-1.6519e+00,  1.5675e+00, -8.4045e-01,  2.9535e-01,  1.1439e+00,\n",
            "         -3.0472e-01, -1.4501e+00,  5.9103e-01],\n",
            "        [-1.9845e+00,  5.9017e-01,  3.9911e-02, -1.0587e+00,  1.6381e+00,\n",
            "          4.4348e-01, -6.9736e-01,  5.5448e-01],\n",
            "        [-2.0149e+00,  2.3229e+00, -5.7956e-01, -6.0405e-01,  1.0969e+00,\n",
            "         -1.3807e-01, -1.1472e+00,  5.3496e-01],\n",
            "        [-4.5530e-01, -7.2082e-01,  1.3327e+00, -2.1258e-01, -3.4355e-01,\n",
            "          1.8540e+00, -1.3160e-01, -1.0014e+00],\n",
            "        [-1.5520e+00,  1.3875e-01, -6.0805e-01, -1.3999e+00,  1.0670e-01,\n",
            "          5.9747e+00, -1.2941e+00, -4.2956e-01],\n",
            "        [-2.5557e+00,  1.2200e+00, -1.6870e+00, -1.8563e+00,  2.9074e+00,\n",
            "         -3.8642e-01, -1.3948e+00,  2.1169e+00],\n",
            "        [-2.1379e+00,  5.1396e-02, -5.0434e-02, -8.3158e-01,  1.8506e+00,\n",
            "          5.8204e-01, -5.2690e-01,  8.0274e-01],\n",
            "        [-9.0647e-01, -1.7319e-01,  1.2341e+00, -1.1945e+00,  4.3451e-01,\n",
            "          1.0997e+00, -5.8092e-01,  3.6201e-01],\n",
            "        [-9.5978e-01,  1.7499e-01,  1.0287e+00, -5.8058e-01,  4.8610e-01,\n",
            "          9.6419e-01, -1.3858e-01, -5.7197e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.4210e+00,  3.3901e-01, -9.3490e-01,  4.1600e+00, -2.8168e-01,\n",
            "         -1.3215e-03, -1.1579e+00, -5.1497e-01],\n",
            "        [-1.2981e+00,  2.0020e-01,  6.2364e-01, -6.4608e-01,  4.3956e-01,\n",
            "          1.1400e+00,  2.6035e-02, -1.7362e-01],\n",
            "        [-2.3416e+00,  1.5719e+00, -1.2595e+00, -5.7290e-01,  1.8631e+00,\n",
            "         -7.2853e-01, -1.1898e+00,  1.6281e+00],\n",
            "        [-1.4559e+00,  3.2050e-01,  5.6157e+00, -2.3918e+00, -1.2364e+00,\n",
            "          9.5614e-01, -1.4514e+00, -2.3771e-01],\n",
            "        [-1.0960e+00,  3.3514e-01, -5.5278e-01, -1.7686e+00,  2.4475e+00,\n",
            "         -3.8513e-01, -1.5255e-01,  6.7177e-01],\n",
            "        [-3.1531e+00,  2.7607e+00, -2.3514e+00, -2.1443e+00,  2.8081e+00,\n",
            "         -1.0887e+00, -2.1722e+00,  2.8484e+00],\n",
            "        [-2.3399e+00,  1.0161e+00, -1.2738e+00, -8.5033e-02, -5.0081e-01,\n",
            "         -1.2719e+00, -7.0092e-01,  4.0876e+00],\n",
            "        [ 4.0685e-01, -2.9056e-01,  2.8010e+00, -1.6287e+00, -8.9635e-01,\n",
            "          1.2929e+00, -1.3763e+00, -3.2434e-01],\n",
            "        [-2.7938e+00,  3.2718e+00, -1.7158e+00, -1.7950e+00,  1.7749e+00,\n",
            "         -6.6198e-01, -2.0184e+00,  2.0773e+00],\n",
            "        [-8.8539e-01, -7.6131e-01,  3.3109e+00, -1.8903e+00, -5.0833e-01,\n",
            "          2.0649e+00, -8.2691e-01, -3.8002e-01],\n",
            "        [-2.1002e+00,  1.8668e+00, -7.1950e-01,  4.2713e-01,  1.1249e+00,\n",
            "         -3.1636e-01, -1.3964e+00,  5.6507e-01],\n",
            "        [-2.5599e+00,  1.9989e+00, -1.0428e+00,  2.4537e+00, -9.7239e-02,\n",
            "         -5.1573e-01, -2.8889e-01, -1.3877e-01],\n",
            "        [-1.3817e+00,  5.6529e-01,  3.4125e-01, -1.6406e+00,  1.2521e+00,\n",
            "          8.0164e-02, -8.6513e-01,  1.0899e+00],\n",
            "        [ 4.8060e-01, -9.8185e-01,  1.2134e+00, -7.3675e-01,  4.9644e-01,\n",
            "          1.4799e+00, -8.9297e-01, -5.6844e-01],\n",
            "        [-8.3406e-01, -4.1493e-01,  1.4216e+00, -8.6124e-01,  2.4311e-01,\n",
            "          1.4970e+00,  1.3666e-01, -4.5310e-01],\n",
            "        [-1.0776e+00, -5.4501e-01,  1.0899e+00, -7.8524e-01,  7.9897e-01,\n",
            "          1.4740e+00, -4.4313e-01, -2.3564e-01],\n",
            "        [-2.5504e+00,  2.5434e-02, -1.6245e+00, -1.8759e+00,  4.2232e+00,\n",
            "          1.4053e-01, -4.5133e-01,  1.2722e+00],\n",
            "        [-2.1751e+00,  1.5433e+00, -9.2567e-01, -1.2982e+00,  1.7238e+00,\n",
            "         -6.1212e-03, -1.1161e+00,  1.0960e+00],\n",
            "        [-7.9388e-01, -6.5259e-01,  7.4159e-01, -5.6374e-01,  9.9559e-01,\n",
            "          1.4021e+00, -5.5520e-01, -1.6358e-01],\n",
            "        [-1.3562e+00,  7.0506e-01, -5.6625e-02, -2.1262e-01,  1.0507e+00,\n",
            "          4.0071e-01, -1.0532e+00,  2.5122e-01],\n",
            "        [-2.4047e+00, -4.5935e-01, -1.6821e+00, -2.1066e+00,  6.7102e+00,\n",
            "          1.8438e-01, -1.0248e+00, -4.0178e-01],\n",
            "        [-1.7495e+00, -4.9612e-01,  4.7697e-03, -1.4321e+00,  1.9848e+00,\n",
            "          8.5016e-01, -5.7450e-01,  1.2988e+00],\n",
            "        [-1.8025e+00, -6.1636e-02, -8.3853e-02,  2.9713e+00,  7.5199e-02,\n",
            "         -1.1482e-01,  5.3979e-01, -7.0787e-01],\n",
            "        [-1.0443e+00,  2.8304e-01, -2.8878e-01, -3.7651e-01,  1.6452e+00,\n",
            "          3.6369e-01, -1.1779e+00,  2.7550e-01],\n",
            "        [ 4.1453e-01, -1.4229e-01,  1.5140e+00, -6.8626e-01, -5.5399e-01,\n",
            "          1.5382e+00, -4.5277e-01, -9.0900e-01],\n",
            "        [-2.8395e+00,  3.3350e+00, -1.5320e+00, -6.2066e-01,  7.2630e-01,\n",
            "         -8.2405e-01, -1.4841e+00,  1.7221e+00],\n",
            "        [-1.8612e+00, -2.0134e-01,  5.8176e-01, -1.1072e+00,  1.4347e+00,\n",
            "          9.6495e-01, -1.0471e-01,  5.5069e-01],\n",
            "        [-1.7928e+00,  1.1302e+00,  1.8129e-02, -6.3675e-01,  9.3425e-01,\n",
            "          2.8897e-01, -3.4361e-01, -4.7453e-02],\n",
            "        [-1.0492e+00, -7.8945e-02, -1.5264e-01, -9.7918e-01,  2.0476e+00,\n",
            "          1.0267e-01, -1.0695e+00,  6.4697e-01],\n",
            "        [-2.8874e+00,  4.8509e+00, -1.5081e+00, -2.5434e+00,  1.1427e+00,\n",
            "         -9.4451e-01, -2.3419e+00,  1.5185e+00],\n",
            "        [-1.7418e+00,  1.9557e+00, -6.2279e-01, -4.4757e-01,  1.4057e+00,\n",
            "         -1.7025e-01, -1.4781e+00,  5.2414e-01],\n",
            "        [-2.3042e+00, -5.1590e-01,  5.2345e+00, -2.6273e+00, -8.8544e-02,\n",
            "          7.3287e-01, -5.3253e-01,  1.8100e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9459, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6895e+00, -1.4096e+00, -1.4107e+00, -1.4920e+00,  6.6655e+00,\n",
            "         -4.5020e-01, -1.1499e+00, -1.8481e-01],\n",
            "        [-1.4058e+00, -1.6413e-01,  1.5146e+00,  1.4696e-01, -4.6914e-01,\n",
            "          1.8146e+00,  4.5095e-01, -7.8122e-01],\n",
            "        [-1.1675e-01, -7.3505e-01,  2.0434e+00, -4.1117e-01,  2.2006e-02,\n",
            "          1.3377e+00, -5.9207e-01, -7.2444e-01],\n",
            "        [-2.0337e+00,  5.0293e-02, -4.6826e-02, -3.5092e-01,  1.5768e+00,\n",
            "          6.1754e-01, -6.4965e-01,  9.2042e-01],\n",
            "        [-1.6585e+00, -3.6378e-01,  1.2476e+00, -7.5549e-01,  7.1907e-01,\n",
            "          9.9899e-01, -4.7473e-01,  1.9909e-01],\n",
            "        [-2.8060e+00,  1.2621e+00, -1.3546e+00, -1.7098e+00,  1.7694e+00,\n",
            "         -6.6219e-01, -1.5835e+00,  3.7470e+00],\n",
            "        [-2.8631e+00,  1.1721e+00, -2.1667e+00, -1.0842e+00,  8.6685e-01,\n",
            "         -1.8339e+00, -1.2590e+00,  5.5109e+00],\n",
            "        [-5.0398e-01, -9.6266e-01,  1.4897e+00, -5.0482e-01,  9.6121e-01,\n",
            "          9.7987e-01, -6.7134e-01, -3.0551e-01],\n",
            "        [-1.4093e+00,  1.8063e-03, -5.9409e-01, -1.4446e+00,  2.4071e+00,\n",
            "          6.9131e-01, -1.1820e+00,  7.5312e-01],\n",
            "        [ 1.2102e+00, -5.9450e-01,  1.7992e+00, -1.2331e+00, -4.1967e-01,\n",
            "          1.8610e+00, -8.7352e-01, -1.0104e+00],\n",
            "        [-6.2736e-01, -1.9088e-01,  1.4568e+00, -5.2022e-01, -1.3648e-01,\n",
            "          1.9980e+00, -6.1872e-02, -7.7343e-01],\n",
            "        [-3.1785e+00,  2.2236e+00, -1.9257e+00, -1.6020e+00,  2.6365e+00,\n",
            "         -1.0312e+00, -1.8123e+00,  2.4379e+00],\n",
            "        [-2.7215e+00,  3.6774e+00, -1.4135e+00, -1.6745e+00,  1.2797e+00,\n",
            "         -7.0641e-01, -1.7037e+00,  1.2994e+00],\n",
            "        [-7.7394e-01, -7.4702e-01,  8.1896e-01, -1.0728e+00,  1.7000e+00,\n",
            "          7.7143e-01, -6.2504e-01,  7.6048e-02],\n",
            "        [-1.7681e+00,  6.9295e-02, -1.8213e+00,  6.3825e+00, -5.4440e-01,\n",
            "         -1.0014e+00, -9.4830e-01, -4.9481e-01],\n",
            "        [-1.7226e+00,  5.2605e-01,  4.2490e-01, -1.4957e+00,  1.4617e+00,\n",
            "          1.3345e-01, -1.7873e-01,  3.0583e-01],\n",
            "        [-2.7139e+00,  1.1316e+00, -1.2413e+00, -9.4176e-01,  2.0716e+00,\n",
            "         -5.6904e-01, -1.1875e+00,  2.3281e+00],\n",
            "        [ 5.8722e+00, -6.5575e-01, -9.7540e-01, -1.3038e+00, -2.5961e-01,\n",
            "         -1.3258e+00, -6.6247e-01, -1.0596e+00],\n",
            "        [-3.3706e-01, -3.4641e-01,  5.4894e-01, -8.7076e-01,  1.2229e+00,\n",
            "          9.4954e-01, -1.4071e+00,  2.5480e-01],\n",
            "        [-2.7274e+00,  9.0782e-01,  5.1408e+00, -2.2824e+00, -5.8625e-01,\n",
            "          2.0039e-01, -5.8303e-01,  1.0841e-01],\n",
            "        [-4.2537e-01,  1.2590e+00,  3.6917e-01, -8.2456e-01, -9.3878e-03,\n",
            "          6.4483e-01, -8.0171e-01, -3.9246e-01],\n",
            "        [-2.3741e+00,  2.0902e+00, -9.7860e-01, -6.3017e-02,  1.1014e+00,\n",
            "          1.5403e-01, -1.0774e+00,  6.7020e-01],\n",
            "        [-1.2110e+00, -7.8566e-01,  9.0047e-01, -1.1633e+00, -1.6744e-01,\n",
            "          4.7014e+00, -1.3205e+00, -1.3223e-01],\n",
            "        [-3.1331e+00,  9.2591e-01, -1.6284e+00, -1.5412e+00,  2.8555e+00,\n",
            "         -1.0957e+00, -1.0110e+00,  3.1679e+00],\n",
            "        [-3.0638e+00, -4.4080e-01, -1.3516e+00, -2.3849e+00,  4.3175e+00,\n",
            "         -1.2398e-01, -3.8674e-01,  2.0058e+00],\n",
            "        [-2.1352e-01,  2.4104e-01,  3.8464e-01, -6.8287e-01,  1.0652e+00,\n",
            "          4.1208e-01, -1.2635e+00, -1.2562e-01],\n",
            "        [-1.8516e+00, -2.5202e-01, -1.2415e-02, -5.9816e-01,  1.7998e+00,\n",
            "          4.9124e-01, -5.8911e-01,  5.9558e-01],\n",
            "        [-1.7879e+00, -1.3170e-01, -5.0335e-01, -9.3578e-01, -1.2710e-02,\n",
            "          6.3147e+00, -1.1462e+00, -5.6713e-01],\n",
            "        [-2.2424e+00,  1.5320e-01, -1.3136e+00, -7.1838e-01,  2.4912e+00,\n",
            "         -6.5697e-01, -1.2857e+00,  2.0039e+00],\n",
            "        [-2.4709e+00,  3.1105e+00, -2.8105e-01, -1.6054e+00,  5.4925e-01,\n",
            "          2.5634e-01, -1.4203e+00,  4.4417e-01],\n",
            "        [-2.4269e+00,  1.7799e+00, -8.1595e-01, -7.6158e-01,  1.0760e+00,\n",
            "         -3.0656e-01, -8.0020e-01,  1.3994e+00],\n",
            "        [-2.9844e+00,  1.2944e+00, -2.3410e+00, -2.3413e+00,  4.7434e+00,\n",
            "         -3.7458e-01, -1.4970e+00,  1.7583e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.0971e+00,  2.5371e+00, -8.4900e-01, -6.2872e-01,  1.1757e+00,\n",
            "         -3.6670e-01, -1.0709e+00,  7.2040e-01],\n",
            "        [ 1.5617e-01,  2.7607e-01,  6.8159e-01, -6.2372e-01,  6.9984e-04,\n",
            "          1.0654e+00, -5.7136e-01, -4.1031e-01],\n",
            "        [-1.8419e+00, -8.7365e-01, -1.5305e+00, -2.2711e+00,  6.8904e+00,\n",
            "         -2.9210e-01, -1.0878e+00, -1.8266e-01],\n",
            "        [-8.5753e-01, -5.1457e-01,  1.4840e+00, -8.3075e-01,  1.2490e-01,\n",
            "          2.3221e+00, -5.2629e-02, -3.6041e-01],\n",
            "        [-1.7530e+00, -1.0788e+00, -1.4933e+00, -1.6715e+00,  6.7626e+00,\n",
            "         -6.4290e-01, -1.0609e+00, -4.1190e-01],\n",
            "        [-1.8661e+00,  1.5827e+00, -5.8458e-01, -5.4058e-01,  1.1748e+00,\n",
            "          1.2564e-01, -9.4479e-01,  8.0269e-01],\n",
            "        [-2.6645e+00,  5.1784e+00, -1.5404e+00, -2.2425e+00,  1.0302e+00,\n",
            "         -1.2426e+00, -2.1341e+00,  1.2593e+00],\n",
            "        [-2.5056e+00,  2.6793e+00, -9.9887e-01, -8.9965e-01,  1.5068e+00,\n",
            "         -7.1263e-01, -1.0316e+00,  1.1249e+00],\n",
            "        [-8.4642e-01,  3.0920e-01,  8.9960e-01, -1.3454e+00,  8.5341e-01,\n",
            "          8.7762e-01, -4.3190e-01,  5.2717e-02],\n",
            "        [-5.3475e-01, -5.9550e-01,  1.0440e-01, -1.9649e+00,  2.2188e+00,\n",
            "         -3.4562e-02, -1.3599e+00,  9.9631e-01],\n",
            "        [-2.9665e+00,  3.5554e+00, -2.1088e+00, -2.4938e+00,  2.8791e+00,\n",
            "         -1.0791e+00, -1.7946e+00,  1.5753e+00],\n",
            "        [-1.5375e+00,  1.0118e+00, -7.8305e-01, -1.8374e+00,  2.2598e+00,\n",
            "          9.3409e-02, -8.8563e-01,  5.8301e-01],\n",
            "        [-1.1015e+00, -2.6647e-01,  4.4820e-01, -1.2773e+00,  1.3238e+00,\n",
            "          1.5667e+00, -6.3822e-01, -1.0608e-01],\n",
            "        [-8.3262e-01, -3.5473e-01,  1.2656e+00, -1.1497e+00,  1.7201e-01,\n",
            "          1.5966e+00, -5.9534e-01,  1.0083e-02],\n",
            "        [-3.1922e+00,  1.6265e+00, -2.3490e+00, -1.8798e+00,  2.7824e+00,\n",
            "         -2.3147e+00, -1.4908e+00,  4.9745e+00],\n",
            "        [-1.5681e+00, -5.8169e-01,  1.9733e+00, -8.9253e-01, -7.0463e-01,\n",
            "          3.2923e+00, -3.0710e-01, -8.4444e-01],\n",
            "        [-2.8628e+00,  9.7724e-01, -1.0003e+00, -1.0111e+00, -1.0072e-01,\n",
            "         -1.4292e+00, -1.4703e+00,  5.0109e+00],\n",
            "        [-1.6065e+00, -1.5874e-01, -1.5164e-01, -9.9760e-01,  1.8566e+00,\n",
            "          1.2967e+00, -9.7261e-01,  4.8040e-01],\n",
            "        [-8.8559e-01,  8.0078e-02,  3.1563e-02, -7.8184e-01,  1.3046e+00,\n",
            "          1.2671e+00, -7.2040e-01,  3.9164e-02],\n",
            "        [-2.8157e+00,  3.6482e-01, -3.0312e-01, -1.6748e+00,  1.7534e+00,\n",
            "          1.0034e-02, -9.5926e-01,  2.8746e+00],\n",
            "        [-1.8473e+00, -4.1073e-01, -3.3213e-01, -5.0610e-01,  2.0146e+00,\n",
            "          2.0322e-01, -6.7225e-01,  8.6913e-01],\n",
            "        [-8.7834e-01, -3.1751e-01,  3.9919e-01, -1.0271e+00,  1.2232e+00,\n",
            "          1.3613e+00, -7.6576e-01, -8.8956e-02],\n",
            "        [-1.7182e+00,  8.7365e-01, -5.2731e-01, -1.1915e+00,  1.7999e+00,\n",
            "          1.6982e-01, -3.5826e-01,  8.7146e-01],\n",
            "        [-2.8589e+00,  7.5237e-01, -2.3795e+00, -2.8371e+00,  5.0778e+00,\n",
            "         -2.0166e-01, -1.1510e+00,  1.2607e+00],\n",
            "        [-1.7768e+00,  6.5626e-01, -6.0815e-01, -9.3701e-01,  1.5208e+00,\n",
            "          8.9123e-01, -1.2996e+00,  9.0600e-01],\n",
            "        [-2.1354e+00, -1.3132e-01,  8.5652e-01, -4.9849e-01, -2.3709e-02,\n",
            "          3.3654e-01,  1.3146e+00,  1.2079e-01],\n",
            "        [-1.8480e+00, -4.3713e-01,  2.0574e+00, -5.4954e-01, -8.4885e-01,\n",
            "          3.7418e+00, -2.1912e-01, -1.0776e+00],\n",
            "        [-6.0414e-01,  5.2462e-01,  3.0660e-01, -3.3512e-01,  6.0784e-01,\n",
            "          7.4781e-01, -9.2912e-01, -1.8627e-01],\n",
            "        [-2.8386e+00,  3.7116e+00, -1.9372e+00, -2.2127e+00,  2.0067e+00,\n",
            "         -1.3572e+00, -1.7746e+00,  1.6311e+00],\n",
            "        [-6.5522e-01, -3.1009e-01,  1.3347e+00, -4.9590e-01, -3.3795e-01,\n",
            "          1.4657e+00, -2.8330e-01, -1.8681e-01],\n",
            "        [-7.0336e-01,  6.4515e-01,  5.1926e-01,  3.5281e-02,  1.3740e-02,\n",
            "          1.0097e+00, -4.3881e-01, -5.4425e-01],\n",
            "        [ 4.7873e-01, -1.2715e-01,  1.1516e+00, -9.7020e-01,  2.4901e-01,\n",
            "          1.0748e+00, -4.9173e-01, -5.8827e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1251, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.2108,  2.1282, -0.7202, -1.8972,  1.6718, -0.5001, -1.5642,  1.5041],\n",
            "        [-1.7472, -0.8318, -1.8809, -2.1376,  6.6979, -0.4618, -0.9871, -0.1176],\n",
            "        [-3.0532,  1.0058, -1.7800, -0.7045,  2.1953, -0.9465, -1.2196,  3.1334],\n",
            "        [-1.6611, -0.1618, -0.5624, -0.9766,  0.0642,  6.1233, -1.1230, -0.6454],\n",
            "        [-0.3354, -0.8818,  0.9855, -0.5787,  0.7963,  1.0457, -0.6840, -0.3427],\n",
            "        [-1.3892, -0.7204, -0.3270, -1.2038,  2.3160,  0.8810, -0.6945,  0.7712],\n",
            "        [-2.8971,  3.1430, -2.1571, -2.6931,  3.2502, -0.6865, -2.0438,  1.6212],\n",
            "        [-2.1490,  1.1023, -0.3078, -1.2133,  1.5236,  0.0276, -1.0181,  1.3243],\n",
            "        [-1.7452,  0.2990, -0.5277, -0.5363,  1.7707, -0.1809, -0.8584,  1.2073],\n",
            "        [-2.9546,  1.8510, -1.8531, -1.4528,  2.5944, -0.3931, -1.0821,  1.7413],\n",
            "        [-0.8825, -0.0748,  1.0061, -1.2512,  1.1163,  0.2153, -0.6749,  0.3183],\n",
            "        [-2.3709,  1.7499, -0.6678, -2.7673,  2.7447, -0.3244, -1.4718,  1.5761],\n",
            "        [-2.7448,  5.5866, -1.6070, -2.6676,  1.0192, -1.4161, -2.1634,  1.3622],\n",
            "        [-1.7437, -0.2660,  0.0948, -1.6493,  2.6663,  0.8011, -0.9138,  0.5021],\n",
            "        [-2.0530,  0.0288, -0.3493, -1.1004,  0.2152,  6.1710, -1.1101, -0.4887],\n",
            "        [-2.5900,  3.3796, -1.9221, -1.7501,  2.1026, -0.7551, -2.2204,  1.8608],\n",
            "        [-2.8807,  0.6390, -1.7076, -1.5625,  3.3757, -0.7457, -1.1995,  2.4844],\n",
            "        [ 0.6616,  0.1696,  1.2552, -1.2289,  0.2702,  0.7998, -1.1382, -0.3550],\n",
            "        [-2.1628,  0.1735, -0.9001, -1.0380,  2.4996,  0.1424, -0.6397,  0.9145],\n",
            "        [-1.6582, -1.1677,  0.3707, -0.9585,  0.1044, -0.6952,  5.8743, -0.0250],\n",
            "        [-0.9349, -0.6560,  2.5641, -1.8877, -0.0334,  1.7126, -0.7822,  0.1295],\n",
            "        [-0.1942, -0.8351,  1.2559, -0.8067,  0.6172,  1.4495, -0.5159, -0.3807],\n",
            "        [-2.3597,  1.3799, -1.7639, -1.9574,  3.3917,  0.2483, -1.5035,  1.1003],\n",
            "        [-0.7789, -0.5009,  1.6375, -1.0670, -0.3843,  1.5885, -0.5909,  0.4721],\n",
            "        [-1.1362, -0.1874,  0.4473, -0.5002,  1.0939,  1.2398, -0.8395,  0.0316],\n",
            "        [-2.5375,  2.1633, -1.4280, -0.9679,  2.3732, -0.7176, -1.3461,  1.5359],\n",
            "        [-3.0464,  3.1389, -2.1053, -1.3751,  0.8932, -0.2075, -2.2700,  3.0015],\n",
            "        [-0.0306, -0.7754,  1.1764, -1.2907,  1.1386,  1.1993, -0.6836, -0.1587],\n",
            "        [-2.9159,  2.7401, -2.2448, -2.0708,  3.4254, -1.1369, -1.7641,  2.0158],\n",
            "        [-2.7791,  0.6574, -1.8770, -1.3330,  2.8880, -0.9576, -1.3571,  3.0294],\n",
            "        [-2.8008,  5.7260, -1.7657, -2.6381,  1.0836, -1.4101, -2.2919,  1.1462],\n",
            "        [-1.8174,  0.8424, -0.5694,  0.5252,  1.1216,  0.0807, -0.7812,  0.5983]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.2444e+00,  2.2969e+00, -1.1418e+00, -1.3315e+00,  2.0188e+00,\n",
            "         -3.8352e-01, -1.6446e+00,  1.1987e+00],\n",
            "        [-2.2725e+00,  1.4633e+00, -1.9152e+00, -7.7979e-01,  2.3403e+00,\n",
            "         -1.2826e+00, -1.9204e+00,  2.8190e+00],\n",
            "        [-1.7387e+00,  3.1261e-01,  5.5722e+00, -2.4829e+00, -1.0897e+00,\n",
            "          4.0544e-03, -1.2305e+00, -1.8473e-02],\n",
            "        [-8.3549e-01,  3.1544e-01, -7.3666e-01, -8.9036e-01,  1.6712e+00,\n",
            "         -1.0581e-01, -1.4235e+00,  9.9170e-01],\n",
            "        [-1.8871e+00,  1.3164e+00, -1.1979e+00, -1.0502e+00,  1.8337e+00,\n",
            "          2.7072e-02, -1.9500e+00,  1.7031e+00],\n",
            "        [-2.3089e+00,  2.6612e+00, -1.3754e+00, -1.1189e-01,  9.4871e-01,\n",
            "         -1.1732e+00, -2.1090e+00,  1.6934e+00],\n",
            "        [-9.9822e-01, -5.6473e-01, -4.7070e-01, -1.4837e+00,  2.7697e+00,\n",
            "          1.5167e+00, -1.3787e+00,  4.7404e-01],\n",
            "        [-2.6549e+00, -1.6413e-02, -1.3602e+00, -1.9731e+00,  3.8666e+00,\n",
            "         -3.1160e-01, -6.2599e-01,  1.6204e+00],\n",
            "        [-1.0871e+00,  7.6215e-02,  7.7329e-03, -1.6845e+00,  2.2573e+00,\n",
            "          2.0791e-02, -1.1059e+00,  9.1696e-01],\n",
            "        [-9.1512e-01, -6.3952e-01,  1.4229e+00, -1.2076e+00,  5.1428e-01,\n",
            "          1.5395e+00, -4.1774e-01, -1.1655e-01],\n",
            "        [-2.7107e+00,  6.5203e+00, -1.7477e+00, -1.9479e+00,  1.8824e-01,\n",
            "         -1.5600e+00, -1.6163e+00,  5.8793e-01],\n",
            "        [-2.8015e+00,  7.4826e-01, -2.3264e+00, -5.8112e-01,  7.8967e-01,\n",
            "         -1.9505e+00, -1.1134e+00,  5.4255e+00],\n",
            "        [-2.0747e+00,  1.2212e+00, -1.2634e+00, -8.7386e-01,  2.1097e+00,\n",
            "         -4.4420e-01, -1.4241e+00,  1.5239e+00],\n",
            "        [-1.5027e+00, -4.6601e-01,  1.9920e+00, -1.0165e+00, -2.5576e-01,\n",
            "          2.9260e+00, -3.9656e-01, -3.6666e-01],\n",
            "        [-1.3979e+00, -7.5044e-02, -3.8502e-01,  1.6621e+00,  1.0771e+00,\n",
            "          1.4891e-01, -7.6311e-01, -6.8381e-02],\n",
            "        [-3.3338e-01, -8.6276e-01,  7.8643e-01, -1.3623e+00,  1.4791e+00,\n",
            "          1.1617e+00, -9.6667e-01,  2.2019e-02],\n",
            "        [-2.8731e+00,  5.4008e-01, -1.0552e+00, -4.9636e-01,  1.9534e+00,\n",
            "         -1.9637e-01, -8.0199e-01,  2.4511e+00],\n",
            "        [-2.0087e+00,  1.0908e+00, -1.1631e+00, -6.4123e-01,  2.4052e+00,\n",
            "         -4.1496e-01, -1.2605e+00,  1.5211e+00],\n",
            "        [-3.0933e+00,  1.0863e+00, -1.2520e+00, -8.6743e-01,  2.0829e+00,\n",
            "         -5.9442e-01, -1.1579e+00,  2.9299e+00],\n",
            "        [-1.0943e+00, -5.3955e-01,  6.9364e-01, -1.1742e+00,  1.3155e+00,\n",
            "          8.4610e-01, -6.0483e-01,  7.5237e-01],\n",
            "        [ 2.5893e-01, -3.7146e-01,  1.1138e+00, -1.2485e+00,  6.5390e-01,\n",
            "          7.0275e-01, -1.1096e+00, -3.9912e-03],\n",
            "        [-1.7064e+00, -2.1394e-01,  8.1844e-01, -1.4545e+00,  1.5737e+00,\n",
            "          1.2370e+00, -5.1548e-01,  1.3636e-01],\n",
            "        [-2.3560e+00,  3.4648e+00, -9.3089e-01, -1.5445e+00,  1.1525e+00,\n",
            "         -2.3267e-01, -1.6483e+00,  8.0694e-01],\n",
            "        [-1.4278e+00,  1.1198e+00, -8.3840e-01,  3.4802e+00, -6.7462e-01,\n",
            "          6.0921e-01, -1.5164e+00, -2.1458e-01],\n",
            "        [-2.2704e+00,  1.7164e+00, -7.6940e-01, -5.3863e-01,  1.3170e+00,\n",
            "         -2.9733e-01, -8.9033e-01,  8.5168e-01],\n",
            "        [-1.5820e+00, -9.4166e-01, -1.7043e+00, -1.9391e+00,  7.0575e+00,\n",
            "         -5.9554e-01, -1.0282e+00, -8.1355e-02],\n",
            "        [-1.9843e+00,  5.0323e-01, -7.9383e-01, -4.8809e-01,  1.9219e+00,\n",
            "         -1.8365e-01, -8.5530e-01,  9.7571e-01],\n",
            "        [ 6.3198e+00, -6.7717e-01, -1.1010e+00, -1.2815e+00, -4.9609e-01,\n",
            "         -1.1003e+00, -9.5007e-01, -9.1524e-01],\n",
            "        [-1.3650e+00,  4.8688e-01,  1.5588e+00, -2.3629e+00,  6.3636e-01,\n",
            "          3.6801e-01, -9.9716e-01,  1.0237e+00],\n",
            "        [-1.5649e+00, -3.1473e-01,  1.8394e+00, -5.3117e-01, -3.6688e-01,\n",
            "          2.7304e+00, -1.3374e-02, -5.3806e-01],\n",
            "        [-4.1896e-01, -8.3200e-01,  1.8289e+00, -2.9190e-01,  8.2842e-02,\n",
            "          1.6450e+00, -6.8526e-01, -4.9062e-01],\n",
            "        [-4.5432e-01, -1.3874e-01,  6.2848e-01, -8.8109e-01,  1.0125e+00,\n",
            "          8.8221e-01, -6.2709e-01, -2.2649e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0623, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.0406,  2.2223, -1.3115, -0.6484,  1.5765, -0.3847, -1.4036,  1.0496],\n",
            "        [-0.1319,  0.6326,  1.8089, -1.6822,  0.1337,  1.0961, -1.5049, -0.3753],\n",
            "        [-2.9855,  2.2536, -2.3732, -1.4867,  2.5576, -0.6466, -1.7861,  2.5474],\n",
            "        [-1.4422,  0.1884,  0.0370, -0.2838,  1.2050,  0.7379, -0.4744,  0.0271],\n",
            "        [-2.3306,  0.2771, -1.2148, -0.9384,  2.8202,  0.4940, -0.9262,  1.6192],\n",
            "        [-2.3222,  0.7670, -0.5645, -1.0286,  2.1465,  0.0253, -0.8880,  1.2188],\n",
            "        [-1.8472,  0.2396, -0.5589, -1.1846, -0.0079,  6.2367, -1.3440, -0.6804],\n",
            "        [ 0.0176, -0.3870,  0.7719, -1.2507,  0.9723,  1.4423, -1.4942, -0.0618],\n",
            "        [-2.9821,  0.9139, -1.1635, -0.3437,  2.4670, -0.6752, -0.5345,  1.1066],\n",
            "        [-0.5227, -0.2593,  0.1927, -1.1720,  1.7594,  0.5342, -1.1457,  0.2944],\n",
            "        [-1.6599, -0.0385, -0.4751, -1.3902,  2.3880, -0.3968, -1.0180,  1.5661],\n",
            "        [-2.0882,  1.6767, -0.9358, -0.6832,  1.6922, -0.6194, -1.1084,  1.0494],\n",
            "        [-1.8646, -1.2334, -1.1220, -1.8585,  6.8115, -0.2304, -1.0059, -0.4647],\n",
            "        [-1.5093, -0.6495,  2.1421, -1.0072, -0.4910,  2.7013, -0.2890, -0.4912],\n",
            "        [-2.1248, -0.8284, -1.8174, -2.1047,  6.6936, -0.6444, -0.7947,  0.4724],\n",
            "        [-2.3318,  0.6038, -1.4967, -1.2221,  2.8926, -0.2688, -0.7283,  1.4847],\n",
            "        [-0.1456,  0.3742,  0.6294, -0.4158,  0.4210,  0.8412, -0.5867, -0.5135],\n",
            "        [-2.4693,  6.5452, -1.8419, -1.9190,  0.4597, -1.7612, -1.8581,  0.6145],\n",
            "        [-2.0125,  0.4667, -1.7130, -1.5502,  3.1037, -0.8498, -1.2476,  2.1901],\n",
            "        [-1.8187, -0.0992,  0.2235, -1.8409,  1.9258,  0.4058, -0.1622,  1.0304],\n",
            "        [-0.6126, -0.7451,  2.3075, -1.3499, -0.3537,  1.8974, -0.3737, -0.3143],\n",
            "        [-1.8841,  0.0570, -0.2439, -1.1726,  1.9208,  0.4062,  0.0891,  0.2707],\n",
            "        [-1.1224, -0.7227,  2.4615, -0.8505, -0.5635,  2.4563, -0.3798, -0.5506],\n",
            "        [-3.0403,  5.7319, -2.1118, -2.4538,  1.2895, -1.5433, -2.5030,  1.4638],\n",
            "        [-1.8656,  1.0123, -0.9898, -0.3621,  1.4831, -0.1471, -1.2863,  1.2814],\n",
            "        [-2.7968,  1.9862, -1.4906, -1.2639,  2.1315, -0.7051, -1.3982,  1.9710],\n",
            "        [-1.2864,  0.8625,  0.3757, -0.3356, -0.1338,  1.0647, -0.5109,  0.1509],\n",
            "        [-2.6147,  0.3391, -1.2603, -1.8445,  3.4614, -0.1143, -0.8268,  1.6139],\n",
            "        [-1.7726, -0.0497, -0.4843,  0.8464,  1.3552,  0.0950, -0.3527,  0.3450],\n",
            "        [-2.9329,  2.6585, -2.2509, -2.1392,  3.1567, -0.9392, -1.6719,  2.1967],\n",
            "        [-2.5251,  3.2248, -1.6031, -1.5361,  1.6971, -0.8902, -1.7761,  1.5430],\n",
            "        [-3.1000,  5.7086, -1.7110, -2.7383,  1.2350, -1.2416, -2.4434,  1.2553]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1013e+00, -5.1286e-01, -1.6723e+00, -2.1619e+00,  6.8293e+00,\n",
            "         -4.9452e-01, -1.1586e+00,  1.0268e-01],\n",
            "        [-6.9527e-01, -8.9952e-01,  1.9052e+00, -1.2070e+00,  1.3867e-01,\n",
            "          1.9477e+00, -5.7534e-01, -4.3006e-01],\n",
            "        [-2.3054e+00,  2.3984e+00, -1.8716e+00, -1.7713e+00,  3.0494e+00,\n",
            "         -7.0850e-01, -1.7637e+00,  1.5261e+00],\n",
            "        [-1.7243e+00,  1.4822e-01,  7.2404e-01, -1.5246e+00,  1.2292e+00,\n",
            "          1.2413e+00, -6.0779e-01,  5.5633e-01],\n",
            "        [-2.4813e+00,  8.3085e-01, -1.3563e+00, -2.2027e+00,  4.2334e+00,\n",
            "          2.9598e-01, -1.6039e+00,  8.4051e-01],\n",
            "        [-1.6592e+00,  5.8316e-01,  3.6232e-01, -2.0106e+00,  6.2499e-01,\n",
            "          4.1866e-01, -8.2044e-01,  1.5929e+00],\n",
            "        [-8.7484e-01, -1.5669e-01,  6.6284e-01, -7.0446e-01,  6.8827e-01,\n",
            "          1.2132e+00, -2.3354e-01, -2.0232e-02],\n",
            "        [-2.0495e+00,  1.7627e+00, -1.1797e+00, -1.0364e+00,  1.9301e+00,\n",
            "         -6.3405e-01, -1.6380e+00,  1.2541e+00],\n",
            "        [-1.6729e+00, -8.3198e-01, -1.8290e+00, -1.9553e+00,  6.8001e+00,\n",
            "         -2.2922e-01, -1.2768e+00, -4.3516e-01],\n",
            "        [-6.3246e-01,  6.6257e-01,  2.7820e-01, -1.1873e+00,  7.0765e-01,\n",
            "          1.0674e+00, -1.5267e+00,  1.3261e-01],\n",
            "        [-1.9347e+00,  4.8322e-02, -5.1190e-01, -1.2690e+00,  3.3239e-01,\n",
            "          6.6459e+00, -1.3598e+00, -6.6281e-01],\n",
            "        [-1.5554e+00, -5.7588e-01,  1.8437e+00, -1.1033e+00, -4.8114e-01,\n",
            "          3.4968e+00, -6.3757e-01, -4.4471e-01],\n",
            "        [-1.1121e+00, -2.5299e-01,  1.7691e-01, -1.1224e+00,  1.4810e+00,\n",
            "          4.6434e-02, -9.9244e-01,  1.5358e+00],\n",
            "        [-1.0507e+00,  1.1120e+00, -6.6983e-02,  1.1389e+00, -9.9814e-02,\n",
            "          5.8050e-01, -7.9581e-01, -5.0777e-01],\n",
            "        [-2.6639e+00,  8.4525e-01, -1.8987e+00, -1.4522e+00,  3.3586e+00,\n",
            "         -5.5331e-01, -1.2097e+00,  2.2281e+00],\n",
            "        [-2.7253e+00,  3.6914e+00, -2.1483e+00, -1.7834e+00,  2.0656e+00,\n",
            "         -1.3238e+00, -2.2413e+00,  1.8289e+00],\n",
            "        [-2.2794e+00,  4.2911e+00, -1.6083e+00, -1.6326e+00,  1.4423e+00,\n",
            "         -1.0792e+00, -2.4692e+00,  1.1693e+00],\n",
            "        [-1.6455e+00,  7.1448e-01, -1.1216e-01, -1.1445e+00,  1.8862e+00,\n",
            "         -1.0739e-01, -1.2178e+00,  9.5394e-01],\n",
            "        [-1.5544e+00,  1.3320e+00,  1.5458e-01, -1.4999e-01,  1.9535e-01,\n",
            "          6.1516e-01, -4.1634e-01,  4.9829e-02],\n",
            "        [-1.3880e+00, -1.2982e-01,  6.3882e-01,  1.9707e+00, -2.5983e-01,\n",
            "          7.9368e-01, -2.9762e-01, -6.6456e-01],\n",
            "        [-2.3308e+00,  2.4910e+00, -1.2069e+00, -4.6512e-01,  1.4730e+00,\n",
            "         -6.8477e-01, -1.4297e+00,  1.0058e+00],\n",
            "        [-9.9051e-01,  3.3644e-01, -4.3479e-01, -1.1631e+00,  1.7718e+00,\n",
            "         -6.5949e-02, -1.3149e+00,  1.1565e+00],\n",
            "        [-2.6888e+00,  1.1038e+00, -1.3129e+00, -1.5916e+00,  2.9954e+00,\n",
            "         -6.7304e-03, -1.0411e+00,  1.3020e+00],\n",
            "        [-2.9053e+00,  4.0662e+00, -2.6386e+00, -1.9116e+00,  2.5977e+00,\n",
            "         -1.4409e+00, -2.0044e+00,  2.1335e+00],\n",
            "        [-2.2787e+00, -1.3864e-01, -8.5011e-01, -1.2058e+00,  2.5496e+00,\n",
            "         -1.5121e-01, -9.6958e-01,  1.7504e+00],\n",
            "        [-1.5184e+00,  2.9878e-01,  4.0255e-01, -1.3438e+00,  1.0411e+00,\n",
            "          7.0728e-01, -1.0385e+00,  9.5422e-01],\n",
            "        [-2.8146e+00,  6.1349e+00, -1.7195e+00, -2.3912e+00,  6.1069e-01,\n",
            "         -1.6041e+00, -2.0616e+00,  9.9189e-01],\n",
            "        [-1.4862e+00,  6.3670e-01,  6.0800e-01, -1.3674e+00,  1.1695e+00,\n",
            "          6.5267e-01, -8.0452e-01,  5.3140e-01],\n",
            "        [-7.9658e-01, -3.3283e-01, -1.1548e-01, -1.0949e+00,  2.1955e+00,\n",
            "          1.4338e-01, -9.1866e-01,  5.2391e-01],\n",
            "        [-9.3714e-01,  1.7755e+00,  7.4246e-02, -1.0418e+00,  5.6104e-01,\n",
            "          3.4143e-01, -1.4913e+00,  4.3075e-01],\n",
            "        [-2.4732e+00,  4.7163e-01, -5.0519e-01, -6.3763e-01,  1.6509e+00,\n",
            "          1.8875e-01, -2.0176e-01,  1.1651e+00],\n",
            "        [-3.1525e+00, -1.3469e-01, -1.6113e+00, -2.1767e+00,  4.8838e+00,\n",
            "         -5.1189e-01, -8.8703e-01,  2.0528e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0867, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.6662,  0.0287,  2.4188, -1.3255, -0.7453,  2.0354, -0.6433, -0.4069],\n",
            "        [-3.1266,  2.1445, -2.3306, -1.8746,  2.9182, -0.9900, -1.7085,  3.1386],\n",
            "        [-1.4430,  0.2649, -0.7336, -0.5482,  1.6345,  0.1138, -1.5038,  1.6361],\n",
            "        [-3.1155,  1.2755, -1.5774, -1.1205,  3.0062, -0.5139, -1.1107,  1.8988],\n",
            "        [-2.9571,  5.8826, -2.1137, -2.0619,  0.8190, -1.5329, -1.7888,  0.8180],\n",
            "        [-1.8724,  0.6577, -1.2774, -1.5298,  2.8062, -0.2409, -1.4897,  1.6998],\n",
            "        [-1.2281,  0.1270,  0.1182, -1.2658,  1.6646,  0.7781, -1.0993,  0.6628],\n",
            "        [-1.6890, -1.1974, -1.4385, -1.8738,  6.9478, -0.2843, -1.2092, -0.2553],\n",
            "        [-1.5041,  0.0929, -0.7456,  2.5616,  0.5563,  0.4116, -1.3533,  0.1927],\n",
            "        [-2.8608,  1.9792, -1.9345, -1.6424,  2.4577, -0.8560, -1.7216,  2.7498],\n",
            "        [-0.9465, -0.0340,  1.2054, -1.4336,  0.6527,  1.2005, -0.2272, -0.2210],\n",
            "        [-2.2763, -0.1417, -0.7646, -1.0482,  3.1937, -0.1052, -0.3600,  1.3409],\n",
            "        [-2.6057,  0.4379, -1.8457, -1.6622,  2.7238, -0.3937, -1.0299,  2.8707],\n",
            "        [-1.3433, -0.2200,  0.2491, -2.1463,  2.5346, -0.0293, -1.1822,  1.1962],\n",
            "        [-2.7642,  0.8739, -1.7038, -1.1162,  2.7838, -0.7500, -1.1227,  2.3597],\n",
            "        [-2.4397,  6.4883, -1.8058, -2.0325,  0.4376, -2.0451, -1.0488,  0.4869],\n",
            "        [-1.5638,  0.5842, -0.1399, -1.5596,  2.2114,  0.0690, -0.9531,  0.6730],\n",
            "        [-2.0475,  1.0083, -0.9451, -0.1872, -0.9665, -1.2606, -0.9289,  4.1370],\n",
            "        [-1.5724,  0.6636,  0.0449, -1.4533,  1.5232, -0.4858, -0.7788,  1.4927],\n",
            "        [-1.7300,  1.0810, -1.0079, -1.7815,  2.1640,  0.4251, -1.6076,  1.2032],\n",
            "        [ 1.0319, -0.2968,  1.0253, -1.5231,  0.7017,  1.0317, -1.0431, -0.5600],\n",
            "        [-2.5018,  0.9731, -1.3934, -0.1959, -0.3908, -1.0918, -1.0229,  4.3164],\n",
            "        [-3.0734,  5.3625, -1.6061, -2.0823,  1.0776, -1.2391, -2.1693,  1.1435],\n",
            "        [-0.6094, -0.6695,  0.7343, -1.0446,  1.0312,  1.2661, -0.9464,  0.4622],\n",
            "        [-2.1448, -0.6026,  0.2314,  2.0198,  0.4853, -0.1861,  1.2291, -0.5684],\n",
            "        [-1.8175,  0.9585, -0.8257, -0.3619,  1.3842,  0.1503, -1.1016,  1.0117],\n",
            "        [-1.7291, -0.0594,  0.0709, -1.1451,  1.3954,  1.2117, -1.0022,  0.8089],\n",
            "        [-2.1566,  1.0285, -1.1745, -0.0895, -0.5349, -1.0250, -0.9734,  4.3847],\n",
            "        [-1.8179,  0.8141, -0.4099, -1.8845,  2.0776, -0.1813, -0.6684,  0.8688],\n",
            "        [ 0.7208, -0.3822,  0.9237, -1.5671,  0.6711,  1.0540, -1.0568, -0.2430],\n",
            "        [-0.8109,  0.3490,  0.7994, -1.0680,  0.5932,  0.8405, -1.1833,  0.1516],\n",
            "        [-0.6567, -0.6842,  1.8346, -0.7707,  0.0819,  1.7785, -0.6183, -0.2683]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2604, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.6707,  3.9582, -2.0820, -2.0593,  1.9218, -1.2109, -1.9786,  1.7982],\n",
            "        [-1.9294,  1.1938, -0.3006, -0.8848,  1.2319,  0.3846, -0.5552,  0.6712],\n",
            "        [-0.6665, -0.1409, -0.3050, -1.2826,  2.1563,  0.5582, -1.0277,  0.5500],\n",
            "        [-0.6669, -0.0658,  1.3008, -0.5111,  0.2813,  1.2667, -0.6836, -0.2958],\n",
            "        [-1.3250, -0.0966, -1.0834, -1.6028,  2.5973,  0.4068, -1.5619,  1.4921],\n",
            "        [-3.1332, -0.0507, -1.5235, -2.6509,  5.0619, -0.4012, -0.6355,  1.9351],\n",
            "        [-1.6689, -0.1272,  0.3494, -0.6557,  1.6654,  0.4144, -0.6061,  0.6251],\n",
            "        [-1.7780,  0.3212, -0.4369, -1.2512,  2.1654, -0.2489, -0.3174,  1.0698],\n",
            "        [-2.1505,  1.4621, -1.4408, -1.4796,  2.7858, -0.6357, -1.2499,  1.3603],\n",
            "        [-1.9828,  1.8829, -0.3697, -0.6267,  1.2447, -0.0585, -1.3940,  0.4913],\n",
            "        [-0.9883, -0.5292,  0.7030, -0.5181,  0.7163,  0.8721, -0.3209, -0.1075],\n",
            "        [-0.9259,  0.1799, -0.1293,  0.3415,  1.1430,  0.2066, -1.0471,  0.1828],\n",
            "        [-2.4764,  4.1081, -1.5499, -1.6332,  1.3426, -0.9618, -1.7899,  0.9678],\n",
            "        [-3.2127,  2.5809, -1.3030, -1.8568,  1.5854, -0.6549, -1.9987,  3.4990],\n",
            "        [-1.8790,  0.7167, -1.4474, -1.0566,  1.9968, -0.5177, -1.0627,  1.9235],\n",
            "        [ 0.2504, -0.1547, -0.2256, -0.7588,  1.3759,  0.2618, -1.1355,  0.0279],\n",
            "        [-2.1134,  1.2337, -0.8841, -1.8109,  2.5422, -0.2345, -1.0598,  1.3292],\n",
            "        [-2.5764,  0.5331, -1.3621, -1.5278,  2.9799, -0.2320, -0.5103,  1.2206],\n",
            "        [-2.2170,  1.8929, -1.6071, -2.4117,  3.0891,  0.3418, -2.0113,  1.2566],\n",
            "        [-1.9492,  0.2065, -0.7451, -2.0418,  2.7969,  1.1114, -0.7218,  0.5325],\n",
            "        [-2.3417, -0.1093, -0.7512,  0.1518,  1.7850, -0.4263, -0.8997,  1.7658],\n",
            "        [-2.8877,  4.2039, -2.1382, -2.0944,  2.0224, -1.2620, -2.3025,  2.2958],\n",
            "        [-2.4052,  0.7063, -0.8428, -0.8408,  2.2740, -0.1783, -1.0396,  1.2210],\n",
            "        [-1.6491,  1.1672, -0.9394, -1.6771,  2.3573,  0.2696, -1.5548,  0.8674],\n",
            "        [-2.2051,  1.3926, -1.1172, -1.3251,  2.1248, -0.6526, -1.2451,  1.9378],\n",
            "        [-2.2884,  0.2789, -1.3863, -1.4887,  2.9250, -0.5461, -1.0997,  1.9755],\n",
            "        [-1.7402, -0.6858, -1.6821, -2.2064,  6.9724, -0.3755, -1.1453, -0.1914],\n",
            "        [-2.9695,  0.5987, -1.4636, -1.4775,  3.6647, -0.7501, -0.4578,  1.2558],\n",
            "        [-2.9061,  5.6838, -1.4946, -2.2713,  0.9378, -1.1604, -1.9422,  0.6744],\n",
            "        [-2.9995,  3.0393, -2.4188, -2.6189,  3.7114, -1.1606, -2.0509,  1.7325],\n",
            "        [-3.4444,  2.6341, -2.1425, -0.6565,  1.7535, -0.9411, -1.7470,  2.2679],\n",
            "        [-1.7786, -1.0590, -1.2548, -1.8910,  6.6267,  0.1294, -1.1876, -0.3631]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9526, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.8938,  0.4792, -0.1717, -1.2040,  1.3243,  0.1158, -1.3291,  2.2476],\n",
            "        [-1.9923, -0.0250,  0.1523, -0.7979,  1.7655,  0.2203, -0.5713,  0.9887],\n",
            "        [-3.1578,  1.6197, -2.2386, -1.0883,  1.1736, -1.8183, -1.6572,  5.4553],\n",
            "        [-1.8990,  0.3837,  1.1064, -1.2850,  0.3262,  0.9929, -0.8578,  0.9326],\n",
            "        [-1.5386,  1.8937, -0.2496, -1.3817,  1.4957,  0.3769, -1.7539,  0.1336],\n",
            "        [-0.9793,  0.0204,  0.9026, -0.6977,  0.4670,  1.4532, -0.1128, -0.5352],\n",
            "        [-2.4197,  0.2526, -0.9125, -0.7785,  2.8651,  0.2231, -0.4987,  0.7904],\n",
            "        [-2.6569,  1.3251, -1.4732, -1.2581,  1.8134, -1.0410, -1.5699,  3.3136],\n",
            "        [-2.7242,  1.7807, -2.1743, -1.2263,  3.0113, -1.0176, -1.1805,  1.8572],\n",
            "        [-1.7336,  0.1123, -0.9230, -1.5943,  0.5901,  6.2757, -1.2212, -0.4893],\n",
            "        [-1.3083, -0.9856, -1.5326, -1.6425,  6.8578, -0.4160, -1.3285, -0.6424],\n",
            "        [-3.2662,  1.3013, -2.0822, -1.6222,  3.3394, -1.0454, -0.8180,  1.9780],\n",
            "        [-1.8725,  0.8940, -1.1361, -1.3285,  2.6312, -0.8573, -1.5734,  1.6084],\n",
            "        [-1.5718,  1.3362, -1.2363, -1.2671,  1.8540, -0.2388, -1.4867,  1.4312],\n",
            "        [-2.8162,  0.1793, -0.9228, -1.8319,  3.5948, -0.5359, -0.1493,  1.0905],\n",
            "        [-1.3572, -0.0779, -0.7590, -1.4257,  0.2108,  6.1034, -1.6586, -0.3094],\n",
            "        [-2.6117,  2.4003, -2.2060, -1.9215,  2.6600, -0.8133, -1.9713,  2.5037],\n",
            "        [-2.8394,  0.0842, -1.3799, -2.0822,  3.9586,  0.0102, -0.8991,  1.6750],\n",
            "        [-0.8313, -0.4299,  0.3132, -0.7562,  1.6134,  0.7106, -0.9149,  0.4414],\n",
            "        [-2.2841,  6.2152, -1.5328, -2.3842,  0.6210, -1.4980, -2.2532,  1.2246],\n",
            "        [-2.5658,  1.5725, -2.1723, -1.3587,  2.8415, -1.3628, -1.3000,  2.6632],\n",
            "        [-2.1951,  1.9802, -1.2026, -0.5798,  1.7926, -0.6667, -1.3114,  0.9795],\n",
            "        [-1.4412,  1.9211, -0.6958, -0.6738,  1.1299,  0.1319, -1.2434,  0.4652],\n",
            "        [-2.3877,  0.0775, -0.8094, -0.8172,  2.6491, -0.1119, -0.3685,  1.4238],\n",
            "        [-2.6007,  1.3024, -1.6390, -2.0644,  3.2432, -0.4346, -1.3758,  2.0822],\n",
            "        [-0.7749, -0.7727,  0.9271, -0.8278,  1.0945,  0.8991, -0.6299,  0.0834],\n",
            "        [-1.4431,  0.1371, -0.2909, -1.6228,  2.2231, -0.2160, -1.5454,  1.7397],\n",
            "        [-1.9248,  1.4628, -1.0883,  0.2745,  1.4299, -0.1694, -1.0994,  0.9814],\n",
            "        [-1.8553,  1.2937, -0.5002, -0.9942,  1.6777, -0.2400, -1.6177,  1.0016],\n",
            "        [-1.3900,  0.0205, -0.6394, -1.3195,  0.1531,  6.4393, -1.0900, -0.9883],\n",
            "        [-2.5538,  5.3135, -2.0098, -1.7057,  1.4352, -1.2111, -2.3384,  0.5337],\n",
            "        [-0.2756,  1.1134,  0.6844, -1.1280,  0.0186,  1.0354, -1.6145,  0.0346]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3196e+00,  2.5755e+00, -2.5361e+00, -1.3167e+00,  2.7752e+00,\n",
            "         -1.4499e+00, -1.8349e+00,  2.9597e+00],\n",
            "        [-1.2308e+00, -4.7978e-01,  1.6593e+00, -3.7396e-01,  7.7650e-02,\n",
            "          2.2489e+00, -6.7297e-01, -5.2555e-01],\n",
            "        [-1.2222e+00,  7.8076e-01,  1.6207e-01,  2.5347e-01,  6.1311e-01,\n",
            "          4.4663e-01, -8.4481e-01, -1.1082e-01],\n",
            "        [-1.7965e+00,  1.3376e+00, -1.0185e+00, -1.2111e+00,  2.0850e+00,\n",
            "         -4.7666e-01, -1.2190e+00,  1.1989e+00],\n",
            "        [-1.2976e+00,  1.1123e+00, -1.4049e+00,  1.2782e-01,  1.5221e+00,\n",
            "         -3.4304e-01, -1.7071e+00,  1.1110e+00],\n",
            "        [-1.7616e+00, -9.1605e-01, -1.4137e+00, -1.7906e+00,  6.6429e+00,\n",
            "         -1.6337e-02, -1.1289e+00, -5.7244e-01],\n",
            "        [-1.6812e+00,  2.7376e+00, -6.2364e-03, -8.6287e-01,  1.8760e-01,\n",
            "         -2.0328e-01, -1.7263e+00,  8.2161e-01],\n",
            "        [-2.4509e+00,  4.7212e-02, -4.2326e-01, -1.6106e+00,  2.7638e+00,\n",
            "         -2.0822e-01, -6.9732e-01,  1.8511e+00],\n",
            "        [-1.4782e+00, -1.8551e-01,  1.6506e+00, -2.1472e+00,  6.6959e-01,\n",
            "          1.9401e+00, -1.2800e+00,  5.8824e-01],\n",
            "        [-2.2657e+00,  1.1428e+00, -8.3931e-01,  2.3011e+00,  5.4776e-01,\n",
            "         -2.8377e-01, -1.4153e+00,  9.1616e-01],\n",
            "        [-2.4720e+00,  1.2725e+00, -1.4378e+00, -1.0386e+00,  2.3288e+00,\n",
            "         -5.5601e-01, -1.4639e+00,  1.9271e+00],\n",
            "        [-1.3046e+00,  3.6863e-01,  2.1921e-02, -1.0773e+00,  1.7036e+00,\n",
            "         -1.0189e-01, -1.2979e+00,  7.4120e-01],\n",
            "        [-1.0281e+00, -3.8926e-01,  9.9735e-01, -4.4733e-01,  6.2480e-01,\n",
            "          1.2399e+00, -2.0011e-01, -1.7753e-01],\n",
            "        [-7.1333e-01, -1.5399e-01,  1.3132e+00, -1.0040e+00,  1.5095e-01,\n",
            "          2.3441e+00, -5.6831e-01, -4.8791e-01],\n",
            "        [-2.1932e+00,  2.0124e+00, -1.4116e+00,  1.7693e-01,  1.4346e+00,\n",
            "         -7.4295e-01, -1.2911e+00,  1.0712e+00],\n",
            "        [-1.8298e+00,  1.5014e-01,  6.8632e-01, -1.0277e+00,  1.3138e+00,\n",
            "          6.9435e-01, -8.9724e-02,  1.5113e-01],\n",
            "        [-5.1200e-01,  5.3264e-01,  1.3796e-01, -1.4068e+00,  1.1704e+00,\n",
            "          3.8516e-01, -1.6869e+00,  6.2209e-01],\n",
            "        [-2.3780e+00,  1.6515e-01, -8.9765e-01, -9.2836e-01,  2.3002e+00,\n",
            "         -2.6649e-02, -9.2537e-01,  2.0099e+00],\n",
            "        [-2.8476e+00,  6.0018e-01, -2.3342e+00, -1.2379e+00,  1.4011e+00,\n",
            "         -1.2847e+00, -1.8373e+00,  5.3796e+00],\n",
            "        [-1.1568e+00,  4.4148e-01, -4.3940e-01, -8.3106e-01,  1.6386e+00,\n",
            "         -6.8841e-02, -8.7028e-01,  7.4778e-01],\n",
            "        [-1.5149e+00,  1.5722e+00, -7.2531e-01, -5.7707e-01,  1.5138e+00,\n",
            "         -5.8417e-01, -1.2253e+00,  1.1066e+00],\n",
            "        [-3.5054e-01,  5.8492e-01, -1.0375e-01,  5.1266e-01,  7.0206e-01,\n",
            "          2.8007e-02, -1.2926e+00, -1.4248e-02],\n",
            "        [ 6.0108e+00, -2.1479e-01, -1.4406e+00, -1.7711e+00,  1.0070e-02,\n",
            "         -1.4596e+00, -8.9586e-01, -8.7906e-01],\n",
            "        [-2.1610e+00,  9.3635e-01, -9.9334e-03, -1.0760e+00,  1.3036e+00,\n",
            "          6.7462e-01, -6.9490e-01,  3.7755e-01],\n",
            "        [-4.1862e-01,  2.4011e-01,  9.3135e-02, -5.4802e-01,  6.9899e-01,\n",
            "          8.8400e-01, -8.1998e-01, -3.4826e-02],\n",
            "        [-2.6112e+00,  4.3910e-01, -1.0272e+00, -7.9146e-01,  2.5691e+00,\n",
            "         -5.7774e-01, -1.1789e+00,  2.0403e+00],\n",
            "        [-1.4709e+00, -7.1521e-02, -4.6072e-01, -1.4366e+00,  2.5502e+00,\n",
            "          1.6021e-01, -1.3863e+00,  1.3508e+00],\n",
            "        [-1.9982e+00, -3.7479e-01, -1.8206e+00, -2.2306e+00,  6.7286e+00,\n",
            "         -8.1299e-01, -1.0557e+00,  2.0972e-01],\n",
            "        [ 2.3219e+00,  4.2597e-01, -1.3592e+00, -1.0137e+00,  1.1343e+00,\n",
            "         -4.8692e-01, -2.1982e+00,  2.8888e-01],\n",
            "        [-1.8526e+00,  2.5013e+00, -1.2255e+00, -1.0496e+00,  1.6853e+00,\n",
            "         -2.7095e-01, -1.9801e+00,  5.2822e-01],\n",
            "        [-2.1719e+00,  2.4457e+00, -1.5208e+00, -1.2700e+00,  2.5717e+00,\n",
            "         -8.3674e-01, -1.9306e+00,  1.1193e+00],\n",
            "        [-1.3592e+00, -3.2680e-01,  1.5160e+00, -1.2915e+00,  2.0302e-01,\n",
            "          1.7944e+00, -1.3668e-01, -2.1909e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3861, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2349e+00, -2.7575e-01,  3.4011e-01, -1.1566e+00,  1.8552e+00,\n",
            "          4.9955e-01, -5.3821e-01,  4.7341e-01],\n",
            "        [-8.7895e-01, -9.5156e-01,  1.4116e-01, -9.9038e-01,  2.3106e+00,\n",
            "          4.1939e-02, -7.5287e-01,  6.8965e-01],\n",
            "        [-1.5867e+00,  9.8277e-01, -5.1103e-01, -1.4825e+00,  1.8863e+00,\n",
            "          6.4126e-01, -1.3867e+00,  5.0843e-01],\n",
            "        [-1.1870e+00,  2.6382e+00, -3.6862e-01, -1.3659e+00,  4.5938e-01,\n",
            "         -1.7871e-01, -8.1696e-01, -2.9137e-02],\n",
            "        [-1.1779e+00,  1.7429e-01,  4.2887e-01, -1.3770e+00,  1.2070e+00,\n",
            "          7.8868e-01, -1.0099e+00,  8.8390e-01],\n",
            "        [-2.5638e+00,  4.9806e-01,  2.5728e-01,  1.7435e+00, -1.1334e-01,\n",
            "          7.2484e-01,  3.4380e-01, -3.3423e-01],\n",
            "        [-2.5771e+00,  1.0012e+00,  6.0619e-01, -1.6069e+00, -4.6403e-01,\n",
            "         -5.5853e-01, -8.2593e-01,  3.5302e+00],\n",
            "        [-2.7872e+00,  2.3892e+00, -1.7985e+00, -3.3054e-01,  1.9260e+00,\n",
            "         -1.0987e+00, -1.6637e+00,  1.6175e+00],\n",
            "        [-1.8900e-01, -3.0344e-01,  1.1435e+00, -1.1531e+00,  3.5599e-01,\n",
            "          1.3747e+00, -8.0714e-01, -1.6856e-01],\n",
            "        [-1.0833e+00,  1.3472e+00, -1.8227e+00, -6.4837e-01,  1.1206e+00,\n",
            "          2.2212e+00, -2.1553e+00,  4.7807e-01],\n",
            "        [-2.2962e+00,  1.9581e+00, -1.5035e+00, -5.3457e-01,  2.0445e+00,\n",
            "         -5.5788e-01, -1.6886e+00,  1.3163e+00],\n",
            "        [-1.2195e+00,  3.9469e-02, -4.3059e-01,  2.4658e-01,  1.7870e+00,\n",
            "          2.1644e-01, -1.1136e+00,  3.6501e-01],\n",
            "        [-2.6137e+00,  3.7416e+00, -1.7222e+00, -1.7016e+00,  1.6987e+00,\n",
            "         -1.0446e+00, -1.7938e+00,  1.6819e+00],\n",
            "        [-7.1429e-01,  1.6398e-01, -4.9298e-02, -1.1000e+00,  1.1359e+00,\n",
            "          6.4967e-01, -8.7365e-01,  5.0039e-01],\n",
            "        [ 1.9851e+00, -1.2730e-01, -2.6291e-01, -7.7117e-01,  6.1036e-01,\n",
            "          1.5744e-01, -1.1689e+00, -8.7219e-01],\n",
            "        [-2.0394e+00,  1.2799e+00, -6.9833e-01, -1.2858e+00,  9.4808e-01,\n",
            "          3.2785e+00, -1.4767e+00, -3.7315e-02],\n",
            "        [-2.3300e+00,  1.5917e+00, -1.1565e+00, -1.5901e+00,  2.1479e+00,\n",
            "         -8.3597e-01, -1.2068e+00,  1.8995e+00],\n",
            "        [-1.4259e+00,  1.5394e+00, -5.6410e-01,  8.7476e-02,  6.8835e-01,\n",
            "          4.6077e-02, -1.2302e+00,  5.4544e-01],\n",
            "        [-2.1390e+00,  1.0080e+00, -1.5340e+00, -5.7644e-01,  2.2301e+00,\n",
            "          7.4922e-02, -1.0359e+00,  1.1847e+00],\n",
            "        [-2.2737e+00,  3.9326e-01, -7.2752e-01, -1.5271e+00,  2.2411e+00,\n",
            "         -1.4296e-01, -1.1312e+00,  1.8914e+00],\n",
            "        [-2.4039e+00,  1.7985e+00, -1.3748e+00, -6.1017e-01,  1.9724e+00,\n",
            "         -4.9672e-01, -9.7249e-01,  1.2898e+00],\n",
            "        [-1.4153e+00,  7.2171e-01, -5.5554e-01, -8.7596e-01,  1.7646e+00,\n",
            "         -9.7369e-02, -1.1860e+00,  1.0116e+00],\n",
            "        [-9.9650e-01,  3.4825e-02, -2.2885e-01, -1.0783e+00,  1.6091e+00,\n",
            "          1.2748e+00, -7.0833e-01, -5.5341e-02],\n",
            "        [-1.7627e+00, -2.1603e-01, -4.5282e-01, -1.3410e+00, -1.8398e-02,\n",
            "          6.6230e+00, -1.3268e+00, -6.8427e-01],\n",
            "        [-6.3054e-01,  2.6508e-01,  6.1636e-01, -4.6194e-01, -6.1288e-02,\n",
            "          1.9291e+00, -9.2451e-01, -4.5908e-01],\n",
            "        [-1.1444e+00,  6.7915e-02,  5.2655e-02, -1.5336e+00,  1.9870e+00,\n",
            "         -2.1484e-01, -7.8714e-01,  7.8949e-01],\n",
            "        [-1.1018e+00,  2.1335e-01, -7.8295e-02, -3.6936e-01,  1.2278e+00,\n",
            "          7.2375e-01, -1.0317e+00,  2.5051e-01],\n",
            "        [-1.2916e+00, -6.7403e-01,  1.9407e+00, -5.7683e-01, -5.3054e-01,\n",
            "          2.4595e+00, -1.6076e-01, -7.0766e-01],\n",
            "        [-1.8510e-01, -1.1802e-01,  1.0892e+00, -5.5915e-01,  3.6984e-02,\n",
            "          1.7709e+00, -5.8679e-01, -7.1829e-01],\n",
            "        [-6.4914e-01,  7.9272e-01,  8.4271e-02, -6.8839e-01,  7.2853e-01,\n",
            "          4.8514e-01, -1.2680e+00, -2.2993e-02],\n",
            "        [-1.9851e+00, -4.9992e-01, -1.9044e+00, -2.5346e+00,  7.0375e+00,\n",
            "         -4.7101e-01, -1.1327e+00,  5.7027e-03],\n",
            "        [-2.5789e-01,  1.5770e-01,  5.6970e-01, -1.3843e+00,  1.0539e+00,\n",
            "          4.6406e-01, -1.2045e+00,  2.8726e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3327e+00,  1.4279e+00,  9.8196e-01, -1.4506e+00,  2.3346e-01,\n",
            "          1.1801e+00, -1.0845e+00,  9.9951e-02],\n",
            "        [-2.4118e+00,  1.3096e+00, -1.4298e+00, -1.1040e+00,  2.5391e+00,\n",
            "         -8.1601e-01, -1.1745e+00,  1.8569e+00],\n",
            "        [-2.4114e+00,  8.0413e-01, -1.3066e+00, -1.6448e+00,  3.1214e+00,\n",
            "         -3.9379e-01, -1.1151e+00,  1.3882e+00],\n",
            "        [-2.0106e+00,  6.5130e-02, -1.8734e-01, -1.2760e+00,  3.2806e-01,\n",
            "          6.6399e+00, -7.6292e-01, -5.4480e-01],\n",
            "        [-1.8083e+00, -9.8706e-01, -1.6915e+00, -2.2158e+00,  6.9291e+00,\n",
            "         -7.0769e-01, -9.4508e-01, -9.7033e-02],\n",
            "        [-1.3873e+00,  9.3629e-01,  2.5434e-02, -8.5155e-01,  1.4137e+00,\n",
            "         -9.8804e-02, -8.2879e-01,  3.7686e-01],\n",
            "        [-1.0650e+00,  6.1339e-01,  2.9019e-01,  2.8316e-01,  6.1090e-01,\n",
            "          6.3804e-01, -5.3182e-01, -2.0051e-01],\n",
            "        [-1.3073e+00, -3.4888e-01,  8.9209e-01,  8.5287e-01,  5.4770e-01,\n",
            "          1.0214e+00, -3.4272e-01, -3.6268e-01],\n",
            "        [-9.9690e-01, -5.6940e-01,  7.4246e-01, -1.3015e+00,  1.3595e+00,\n",
            "          1.0836e+00, -4.9005e-01,  2.0600e-01],\n",
            "        [-3.0035e+00,  1.9634e+00, -2.6146e+00, -2.4479e+00,  4.6784e+00,\n",
            "         -5.8967e-01, -1.4133e+00,  1.2459e+00],\n",
            "        [-2.4719e+00,  1.4677e+00, -1.7856e+00, -3.1758e-01,  2.2461e+00,\n",
            "         -9.8330e-01, -9.7113e-01,  1.5975e+00],\n",
            "        [-1.5726e+00,  1.4980e+00, -1.0160e+00,  9.4493e-02,  1.3170e+00,\n",
            "         -3.6015e-01, -1.4185e+00,  8.8737e-01],\n",
            "        [-2.3998e+00,  7.6249e-01, -8.2304e-01, -1.1117e+00,  1.9711e+00,\n",
            "         -4.1442e-03, -8.5374e-01,  1.2821e+00],\n",
            "        [-2.1819e+00,  1.2784e+00, -1.2614e+00, -8.2048e-01,  2.2745e+00,\n",
            "         -6.2252e-01, -1.1822e+00,  1.1782e+00],\n",
            "        [-1.6314e+00, -3.0569e-01,  4.6892e-03,  7.4322e-01,  1.4035e+00,\n",
            "          2.8626e-01, -5.6207e-01,  1.4476e-01],\n",
            "        [-2.0832e+00, -1.1928e-01, -8.9269e-01, -1.0736e+00,  2.6830e+00,\n",
            "          6.1457e-02, -4.8554e-01,  1.3533e+00],\n",
            "        [-1.6407e+00, -2.4385e-01, -2.4447e-01, -1.2785e+00,  6.5938e-02,\n",
            "          6.7117e+00, -1.3116e+00, -6.7388e-01],\n",
            "        [-6.0122e-01, -1.7623e-01,  1.4432e-01, -4.9095e-01,  1.4498e+00,\n",
            "          5.8293e-01, -1.0730e+00,  6.2795e-02],\n",
            "        [-2.3444e+00,  2.2538e+00, -1.2940e+00, -1.8935e-01,  1.4935e+00,\n",
            "         -5.7449e-01, -1.2453e+00,  1.3630e+00],\n",
            "        [-2.8031e+00,  4.6365e+00, -2.3105e+00, -1.7388e+00,  1.5999e+00,\n",
            "         -1.1901e+00, -2.4581e+00,  1.6189e+00],\n",
            "        [-3.1890e+00,  1.8301e+00, -2.2065e+00, -1.2917e+00,  2.8990e+00,\n",
            "         -1.1169e+00, -1.5576e+00,  2.6334e+00],\n",
            "        [-2.1512e+00, -6.6690e-01, -1.6983e+00, -2.1195e+00,  6.7091e+00,\n",
            "         -2.9097e-01, -1.2228e+00, -2.8106e-01],\n",
            "        [-4.3642e-01, -6.9680e-01,  1.7742e+00, -4.6811e-01, -4.7536e-01,\n",
            "          1.9175e+00, -1.1329e-01, -8.6980e-01],\n",
            "        [-1.5196e+00,  9.5934e-01, -7.2206e-01, -7.7474e-01,  1.9617e+00,\n",
            "         -2.9108e-01, -1.4221e+00,  8.8671e-01],\n",
            "        [-3.8245e-01,  3.9547e-01,  5.4578e-01, -3.9895e-01,  2.2214e-01,\n",
            "          1.2369e+00, -7.4443e-01, -4.6065e-01],\n",
            "        [-2.6218e+00,  3.6460e+00, -1.8586e+00, -1.9688e+00,  1.8714e+00,\n",
            "         -1.2441e+00, -1.7940e+00,  1.6905e+00],\n",
            "        [-1.4713e+00,  2.6135e-01, -2.3396e-02, -5.2915e-01,  1.4273e+00,\n",
            "          1.8338e-01, -8.6028e-01,  7.4053e-01],\n",
            "        [ 2.2027e-01, -5.2797e-01,  6.8701e-01, -1.5169e+00,  1.4722e+00,\n",
            "          9.7887e-01, -1.2859e+00, -8.2435e-02],\n",
            "        [-1.8419e+00,  2.7367e+00,  7.5288e-01, -1.5433e+00, -4.5871e-01,\n",
            "          8.4468e-01, -1.5017e+00,  4.9862e-01],\n",
            "        [-1.5798e+00,  8.6683e-01, -1.6513e-01, -1.4736e+00,  1.5346e+00,\n",
            "          4.5304e-01, -9.0828e-01,  4.0657e-01],\n",
            "        [-1.5997e+00, -1.8548e-01,  3.6606e-01, -6.3322e-01,  1.3495e+00,\n",
            "          8.7501e-01, -5.0589e-01,  2.2553e-01],\n",
            "        [-2.4775e+00,  1.4448e+00, -1.5102e+00, -1.3708e+00,  2.9203e+00,\n",
            "         -5.1694e-01, -1.1588e+00,  1.5144e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2411,  0.0072,  0.4297, -1.0665,  1.5625,  0.6392, -0.6763,  0.1605],\n",
            "        [-1.6562, -0.0206, -0.1990, -0.2695,  2.0104,  0.2304, -0.4721,  0.4003],\n",
            "        [-1.9575, -0.0288, -0.8264,  1.4971,  1.4806, -0.4796, -0.6556,  0.2394],\n",
            "        [-2.6906,  3.4494, -1.5015,  0.5996,  0.5749, -0.6858, -1.5152,  0.0975],\n",
            "        [-2.7691,  0.4274, -1.2201, -0.4873,  0.4121, -1.5442, -1.2556,  5.5547],\n",
            "        [-1.1338,  0.3948, -0.8817,  3.2623,  0.0403,  0.0953, -1.5843, -0.0556],\n",
            "        [-2.4796,  6.4215, -1.9619, -1.9752,  0.5842, -1.8119, -1.7953,  0.2574],\n",
            "        [-0.3693, -0.5333,  1.1688,  0.3041,  0.6549,  0.3266, -0.6939, -0.4879],\n",
            "        [-0.4652,  0.3396,  1.6776, -0.9283, -0.6139,  1.6838, -0.4734, -0.5295],\n",
            "        [-1.6318, -0.8159, -1.3103, -1.7988,  6.5952, -0.2493, -1.3974, -0.7842],\n",
            "        [-2.3910,  0.0113, -1.3648, -0.4212,  0.2810, -1.3714, -0.9640,  5.1292],\n",
            "        [-3.4295,  1.7323, -2.3671, -0.6208,  1.0625, -1.7564, -2.0834,  5.4193],\n",
            "        [-2.2648,  4.5159, -1.9531, -0.8627,  1.1345, -0.9192, -2.4728,  0.7028],\n",
            "        [-0.6798, -0.5463,  0.6404, -1.4634,  1.5897,  0.6577, -1.1603,  0.1986],\n",
            "        [-2.5296,  0.4477, -0.7417, -0.4345,  1.9283, -0.2565, -0.7236,  1.7179],\n",
            "        [-1.7339,  0.6853, -0.4446, -0.8506,  1.7541, -0.2160, -1.1003,  1.1641],\n",
            "        [-1.9624, -0.0873,  0.8348, -0.5835,  0.4680,  1.1410,  0.5934, -0.1585],\n",
            "        [-3.4923,  2.1720, -2.6127, -1.5037,  3.4057, -1.4203, -1.0393,  2.2361],\n",
            "        [-2.2549,  1.6354, -1.3150, -1.7973,  2.6467, -0.2915, -1.4125,  1.5158],\n",
            "        [-2.8232,  1.7502, -1.6436, -0.5690, -0.3243, -1.9346, -1.3204,  4.9550],\n",
            "        [-2.3755,  1.2800, -1.2365, -0.6135,  2.2657, -0.3536, -0.6296,  1.0311],\n",
            "        [-1.2738, -0.8785,  2.1190, -0.9920, -0.1541,  2.7550, -0.3778, -0.4189],\n",
            "        [-1.5931, -0.5116,  5.9012, -2.3633, -0.5642,  0.2280, -0.7577, -0.5458],\n",
            "        [-1.1384,  2.9827, -1.4004, -1.7892,  1.5161, -0.8881, -2.0764,  1.2479],\n",
            "        [ 0.2592, -0.4306, -0.1216, -1.1683,  1.5209,  0.9503, -1.2852, -0.1927],\n",
            "        [-1.7913,  1.1629, -0.8163, -1.3217,  2.0739,  0.2247, -1.3649,  0.8180],\n",
            "        [-3.0474,  1.0370, -1.8430, -1.0000,  3.7458, -0.8191, -0.8930,  1.3953],\n",
            "        [-2.1246,  0.4402, -1.1328, -0.4665,  2.5945, -0.4796, -1.2406,  1.5318],\n",
            "        [-1.4126, -0.9935, -1.2315, -1.6466,  6.4642, -0.5614, -1.0502, -0.6175],\n",
            "        [-1.5713, -0.7801,  0.0239,  3.4216,  0.4128,  0.3419, -0.0845, -0.6940],\n",
            "        [ 0.1446, -0.5904,  1.9399, -1.6912,  0.1728,  0.8821, -0.8917,  0.1405],\n",
            "        [-3.1630,  0.3941, -0.7438, -1.7332,  2.9890, -0.8385, -0.8550,  2.4422]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2971, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.1306e+00,  5.7857e+00, -2.3854e+00, -2.2587e+00,  1.5861e+00,\n",
            "         -1.6912e+00, -2.3812e+00,  1.0511e+00],\n",
            "        [-2.6548e-01, -3.8401e-01, -3.2130e-01, -1.1290e+00,  1.5389e+00,\n",
            "          2.1434e-01, -1.1878e+00,  9.8058e-01],\n",
            "        [-1.0973e+00, -7.5619e-01,  1.5283e+00, -1.1629e+00,  6.2034e-01,\n",
            "          2.3069e+00, -6.1685e-01,  1.3032e-03],\n",
            "        [-7.0916e-01, -1.8852e-01,  1.5855e-01, -8.2528e-01,  1.1658e+00,\n",
            "          1.2689e+00, -9.1557e-01, -1.2567e-02],\n",
            "        [-1.2628e+00, -8.2956e-02,  8.2124e-01,  4.2645e-01,  2.5301e-01,\n",
            "          9.3819e-01, -1.3647e-01, -6.0670e-01],\n",
            "        [-1.9378e+00,  4.5480e-01, -1.0180e+00,  4.2598e-01,  1.9835e+00,\n",
            "         -5.1198e-01, -1.2434e+00,  1.0676e+00],\n",
            "        [-1.7864e+00,  3.4578e-01, -3.3899e-01, -7.0289e-01,  1.8273e+00,\n",
            "         -8.9465e-02, -8.3934e-01,  7.5394e-01],\n",
            "        [-3.3108e-01,  7.5357e-02, -3.8002e-01, -2.1392e+00,  2.3503e+00,\n",
            "          2.2640e-01, -1.6995e+00,  3.1546e-01],\n",
            "        [-2.3444e+00,  6.3265e+00, -1.6463e+00, -2.3575e+00,  4.8061e-01,\n",
            "         -1.6394e+00, -2.1560e+00,  1.0413e+00],\n",
            "        [-1.9050e+00,  2.7874e-01,  1.1826e+00, -7.6153e-01,  6.5423e-01,\n",
            "          1.1518e+00, -4.4516e-01, -5.0536e-02],\n",
            "        [-1.8759e+00,  5.3910e-01, -8.2612e-01, -1.6879e+00,  2.8758e+00,\n",
            "         -6.7484e-01, -1.5068e+00,  1.5724e+00],\n",
            "        [-1.6097e+00, -4.1800e-01,  1.7857e+00,  1.6859e-01, -7.9766e-01,\n",
            "          2.0079e+00,  4.1490e-01, -1.1281e+00],\n",
            "        [-7.1832e-01, -4.6419e-01, -1.5465e-01, -4.4776e-01,  1.3724e+00,\n",
            "          1.0160e+00, -1.1894e+00,  2.1842e-01],\n",
            "        [-1.4183e+00,  1.0796e+00, -5.9239e-01, -7.2951e-02,  1.4520e+00,\n",
            "         -1.5060e-02, -1.2823e+00,  4.7478e-01],\n",
            "        [-1.2505e+00, -2.7647e-01,  4.2938e-01, -1.3646e+00,  2.1814e+00,\n",
            "          5.0402e-01, -1.1146e+00,  5.2613e-01],\n",
            "        [-8.4766e-01, -1.4050e-01, -5.0175e-01,  3.3197e-01,  1.4292e+00,\n",
            "          8.5274e-01, -1.1632e+00, -1.8110e-01],\n",
            "        [-3.0409e+00,  5.9231e-01, -1.4775e+00, -1.0868e+00,  2.9620e+00,\n",
            "         -4.0059e-01, -8.9463e-01,  1.7395e+00],\n",
            "        [-1.6568e+00,  2.7510e-01, -3.8112e-01, -3.5653e-01,  1.8039e+00,\n",
            "          8.2958e-02, -9.7119e-01,  7.5683e-01],\n",
            "        [-2.6648e+00,  9.7942e-01, -1.5758e+00, -1.0747e+00,  2.8397e+00,\n",
            "         -8.6338e-01, -1.1002e+00,  2.0251e+00],\n",
            "        [-4.1207e-01, -4.1209e-01,  2.6990e+00, -6.8838e-01, -8.0963e-01,\n",
            "          1.9722e+00, -2.1750e-01, -9.5786e-01],\n",
            "        [-9.4778e-01,  2.2283e-01,  1.8765e-01, -4.8620e-01,  1.1682e+00,\n",
            "          3.2337e-01, -8.5329e-01,  1.6128e-01],\n",
            "        [-2.1877e+00,  2.6300e+00, -1.3606e+00, -1.6155e+00,  2.2402e+00,\n",
            "         -2.1496e-01, -1.0893e+00,  6.6251e-01],\n",
            "        [-2.4600e+00,  2.6257e+00, -2.3373e+00, -2.5119e-01,  1.8835e+00,\n",
            "         -8.3356e-01, -1.9464e+00,  1.5511e+00],\n",
            "        [-1.0416e+00, -3.8361e-01,  3.9142e-01, -1.4212e+00,  1.4594e+00,\n",
            "          5.0924e-01, -1.1254e+00,  7.3423e-01],\n",
            "        [-3.2947e+00,  2.9683e+00, -2.4358e+00, -1.0715e+00,  2.1615e+00,\n",
            "         -1.3180e+00, -1.7406e+00,  2.5187e+00],\n",
            "        [-2.2475e+00,  1.1553e+00, -1.5587e+00, -1.8913e+00,  3.1762e+00,\n",
            "         -1.3472e-01, -1.4039e+00,  1.6327e+00],\n",
            "        [-2.6129e+00,  3.8297e-01, -1.0276e+00, -1.5175e+00,  3.2799e+00,\n",
            "         -2.3267e-01, -9.5289e-01,  1.5168e+00],\n",
            "        [-1.6886e+00,  4.8835e-01, -6.8312e-01, -7.3627e-01,  1.9501e+00,\n",
            "          6.6675e-01, -1.2203e+00,  9.0993e-01],\n",
            "        [-1.6707e-01, -8.7121e-01,  2.3548e+00, -1.0406e+00, -5.0363e-01,\n",
            "          2.5350e+00, -8.9904e-01, -7.7948e-01],\n",
            "        [-3.1409e-01,  6.2447e-01,  4.1008e-01,  7.6116e-02,  3.4486e-01,\n",
            "          6.3573e-01, -8.9219e-01, -4.0453e-01],\n",
            "        [-3.5866e+00,  3.1497e+00, -2.4151e+00,  4.7105e+00, -6.3323e-01,\n",
            "         -1.4306e+00, -4.6471e-01, -1.3414e-01],\n",
            "        [-2.7343e+00,  4.9323e-01, -1.8477e+00, -1.6388e+00,  3.7068e+00,\n",
            "         -3.9940e-01, -1.3841e+00,  1.9498e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2869, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.0544e+00,  4.5503e-01, -3.5531e-01, -6.8919e-01,  1.7552e+00,\n",
            "          1.8455e-01, -1.3275e+00,  5.0739e-01],\n",
            "        [-2.1103e+00,  2.3120e+00, -1.2940e+00, -1.3420e+00,  2.1249e+00,\n",
            "         -6.0301e-01, -1.2132e+00,  9.3524e-01],\n",
            "        [-1.3323e+00, -1.1278e+00, -1.4012e+00, -1.6014e+00,  6.8262e+00,\n",
            "         -3.0667e-01, -1.3913e+00, -6.8237e-01],\n",
            "        [-6.3267e-01, -6.3554e-02,  5.9218e-01, -4.2039e-01,  8.5067e-01,\n",
            "          1.0191e+00, -5.0100e-01, -2.6386e-01],\n",
            "        [-2.4536e+00,  5.3342e-01, -1.1053e+00, -1.3498e+00,  2.6766e+00,\n",
            "         -1.6580e-01, -1.1177e+00,  2.0201e+00],\n",
            "        [-2.6475e+00,  6.4741e+00, -1.5781e+00, -1.8444e+00,  1.1928e-01,\n",
            "         -1.0840e+00, -2.0404e+00,  1.6502e-02],\n",
            "        [-2.5811e+00,  1.5307e+00, -8.4325e-01, -9.1796e-01,  1.7435e+00,\n",
            "         -1.4868e-01, -1.2798e+00,  1.5378e+00],\n",
            "        [-2.7072e+00,  1.4483e+00, -1.9044e+00, -1.6011e+00,  3.0668e+00,\n",
            "         -9.1682e-01, -1.6155e+00,  2.4029e+00],\n",
            "        [-2.3597e+00,  1.6920e+00, -7.4117e-01, -4.0472e-01,  1.0517e+00,\n",
            "         -5.2216e-01, -9.3858e-01,  1.1131e+00],\n",
            "        [-2.9771e+00,  7.6934e-01, -1.6668e+00, -8.4799e-03,  2.3140e+00,\n",
            "         -8.0671e-01, -1.3056e+00,  2.5238e+00],\n",
            "        [-2.5283e+00,  2.6524e+00, -2.0829e+00, -1.6574e+00,  2.8747e+00,\n",
            "         -8.1478e-01, -1.7288e+00,  1.5609e+00],\n",
            "        [-1.7041e+00, -8.4517e-01, -1.4005e+00, -2.0563e+00,  6.7916e+00,\n",
            "         -5.7777e-01, -1.0305e+00, -4.3498e-01],\n",
            "        [-1.3137e+00, -1.0476e-01, -3.3434e-01, -1.2667e+00,  7.8851e-02,\n",
            "          6.5109e+00, -1.1107e+00, -7.9957e-01],\n",
            "        [-8.5276e-01, -3.3683e-01,  2.6345e+00, -7.8105e-01, -1.6040e+00,\n",
            "          3.1239e+00, -5.8738e-01, -1.4032e+00],\n",
            "        [-1.2661e+00,  1.8571e-01, -2.4171e-01,  4.1730e-01,  1.3379e+00,\n",
            "          2.5351e-01, -5.0538e-01, -2.9179e-01],\n",
            "        [-2.8774e+00,  4.3549e+00, -2.4762e+00, -1.9969e+00,  2.3051e+00,\n",
            "         -1.3718e+00, -2.3433e+00,  1.7949e+00],\n",
            "        [-1.6327e+00, -2.1166e-01,  1.5038e-01, -5.3468e-01,  1.6425e+00,\n",
            "          4.1633e-01, -4.0143e-01,  4.9396e-01],\n",
            "        [-2.0464e+00,  1.1046e+00, -6.1418e-01,  1.3382e-01,  1.6686e+00,\n",
            "         -2.3423e-01, -7.2151e-01,  3.9766e-01],\n",
            "        [-2.0456e+00, -4.1429e-01,  1.8794e+00,  9.1169e-01, -1.2249e+00,\n",
            "          2.7573e+00,  2.8140e-01, -1.0682e+00],\n",
            "        [-9.7261e-01,  1.7498e-01, -4.2055e-02, -1.0383e+00,  2.2877e+00,\n",
            "         -8.8247e-02, -1.1110e+00,  5.7281e-01],\n",
            "        [-2.7688e+00,  1.3630e+00, -2.0329e+00, -1.9830e+00,  3.9059e+00,\n",
            "         -2.4390e-01, -1.1604e+00,  1.5976e+00],\n",
            "        [-3.0424e+00,  3.3579e+00, -2.2633e+00, -1.7666e+00,  2.3378e+00,\n",
            "         -1.1107e+00, -1.8659e+00,  2.0865e+00],\n",
            "        [-2.5598e+00,  6.7982e-01, -1.5746e+00, -1.7763e+00,  3.5928e+00,\n",
            "         -5.8735e-01, -1.4043e+00,  1.9223e+00],\n",
            "        [-1.6115e+00, -6.5846e-02, -6.3314e-03, -4.1978e-02,  1.0462e+00,\n",
            "          6.9519e-01, -3.8212e-01,  4.8945e-01],\n",
            "        [-2.2304e+00,  8.7245e-01, -4.9122e-01, -8.2851e-01,  1.6620e+00,\n",
            "          3.3423e-01, -6.2881e-01,  9.4522e-01],\n",
            "        [-1.2309e+00, -2.7212e-01,  1.8180e-01, -1.3199e-02,  1.4100e+00,\n",
            "          5.6746e-01, -6.9610e-01,  3.1345e-01],\n",
            "        [-2.3679e+00,  3.3157e+00, -1.8236e+00,  1.6336e+00,  4.5148e-01,\n",
            "         -1.0178e+00, -2.1868e+00,  5.8396e-01],\n",
            "        [-2.2956e+00,  3.8564e+00, -1.9229e+00, -1.7313e+00,  1.9111e+00,\n",
            "         -3.0433e-01, -2.0775e+00,  6.8383e-01],\n",
            "        [-1.9975e+00,  2.1434e+00, -1.3213e+00,  8.2771e-01,  1.2991e+00,\n",
            "          2.6356e-01, -1.5231e+00, -1.0057e-01],\n",
            "        [-1.4407e+00, -6.2482e-01, -1.2266e+00, -2.0032e+00,  6.6312e+00,\n",
            "          9.3904e-02, -1.0325e+00, -7.2539e-01],\n",
            "        [-2.6708e+00,  4.1606e+00, -2.0980e+00, -1.7790e+00,  2.0842e+00,\n",
            "         -1.1153e+00, -2.2384e+00,  1.3988e+00],\n",
            "        [-8.0956e-01,  1.2384e+00, -3.7561e-01,  2.1047e-01,  8.1372e-01,\n",
            "         -4.0077e-02, -1.1098e+00, -1.6642e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0842, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.8125e+00, -3.6330e-01,  2.1758e+00, -2.2907e-01, -7.7758e-01,\n",
            "          2.5766e+00,  2.2957e-01, -9.5556e-01],\n",
            "        [-3.5379e-01,  1.4227e-01,  1.0939e+00, -2.1393e-01, -2.6463e-01,\n",
            "          1.3329e+00,  8.4289e-02, -9.3405e-01],\n",
            "        [-1.5716e+00, -6.5892e-01,  4.8102e-01,  2.6915e+00,  1.7623e-01,\n",
            "          3.6163e-01,  2.0499e-01, -3.4577e-01],\n",
            "        [-2.5254e+00,  1.5914e+00, -1.3039e+00, -7.0997e-01,  2.0274e+00,\n",
            "         -3.4388e-01, -1.0021e+00,  1.1388e+00],\n",
            "        [-2.1444e+00,  4.6831e-01, -7.5138e-01, -1.6215e-01,  1.5967e+00,\n",
            "          1.5182e-01, -1.1046e+00,  1.3353e+00],\n",
            "        [-2.8477e+00,  3.2600e+00, -2.1411e+00, -1.6847e+00,  2.4604e+00,\n",
            "         -9.9610e-01, -1.5456e+00,  1.0989e+00],\n",
            "        [-1.4070e+00,  1.6739e+00, -1.2379e+00, -5.8150e-01,  1.3488e+00,\n",
            "          7.3170e-02, -1.9709e+00,  1.0196e+00],\n",
            "        [-1.8284e+00,  4.5340e-01, -6.3507e-01,  9.7175e-02,  1.5646e+00,\n",
            "          4.2700e-02, -1.0225e+00,  5.9693e-01],\n",
            "        [-1.4681e+00,  2.4063e-01,  2.7305e-02, -1.3121e+00,  2.1109e+00,\n",
            "          2.7463e-02, -1.2185e+00,  8.8315e-01],\n",
            "        [-2.3921e+00,  2.2313e+00, -1.1129e+00, -1.3248e-01,  1.3954e+00,\n",
            "         -4.7175e-01, -1.6187e+00,  9.8566e-01],\n",
            "        [-1.5518e+00, -7.7201e-01,  8.2959e-01, -9.2889e-01,  1.2284e+00,\n",
            "          7.7070e-01, -6.2203e-01,  1.0072e+00],\n",
            "        [-1.9277e+00, -5.4045e-01, -2.7937e-01, -6.1061e-01,  2.2584e+00,\n",
            "          6.9346e-01, -6.1720e-01,  5.6216e-01],\n",
            "        [-1.5259e+00,  9.3415e-01,  5.1900e-01, -6.9023e-01,  1.6520e-01,\n",
            "          5.9941e-01, -1.5249e+00,  9.7259e-01],\n",
            "        [-1.7502e+00,  5.9000e-01, -4.2454e-01,  5.2922e-01,  1.2835e+00,\n",
            "          3.0627e-01, -1.0085e+00,  2.9752e-01],\n",
            "        [-2.1312e+00,  1.4725e+00, -7.9890e-01, -1.0264e+00,  5.7969e-01,\n",
            "         -8.0337e-01, -1.7474e+00,  3.3025e+00],\n",
            "        [-2.6092e+00,  6.5545e-01, -1.3032e+00, -2.0738e+00,  4.6434e+00,\n",
            "         -2.5133e-01, -8.9626e-01,  5.3400e-01],\n",
            "        [-1.2191e-01,  3.3928e-01,  7.3688e-01, -2.2174e-01, -5.6161e-01,\n",
            "          1.5089e+00, -2.9477e-01, -8.6545e-01],\n",
            "        [-1.7922e+00, -1.4059e+00,  5.0326e-01, -7.5255e-01, -2.7510e-01,\n",
            "         -8.9735e-01,  6.0604e+00, -3.7931e-01],\n",
            "        [-8.4735e-01, -4.0030e-01,  2.9657e+00, -1.3936e+00, -5.1914e-01,\n",
            "          1.9251e+00, -9.8847e-01, -5.8590e-01],\n",
            "        [-1.7318e+00,  9.6217e-02, -4.2067e-01, -1.0790e-01,  1.8166e+00,\n",
            "          2.6473e-01, -1.0670e+00,  7.1969e-01],\n",
            "        [-2.7376e+00,  2.0484e+00, -2.8203e+00, -5.6992e-01,  2.0001e+00,\n",
            "         -1.0414e+00, -2.1458e+00,  3.5928e+00],\n",
            "        [-3.2278e+00,  6.0549e-01, -2.3518e+00, -1.0232e+00,  1.8523e+00,\n",
            "         -1.3883e+00, -1.8042e+00,  5.1032e+00],\n",
            "        [-1.7417e+00, -5.9124e-01,  2.0232e+00, -1.0947e+00, -4.2755e-02,\n",
            "          1.9079e+00, -4.4702e-01,  1.3803e-03],\n",
            "        [-1.3980e+00, -2.5614e-02, -1.3575e+00,  4.7960e+00, -1.6697e-01,\n",
            "         -7.5581e-01, -8.1703e-01, -2.3973e-01],\n",
            "        [-1.2076e+00, -2.8129e-01,  3.1351e-01, -9.1738e-01,  1.7304e+00,\n",
            "          4.1142e-01, -7.2008e-01,  5.9708e-01],\n",
            "        [ 1.2369e+00,  6.0859e-01,  3.4871e-01, -9.8039e-01, -3.1516e-01,\n",
            "          1.1250e+00, -1.1694e+00, -7.5568e-01],\n",
            "        [-1.3310e+00, -1.5789e-02,  1.3600e+00, -5.9472e-01, -1.5697e-01,\n",
            "          1.6873e+00,  4.9560e-02, -5.2828e-01],\n",
            "        [ 3.0061e-01,  2.6719e-01,  1.7244e-01,  1.2388e-01,  3.6635e-01,\n",
            "          1.0873e+00, -1.3195e+00, -5.2977e-01],\n",
            "        [-1.4382e+00, -9.8743e-01, -1.1676e+00, -1.6162e+00,  6.7706e+00,\n",
            "         -5.5914e-01, -1.1539e+00, -7.7459e-01],\n",
            "        [-7.5620e-01, -6.8324e-01,  6.0640e-01, -6.9674e-03,  8.4311e-01,\n",
            "          1.2995e+00, -8.5602e-01, -2.4889e-01],\n",
            "        [-3.0592e+00,  1.0104e+00, -2.5394e+00, -2.5579e+00,  5.8257e+00,\n",
            "         -3.8705e-01, -1.2024e+00,  8.5136e-01],\n",
            "        [-9.4549e-01, -3.4246e-01,  2.1464e+00, -6.3404e-01, -1.2692e+00,\n",
            "          3.3003e+00, -6.3626e-01, -8.8223e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5407,  6.4374, -1.8413, -1.4846,  0.4164, -1.8159, -1.6376,  0.3817],\n",
            "        [-2.7188,  1.4226, -1.7963, -0.4654,  2.4947, -0.6907, -1.1627,  1.7322],\n",
            "        [-2.7262,  0.4911, -1.3502, -2.0751,  4.3886,  0.1297, -0.7053,  0.4880],\n",
            "        [-1.8050, -0.5072,  0.1578, -0.3901,  1.5927,  0.4957, -0.7393,  0.8615],\n",
            "        [-1.0006, -0.2328,  0.2663, -1.3130,  1.0462,  1.1545, -0.5269,  0.1925],\n",
            "        [-2.9227,  1.2264, -1.7159, -1.3360,  3.2681, -0.2466, -0.5231,  1.2234],\n",
            "        [-2.7115,  3.3579, -2.3744, -1.0363,  2.3848, -1.1815, -2.2463,  1.5220],\n",
            "        [-1.4689, -1.0286,  2.5775, -1.6495, -0.3704,  1.7441, -0.6668,  0.8859],\n",
            "        [ 0.8666, -1.0031,  1.2779,  0.2195,  0.1858,  0.8873, -1.1114, -0.8607],\n",
            "        [ 1.2217, -0.2793,  1.3871, -0.7499, -0.6613,  1.3917, -0.3841, -1.1093],\n",
            "        [-1.8552,  0.9395, -1.2286, -1.1751,  2.4681, -0.1265, -1.4181,  1.3154],\n",
            "        [-3.2351,  3.2373, -2.5446, -1.7617,  2.9869, -0.8757, -1.6941,  1.7855],\n",
            "        [-2.3419,  2.0360, -0.9015, -1.0293,  1.3370, -0.4274, -1.5755,  1.1368],\n",
            "        [-1.6215, -0.3111,  1.5448, -0.8355,  0.0568,  1.6243, -0.6866,  0.4259],\n",
            "        [-1.0716, -1.3000,  2.4012, -0.7422, -0.3201,  2.8864, -0.5590, -0.5364],\n",
            "        [-1.3499, -0.3412,  0.0380, -1.1802,  2.3124,  0.3059, -1.0479,  0.6355],\n",
            "        [ 0.3053, -0.4159,  0.5365, -0.7062,  0.3929,  2.2048, -1.0006, -0.7570],\n",
            "        [-2.7525,  1.0689, -1.9469, -1.2055,  2.9001, -0.9773, -1.3781,  2.6053],\n",
            "        [-1.3677, -0.1809,  1.8543,  0.0283, -1.2893,  2.7475,  0.0204, -1.0184],\n",
            "        [ 0.1731,  0.3472,  0.4792, -0.1160,  0.1654,  1.2003, -0.9624, -0.6717],\n",
            "        [-3.2361,  3.5717, -2.4849, -2.0078,  2.4870, -1.5490, -2.0166,  2.5963],\n",
            "        [-1.3201,  0.2029,  0.5198, -0.1741,  0.9019,  0.7428, -0.7804, -0.0211],\n",
            "        [-0.6273, -0.4042,  1.6098, -1.2458,  0.2448,  1.7787, -0.2875, -0.5770],\n",
            "        [-2.4610,  6.0664, -1.9397, -1.7458,  0.4131, -1.6375, -1.8904,  0.8884],\n",
            "        [-1.2528,  0.1261, -0.2137,  1.0825,  0.9563,  0.2133, -0.9172,  0.1948],\n",
            "        [-2.9986,  1.8093, -2.7549, -0.8149,  1.2504, -1.4665, -2.0511,  4.7313],\n",
            "        [-2.0104,  0.6677,  0.0937, -1.6233,  1.3624,  1.1476, -0.8173,  0.9712],\n",
            "        [-1.9847,  1.8007, -0.7860,  0.2549,  1.0995, -0.3837, -1.2188,  0.4597],\n",
            "        [-1.1371,  0.8888,  0.6682,  0.0573,  0.1759,  0.7119, -0.5559, -0.5068],\n",
            "        [-0.9983, -0.4278,  1.2553, -0.6299,  0.1111,  1.5345, -0.0465, -0.2798],\n",
            "        [-1.4152, -0.9732, -1.1351, -1.9935,  6.7889, -0.6039, -1.1011, -0.3524],\n",
            "        [-1.7392, -0.0682,  0.2454, -0.0942,  1.1738,  1.1550, -0.2797, -0.2507]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.9855e+00,  4.9151e+00, -2.2190e+00, -1.6266e+00,  1.3731e+00,\n",
            "         -1.0439e+00, -2.3611e+00,  5.1889e-01],\n",
            "        [-8.0901e-01, -6.9956e-01,  1.2329e+00, -7.7399e-01,  1.2108e+00,\n",
            "          1.5863e+00, -6.7752e-01, -6.7686e-01],\n",
            "        [-1.6761e+00, -3.1299e-01,  2.5624e-01,  1.0189e+00,  9.0775e-01,\n",
            "          7.7477e-01, -2.2720e-01, -3.7011e-01],\n",
            "        [-1.9229e+00, -6.0646e-01, -3.3290e-01,  3.6543e-01, -2.9994e-01,\n",
            "          6.3997e+00, -4.5288e-01, -1.0790e+00],\n",
            "        [-8.2759e-01,  4.6974e-01,  6.6565e-01, -3.2644e-01,  7.6570e-02,\n",
            "          1.7309e+00, -4.5760e-01, -6.7185e-01],\n",
            "        [-2.3552e+00,  1.0901e-01, -4.0356e-01, -9.7002e-01,  2.2334e+00,\n",
            "          3.0556e-01, -8.5240e-01,  1.1673e+00],\n",
            "        [-2.7384e+00,  1.8949e+00, -1.4762e+00,  5.0553e-01,  1.8450e+00,\n",
            "         -6.3647e-01, -1.3299e+00,  1.0270e+00],\n",
            "        [-2.7569e+00,  4.3562e-01, -1.0802e+00, -7.1034e-01,  3.2948e+00,\n",
            "         -2.8094e-01, -9.7392e-01,  1.3023e+00],\n",
            "        [-1.4226e+00,  2.9485e-01,  1.7272e-01,  8.2978e-02,  9.9665e-01,\n",
            "          8.0644e-01, -7.1310e-01, -3.2720e-02],\n",
            "        [-2.0887e+00,  1.0434e-01, -2.4461e-01, -1.1629e+00,  2.2422e+00,\n",
            "          3.4746e-01, -7.1294e-01,  8.8803e-01],\n",
            "        [-1.9165e+00, -3.2716e-01, -1.5840e+00, -2.1637e+00,  6.7246e+00,\n",
            "         -5.3330e-01, -1.0049e+00, -3.1279e-01],\n",
            "        [-2.7005e+00,  3.1183e+00, -1.9787e+00, -1.8575e+00,  2.2315e+00,\n",
            "         -7.7393e-01, -1.7367e+00,  1.4311e+00],\n",
            "        [-1.1964e+00,  8.4870e-01, -2.7518e-01,  3.5496e-01,  7.9548e-01,\n",
            "          4.4931e-01, -8.4856e-01, -1.5534e-01],\n",
            "        [-1.8185e+00, -6.2927e-02,  1.4476e-01, -7.1271e-01,  1.0999e+00,\n",
            "          6.5356e-01, -5.2250e-01,  9.7337e-01],\n",
            "        [-1.0647e+00,  2.3755e-02, -2.0716e-01, -3.2259e-01,  1.2663e+00,\n",
            "          7.5280e-01, -8.1432e-01,  2.6637e-01],\n",
            "        [-1.6926e+00, -9.9443e-01, -1.2402e+00, -1.7004e+00,  6.6361e+00,\n",
            "         -2.7916e-01, -1.3108e+00, -6.9180e-01],\n",
            "        [-1.0271e+00, -7.0353e-01,  1.1074e+00, -4.1205e-01,  6.0136e-01,\n",
            "          1.4358e+00, -2.8334e-01,  3.0739e-03],\n",
            "        [-1.3260e+00,  7.0981e-01,  6.9405e-01, -7.8153e-01,  7.3237e-01,\n",
            "          2.7225e-01, -6.2415e-01,  1.5373e-01],\n",
            "        [ 6.5624e+00, -4.9883e-01, -1.2364e+00, -1.1017e+00, -5.1549e-01,\n",
            "         -1.1339e+00, -1.4587e+00, -8.5614e-01],\n",
            "        [-1.5579e+00, -4.3140e-01,  6.7727e-01,  1.4423e-01,  4.5551e-01,\n",
            "          8.7504e-01, -4.4367e-01,  2.7546e-01],\n",
            "        [-7.8741e-01, -1.0071e+00,  2.8072e+00, -1.1350e+00, -5.5791e-01,\n",
            "          2.5005e+00,  2.2659e-01, -9.2239e-01],\n",
            "        [-2.3610e+00, -8.2494e-01,  4.6236e-01, -1.3048e-01, -3.7300e-01,\n",
            "         -7.1532e-01,  5.3369e+00, -1.9788e-01],\n",
            "        [-1.9394e+00,  6.4917e+00, -1.5137e+00, -1.8847e+00, -1.4658e-01,\n",
            "         -1.4867e+00, -1.1907e+00,  4.0302e-01],\n",
            "        [-1.2761e+00,  7.5101e-01,  2.2776e+00, -4.5398e-01,  6.9267e-02,\n",
            "          8.9272e-01, -1.3218e+00, -1.0289e+00],\n",
            "        [-2.3108e+00,  2.0256e+00, -1.2846e+00,  2.6820e-02,  1.4821e+00,\n",
            "         -5.3516e-01, -1.5687e+00,  1.3444e+00],\n",
            "        [-7.1431e-01, -5.9769e-01,  1.7052e+00, -5.0240e-01,  2.7726e-01,\n",
            "          1.3570e+00, -3.4542e-01, -5.7595e-01],\n",
            "        [-2.5370e+00,  3.0243e+00, -1.4120e+00, -1.0765e+00,  1.2327e+00,\n",
            "         -5.9113e-01, -1.8957e+00,  1.7150e+00],\n",
            "        [-2.5363e+00,  5.0122e-01, -1.4916e+00, -1.7810e+00,  3.7824e+00,\n",
            "         -4.3944e-01, -7.3096e-01,  1.2329e+00],\n",
            "        [-4.5851e-01, -8.0219e-02, -5.7689e-02, -2.1180e-01,  1.1259e+00,\n",
            "          1.7990e+00, -1.2406e+00, -2.3876e-01],\n",
            "        [-2.5167e+00, -1.2792e-02, -7.9886e-01,  1.0879e+00,  1.8319e+00,\n",
            "          1.1680e-01, -8.2157e-01,  9.0359e-01],\n",
            "        [-1.7292e+00, -1.0719e+00, -1.1575e+00, -1.7183e+00,  6.7271e+00,\n",
            "         -2.1587e-01, -8.7613e-01, -8.5390e-01],\n",
            "        [-1.8674e+00, -1.8961e-02,  4.1343e-01, -2.8896e-01,  1.4278e+00,\n",
            "          4.8650e-01,  2.4287e-01, -1.3279e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9673, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.2905,  6.6108, -1.6383, -1.7788, -0.2730, -1.3416, -0.8160, -0.4331],\n",
            "        [-2.2475,  4.2133, -1.7473, -1.1695,  1.4989, -0.8765, -1.8325,  0.4212],\n",
            "        [-2.5458,  5.9821, -1.7415, -2.0207,  0.6514, -1.2604, -1.5260, -0.1836],\n",
            "        [-1.9058,  1.8378, -0.9252,  0.0728,  1.2522, -0.6418, -1.4908,  0.4647],\n",
            "        [-2.0474, -0.2905, -0.3306, -1.2764,  2.4786,  1.0907, -0.4262,  0.3986],\n",
            "        [-1.8229, -0.5495,  1.7922,  0.4300,  0.0672,  1.5412,  0.4118, -1.0385],\n",
            "        [-1.7236, -0.7853,  2.2259, -1.0653, -0.3812,  2.6681, -0.1222, -0.3161],\n",
            "        [-2.4611,  2.2032, -1.1578,  0.2973,  0.8812, -0.3836, -1.2341,  1.0545],\n",
            "        [-1.1861, -0.8108,  0.6395,  2.2660,  0.0276,  0.6291, -0.3671, -0.7742],\n",
            "        [-2.8133,  0.9760, -1.5622, -1.5243,  2.9749, -0.4007, -0.9652,  1.6948],\n",
            "        [-1.9791, -0.2036, -1.4296,  5.2713,  0.2465, -0.1697, -1.5682, -0.1961],\n",
            "        [-2.4563,  1.5634, -0.6868, -0.3148,  1.3805, -0.0572, -0.9898,  0.9015],\n",
            "        [-1.7391,  1.3581,  0.4647, -1.2612,  0.4117,  1.7143, -1.3809,  0.2508],\n",
            "        [-2.5963,  6.4591, -1.8789, -1.8625,  0.4526, -1.4801, -1.2263,  0.0513],\n",
            "        [-0.9147, -0.7761,  0.7008,  0.4785,  0.7969,  0.8593, -0.8074, -0.2829],\n",
            "        [-2.7492,  1.3692, -2.0012, -1.6082,  3.3142, -1.0019, -1.5667,  2.8216],\n",
            "        [-2.5727,  6.3503, -1.8538, -1.8119,  0.4074, -1.6016, -1.2051, -0.2728],\n",
            "        [-1.7568, -0.6740, -1.2089, -1.7336,  6.6460, -0.2763, -1.0908, -0.7732],\n",
            "        [-2.6265,  3.1826,  0.1819, -0.8720, -0.6269,  0.8637, -1.3975,  0.0688],\n",
            "        [-2.1297,  0.7194, -1.8323, -0.4883,  1.0709, -0.8255, -2.0437,  4.3156],\n",
            "        [-0.9277, -0.2056,  1.9424, -1.5553,  0.0579,  1.7527, -0.6067, -0.1668],\n",
            "        [-2.2294,  2.8597, -1.2358,  0.2408,  1.3351, -0.9466, -0.7542, -0.0977],\n",
            "        [-2.4411,  0.2932, -0.0939, -0.9468,  1.7540,  0.7275, -0.5887,  0.9044],\n",
            "        [ 0.5817, -0.7604,  1.4745, -0.1762,  0.3262,  0.9801, -1.0789, -0.8403],\n",
            "        [-1.4374, -0.8250, -1.2558, -1.7538,  6.5215, -0.5626, -1.0437, -0.7208],\n",
            "        [-2.8618,  1.8261, -2.0549, -1.0703,  2.7916, -0.8939, -1.2788,  1.9227],\n",
            "        [-2.6604,  3.7405, -1.8992, -1.7323,  2.4032, -1.1107, -1.7652,  0.8125],\n",
            "        [-1.1831,  0.7077, -0.0239, -0.5218,  1.3813, -0.0909, -1.2995,  0.1141],\n",
            "        [-1.9178,  1.4928, -0.6234,  0.2073,  1.0655,  0.0099, -1.2361,  0.0875],\n",
            "        [-0.1589, -0.7453,  1.1756, -1.0770,  0.8050,  1.3205, -0.8422, -0.3634],\n",
            "        [-0.6472, -0.7006,  0.9879,  0.0341,  0.5746,  1.1771, -0.5671, -0.3213],\n",
            "        [-3.0539,  3.8198, -1.9511, -2.1792,  2.8345, -1.5966, -1.6186,  0.8963]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.6358, -0.2703, -0.1914,  0.5381,  1.3686,  0.8293, -1.2614, -0.2237],\n",
            "        [-0.6246, -0.6954,  1.4607, -0.3937,  0.5147,  1.3196, -0.6087, -0.3819],\n",
            "        [-1.6517,  1.8149, -0.4088, -0.0656,  0.7601,  0.4361, -1.2926,  0.2859],\n",
            "        [-1.3517, -0.4726,  2.0737, -0.6776, -0.0430,  2.0809, -0.6089, -0.5709],\n",
            "        [-2.8054,  0.9729, -1.3469, -0.5832,  2.5534, -0.5527, -1.1567,  1.9746],\n",
            "        [-1.2289, -0.5342,  5.3392, -1.5366, -1.3935,  0.1386,  0.6036, -1.1862],\n",
            "        [-1.1145, -0.8917,  2.5980, -0.9325, -0.9022,  2.7530, -0.5914, -0.4233],\n",
            "        [-2.2258,  0.7142, -0.9543, -0.6686,  1.5391,  0.0810, -1.3628,  2.1180],\n",
            "        [-1.6973,  0.2779, -0.1132, -0.3557,  1.6756,  0.6366, -0.7716,  0.2386],\n",
            "        [-1.9753, -0.2641, -0.9769, -1.3921,  3.2802,  0.0705, -0.5722,  1.1973],\n",
            "        [-1.8073,  2.3319, -1.1507, -0.1430,  1.1628, -0.2149, -1.3830,  0.4296],\n",
            "        [-1.5281,  0.4280,  0.2051,  0.6925,  0.2785,  1.2588, -0.0856, -0.4470],\n",
            "        [-0.6665,  0.2320,  0.1506, -0.5145,  1.5386,  0.4268, -1.1085, -0.0898],\n",
            "        [-2.8887, -0.0753, -0.2381,  2.5141,  0.8148, -0.1800,  0.7863, -0.4021],\n",
            "        [-0.2615, -0.7127,  2.8544, -0.9577, -0.8628,  2.8302, -0.3128, -1.3223],\n",
            "        [-1.6484,  0.5583, -0.2899, -0.4048,  1.3501,  0.8735, -0.5757,  0.1638],\n",
            "        [-1.6710,  1.3010, -0.6483, -0.4626,  1.6999,  0.0988, -1.1784,  0.4389],\n",
            "        [-1.5554,  0.4060, -0.4862, -0.6852,  1.4372,  0.4941, -1.3896,  1.3358],\n",
            "        [-2.3995, -0.4781,  0.0805,  3.1828,  0.4944,  0.0602, -0.2475, -0.4885],\n",
            "        [-2.2165,  0.1393, -0.4322, -1.1800,  2.2568,  0.9274, -0.7312,  0.8650],\n",
            "        [-1.4578,  0.2460, -0.1414,  3.9334, -0.1127, -0.3995, -0.1485, -1.1315],\n",
            "        [-2.0420,  0.2231,  1.0540, -0.3493, -0.2672,  1.8235, -0.3973,  0.1130],\n",
            "        [-2.4038,  1.6218, -0.5404,  0.2195,  1.0534,  0.0419, -0.9144,  0.6016],\n",
            "        [-2.0848,  0.2796, -0.6903, -1.2517,  2.3587,  0.2271, -0.6739,  1.0464],\n",
            "        [-1.4958, -0.4873,  1.7633, -0.4726, -0.1221,  2.5856,  0.1334, -0.8836],\n",
            "        [-0.7590,  0.0731,  1.6625, -0.4932, -0.6326,  1.6674,  0.3058, -0.8787],\n",
            "        [-1.4173, -1.0363,  4.4878, -1.7123, -1.3163,  2.5755, -0.3405, -0.5382],\n",
            "        [-0.5236, -0.9221,  1.8812, -0.4367,  0.1280,  1.9793, -0.6020, -0.7979],\n",
            "        [-0.5655, -0.9475,  1.1746, -0.5425,  0.6919,  1.5351, -0.7484, -0.1250],\n",
            "        [-1.3344, -0.3243,  0.1600, -0.1255,  1.0846,  0.8526, -0.1890, -0.2601],\n",
            "        [-2.1742,  2.9019, -1.0947, -1.3882,  1.1923, -0.1043, -1.3624,  0.6901],\n",
            "        [ 0.4871, -1.1114,  2.2333, -0.8966, -0.0258,  1.4334, -0.8056, -0.9438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1984, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1090, -0.1199, -0.6175, -0.9610,  2.5689,  0.1642, -0.9528,  0.9327],\n",
            "        [-1.4271, -0.2756, -0.0362, -0.3229,  1.7619,  0.9011, -0.5083,  0.1921],\n",
            "        [-2.3905,  6.6178, -1.9009, -1.9560,  0.4028, -1.3293, -1.3049, -0.0216],\n",
            "        [-2.1584,  1.4742, -1.3311, -1.8181,  3.3143,  0.5280, -1.3876,  0.3215],\n",
            "        [-2.4383,  1.3684, -0.6457, -0.6611,  1.8834, -0.0311, -0.8056,  0.5190],\n",
            "        [-1.0462, -0.8371,  1.4858,  1.1786, -0.1597,  1.5570, -0.0913, -1.0510],\n",
            "        [-3.0390,  0.7364, -1.6282, -1.7355,  4.0932, -0.3373, -0.4839,  0.7051],\n",
            "        [-1.1995,  1.2719, -0.5652, -0.8464,  0.4918,  0.2669, -2.0049,  1.8323],\n",
            "        [-1.9520, -0.5235,  3.0694, -1.3884, -1.1758,  4.2276, -0.6332, -0.8896],\n",
            "        [-2.3207, -0.3820,  1.7796, -0.5799, -0.2410,  2.7165,  0.1012, -0.6824],\n",
            "        [-1.9888, -0.6473,  1.1579, -0.5494,  0.6748,  1.0651,  1.4490, -0.5014],\n",
            "        [-2.2276,  1.2338, -0.6094, -1.2117,  2.2577,  0.0497, -0.8788,  0.6924],\n",
            "        [-1.1576, -0.4682,  0.0480,  2.5419,  0.4221,  0.5104, -0.2001, -0.6865],\n",
            "        [-1.8697,  2.2719,  0.1283, -1.2915,  0.5157,  0.9279, -1.5937,  0.2349],\n",
            "        [-1.9001, -0.7901,  2.0031, -0.4312, -0.0738,  2.7698, -0.3410, -0.6407],\n",
            "        [-2.1361,  0.0753, -0.3986, -1.4189, -0.3658,  6.6292, -1.0535, -0.4730],\n",
            "        [-1.7321,  1.9495, -0.6679,  0.0152,  1.1979, -0.3989, -1.4702,  0.4126],\n",
            "        [-1.1635, -0.8077,  2.2979, -0.5951,  0.4914,  1.2289, -0.6851, -0.1556],\n",
            "        [-2.1256,  1.0923, -0.9065,  0.1917,  1.8954, -0.3846, -1.2018,  0.6127],\n",
            "        [-1.9697,  0.1263, -0.5087, -0.3350,  2.0076,  0.1494, -0.8957,  0.7603],\n",
            "        [-1.7989, -0.4097, -0.2019,  2.5310,  0.6176,  0.3772, -0.5725, -0.3349],\n",
            "        [-1.8728,  1.2058, -0.7221, -0.2591,  1.8184,  0.2518, -0.9246,  0.4482],\n",
            "        [-2.2715,  0.3876,  0.4156, -0.9423,  1.2122,  0.8287, -0.4599,  0.5911],\n",
            "        [-0.8778, -0.6148,  2.2766, -1.0099, -0.0805,  1.8587, -0.0671, -0.7179],\n",
            "        [-2.5088,  0.6977, -1.7949, -2.3048,  3.8237,  0.2629, -0.8047,  1.2136],\n",
            "        [-2.9161,  0.3888, -0.4560, -1.0816,  1.1689, -0.2295, -0.9134,  3.0657],\n",
            "        [-2.6500,  0.2869, -0.8905, -1.0711,  3.1147, -0.0185, -0.6875,  1.1269],\n",
            "        [-0.5626, -0.7311,  1.8001,  0.0251, -0.4775,  2.1043,  0.0744, -1.0690],\n",
            "        [-2.5948,  0.5549, -0.9942, -0.9560,  2.8427, -0.2695, -1.0840,  1.2353],\n",
            "        [-2.1280,  0.0989, -0.5650, -0.5045,  1.9356, -0.3214, -1.5219,  1.8421],\n",
            "        [-1.4234,  1.2884, -0.0235, -0.0437,  0.1974,  0.6589, -0.5243, -0.3446],\n",
            "        [-2.8065,  1.3496, -0.9877, -0.7105,  2.0487, -0.2284, -0.6491,  1.0872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5921e+00,  1.9877e-01, -1.7280e+00, -2.2987e+00,  5.9163e+00,\n",
            "         -3.3536e-01, -7.0608e-01,  2.1697e-01],\n",
            "        [-2.3521e+00,  2.4049e-01, -1.0992e+00, -1.2680e+00,  3.3922e+00,\n",
            "         -3.6294e-01, -8.9804e-01,  1.0810e+00],\n",
            "        [-1.7735e+00, -6.2696e-01,  2.1164e+00, -5.8823e-01, -5.7780e-01,\n",
            "          2.9041e+00, -2.6814e-01, -6.1469e-01],\n",
            "        [-2.0385e+00, -9.7591e-02,  4.6422e-01, -1.9039e-01,  1.3136e+00,\n",
            "          7.9794e-01, -6.0012e-02, -8.8830e-02],\n",
            "        [-2.6706e+00,  9.7569e-01, -2.7458e-01, -6.7504e-01, -3.9569e-01,\n",
            "         -8.3989e-01, -1.6966e+00,  4.9203e+00],\n",
            "        [-2.4934e+00, -4.8740e-02, -4.9878e-01, -3.0854e-01,  2.2672e+00,\n",
            "         -2.9623e-01, -7.1583e-01,  1.5059e+00],\n",
            "        [ 6.3006e-01, -2.3819e-01,  5.8892e-01, -8.5792e-01,  3.5164e-01,\n",
            "          1.5558e+00, -8.5508e-01, -7.2921e-01],\n",
            "        [-2.6201e+00,  3.1936e-01, -4.5294e-01, -1.6150e+00,  2.8320e+00,\n",
            "          1.0491e+00, -8.4861e-01,  4.5599e-01],\n",
            "        [-1.1736e+00, -8.5500e-02, -2.1713e-01, -6.1909e-01,  1.5380e+00,\n",
            "          3.2669e-01, -1.1930e+00,  7.7604e-01],\n",
            "        [-3.2088e+00,  1.1275e+00, -1.3582e+00, -1.2955e+00,  3.2159e+00,\n",
            "         -6.4553e-02, -5.5601e-01,  7.5805e-01],\n",
            "        [-2.8630e+00,  1.7253e+00, -1.7639e+00, -2.0186e+00,  4.3769e+00,\n",
            "         -3.1424e-01, -7.7756e-01,  4.3768e-01],\n",
            "        [-2.1270e+00, -7.1400e-01,  1.7887e+00, -1.4418e-01, -2.1007e-02,\n",
            "          1.1182e+00,  1.4328e+00, -9.1915e-01],\n",
            "        [-2.5744e+00,  4.7450e+00, -5.5790e-01, -1.5620e+00,  2.9528e-01,\n",
            "         -1.7366e-01, -1.8503e+00, -8.6869e-02],\n",
            "        [-1.3835e+00, -1.5780e+00,  1.9600e+00, -5.2655e-01, -2.4446e-02,\n",
            "          2.2643e+00, -1.3026e-01, -3.4909e-01],\n",
            "        [-2.2858e+00,  2.6267e-02, -6.3378e-01, -1.1073e+00,  2.8012e+00,\n",
            "          1.7983e-01, -7.2599e-01,  1.1864e+00],\n",
            "        [-7.7949e-01, -1.0995e+00,  2.7520e+00, -9.2910e-01, -1.5013e+00,\n",
            "          3.9195e+00, -6.1580e-01, -1.3178e+00],\n",
            "        [-1.3415e+00, -6.5615e-02,  2.7384e-01, -4.7205e-03,  1.1771e+00,\n",
            "          1.1614e+00, -9.3126e-01, -6.1942e-03],\n",
            "        [-9.7921e-01,  7.5075e-01,  5.0487e-01, -1.9758e-01, -6.1275e-01,\n",
            "          2.2209e+00, -1.1318e+00, -7.7793e-01],\n",
            "        [-1.2110e+00, -9.7138e-01,  5.5410e+00, -1.8226e+00, -1.1223e+00,\n",
            "          1.0606e+00, -6.7463e-01, -8.6541e-01],\n",
            "        [-1.8345e+00,  2.6471e-01,  7.7905e-02, -1.1682e+00,  1.5022e+00,\n",
            "          5.6419e-01, -1.7766e-01,  6.5068e-01],\n",
            "        [-2.9099e+00,  1.5755e+00, -9.3599e-01, -1.5013e-01,  1.8012e+00,\n",
            "         -2.1382e-01, -1.4201e+00,  1.5630e+00],\n",
            "        [-3.3093e-01, -2.8661e-01,  1.7513e+00, -1.0232e-01, -7.7765e-01,\n",
            "          2.1850e+00, -2.5932e-02, -1.1829e+00],\n",
            "        [-2.6318e+00,  3.2588e+00, -1.8162e+00, -1.2077e+00,  2.4240e+00,\n",
            "         -8.8684e-01, -1.7019e+00,  6.7810e-01],\n",
            "        [-2.4861e+00,  5.6425e-01, -3.6757e-01, -7.3512e-01,  2.1918e+00,\n",
            "          7.7326e-01, -3.8161e-01,  1.9206e-01],\n",
            "        [-4.7300e-01, -8.5624e-01,  1.3733e+00, -4.2069e-01, -2.4842e-01,\n",
            "          3.3457e+00, -6.9669e-01, -8.4208e-01],\n",
            "        [-7.7418e-01, -7.8032e-01,  1.5055e+00, -3.0912e-01,  6.4206e-01,\n",
            "          1.3206e+00, -5.2259e-01, -3.7999e-01],\n",
            "        [-1.7318e+00,  6.6496e-02, -5.0090e-01,  2.9439e-02,  1.8751e+00,\n",
            "          3.9971e-01, -1.1210e+00,  5.5218e-01],\n",
            "        [-2.3884e+00,  4.1508e-01, -1.1844e+00, -1.0116e+00,  2.9927e+00,\n",
            "         -3.9053e-01, -1.2458e+00,  1.7021e+00],\n",
            "        [-2.5267e+00,  2.7236e-01, -1.3176e+00, -3.8643e-01,  4.5239e-01,\n",
            "         -1.4188e+00, -1.8523e+00,  5.6180e+00],\n",
            "        [-2.9452e+00,  1.5915e+00, -1.3727e+00, -1.1804e+00,  2.3705e+00,\n",
            "         -6.8045e-01, -1.2449e+00,  1.6809e+00],\n",
            "        [-2.0146e+00,  9.5882e-01, -1.9852e-01, -2.8169e-01,  1.2204e+00,\n",
            "          3.1611e-01, -8.8186e-01,  4.5431e-01],\n",
            "        [-2.2884e+00,  9.6669e-01, -1.1832e+00, -9.0787e-01,  2.5185e+00,\n",
            "         -3.6076e-01, -1.4553e+00,  1.6139e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4580, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.0092, -0.2403,  0.3808, -1.1318,  1.4834,  0.8987, -0.6820,  0.1490],\n",
            "        [-2.0760,  1.9670, -0.8469, -0.1729,  1.5202, -0.3742, -1.3131,  0.6495],\n",
            "        [-2.0309, -0.8937,  3.0233, -0.5292, -1.4605,  3.9198, -0.3249, -1.0953],\n",
            "        [-2.0871,  1.2339, -0.1987,  0.1301,  0.7938,  0.3667, -0.2911,  0.3065],\n",
            "        [-0.9499, -1.2283,  1.3467, -0.2240, -0.4709,  3.6078, -0.7556, -0.8556],\n",
            "        [-1.5615, -0.1527,  0.8577, -0.7508,  1.0760,  1.0089, -0.4259,  0.1283],\n",
            "        [-1.8849,  0.3603, -0.5425, -0.6879,  2.0178,  0.4146, -1.1360,  1.2011],\n",
            "        [-0.8900,  0.7774,  0.0551,  0.1766,  0.2656,  0.7334, -0.6666, -0.5393],\n",
            "        [-2.0957,  0.4953, -0.9022, -1.6199,  2.8438,  0.6111, -1.0887,  0.7983],\n",
            "        [-1.3763, -0.4453,  0.3956,  0.0754,  1.2318,  1.0770, -0.6013,  0.0371],\n",
            "        [-0.7927, -0.0215, -0.0641, -0.5002,  1.2026,  1.1003, -0.6553,  0.0271],\n",
            "        [-2.2789,  1.0215, -1.6524, -1.0800,  3.1444, -0.6325, -1.4286,  1.3300],\n",
            "        [-2.3019,  0.5114, -1.0935, -1.4354,  3.1161, -0.5091, -0.8149,  1.3921],\n",
            "        [-1.1261,  0.5349,  0.1559, -1.1365,  0.6537,  1.9335, -1.0975,  0.0305],\n",
            "        [-2.0641, -0.1598,  1.2601, -0.5780,  0.4483,  1.6572, -0.2168,  0.0757],\n",
            "        [-0.9939,  1.0243,  0.3045, -0.0299,  0.2997,  0.8401, -1.0334, -0.4006],\n",
            "        [-0.5282, -0.3739,  0.0151, -1.2629,  2.0380,  1.0281, -1.2516,  0.1144],\n",
            "        [-2.3453,  1.1416, -1.0590, -0.4288,  1.8178, -0.0288, -1.1841,  1.3507],\n",
            "        [-2.4894,  6.0571, -1.8473, -1.8686,  0.5107, -1.2980, -1.9286,  0.2545],\n",
            "        [-2.0701, -1.0220,  1.5024, -0.4626,  0.6689,  1.6819,  0.1997, -0.0359],\n",
            "        [-2.8379, -0.1075, -1.1089, -0.5502,  2.3116,  0.0167, -0.8804,  2.1746],\n",
            "        [-2.7554,  4.6741, -1.5186, -1.9524,  1.5030, -0.7595, -1.8573,  0.1524],\n",
            "        [-1.2131, -0.3842,  2.1966, -0.6483, -0.1607,  1.8384, -0.9662, -0.5641],\n",
            "        [-1.5394,  0.2247,  0.4883, -0.3821,  1.1231,  0.1957, -0.3288, -0.0432],\n",
            "        [ 0.4744, -1.2430,  1.8713, -1.3087, -0.2989,  2.3140, -0.6780, -0.5997],\n",
            "        [-2.8653,  0.1921, -1.3315, -0.5797,  2.5896, -0.5835, -1.7012,  3.0701],\n",
            "        [-2.0225, -0.1673, -0.3372, -1.1708,  0.2167,  6.7349, -0.8332, -0.5888],\n",
            "        [-2.3057,  0.1996, -0.3345, -0.1813,  1.7064,  0.4610, -0.5221,  0.6555],\n",
            "        [-2.4324,  3.9528, -1.5287, -0.9538,  1.0053, -0.7276, -2.1070,  0.3408],\n",
            "        [-1.0909,  0.1874,  0.0262, -0.0518,  0.6636,  0.5449, -1.6024,  1.0046],\n",
            "        [-1.8568,  0.2541,  0.4489, -1.3751,  1.4875,  0.4675, -0.3659, -0.1103],\n",
            "        [-1.2748, -0.8092,  1.6012,  0.1931,  0.5080,  1.1007, -0.4992, -0.4291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.7033, -0.6093,  0.8197, -0.6585,  0.8215,  1.5811, -0.2653, -0.4100],\n",
            "        [-2.7844,  0.2333, -0.8385, -0.1804,  2.0966,  0.0694, -0.8496,  1.5954],\n",
            "        [-1.4390,  0.5935,  0.2878, -0.0506,  0.8826,  0.8289, -0.4618, -0.1147],\n",
            "        [-0.8281, -0.5195,  1.2115, -0.7481,  0.8500,  1.4877, -0.7768, -0.2224],\n",
            "        [-1.3874,  0.0058,  1.1039, -0.7907,  0.4795,  1.7005, -0.6046, -0.0992],\n",
            "        [-3.0503,  3.2354, -1.1859, -0.9002,  1.0441, -0.6136, -1.0538,  0.6069],\n",
            "        [-3.0843, -0.2271, -2.0243, -1.0395,  2.4212, -0.8255, -1.7218,  5.0136],\n",
            "        [-2.9502,  2.7869, -1.7008, -1.3581,  1.8972, -0.7197, -1.5329,  1.2208],\n",
            "        [-2.6315,  1.6499, -1.4285, -0.9726,  2.3624, -0.6054, -1.2474,  1.6572],\n",
            "        [-1.3511,  0.7939, -0.1422,  0.2959,  0.9139,  0.5906, -0.4996, -0.2586],\n",
            "        [-2.0321, -0.0673, -0.0893, -1.3505,  2.3245,  0.6848, -0.5694,  0.6187],\n",
            "        [-1.2638, -0.7724,  1.2717, -0.8999,  0.5758,  2.4459, -0.7618, -0.3404],\n",
            "        [-2.1122,  1.0239, -0.4363, -0.7730,  1.9306,  0.0930, -0.9642,  0.6316],\n",
            "        [-2.4691,  2.1799, -0.8371, -0.4819,  1.5308, -0.3789, -1.1192,  0.9176],\n",
            "        [-1.7413, -0.3899,  1.4341, -0.8752,  0.2365,  2.3197, -0.1331, -0.5458],\n",
            "        [-2.3453,  3.0083, -1.0547, -1.4659,  1.4548, -0.4026, -0.9919,  0.2792],\n",
            "        [-3.7115,  0.2832, -1.5650, -1.8575,  4.7956, -0.9828,  0.0762,  0.9762],\n",
            "        [-2.0976,  0.1528, -0.9008, -1.4374,  2.9624, -0.2504, -0.7922,  0.8450],\n",
            "        [-2.9152,  1.3997, -1.7174,  1.0592,  2.0472, -0.8611, -1.1956,  1.0655],\n",
            "        [-1.5912,  0.2272,  0.6460, -1.4037,  0.5727,  0.7066, -0.9055,  1.3772],\n",
            "        [-1.3033,  1.0795, -0.4928,  0.0970,  1.1110,  0.3473, -1.5175,  0.3201],\n",
            "        [-1.4315,  0.2916,  0.1513,  0.5170,  0.7670,  0.2303, -0.2851, -0.2119],\n",
            "        [-3.1550,  1.9850, -1.3678, -1.0674,  2.4177, -0.7418, -1.0752,  1.5190],\n",
            "        [-1.6915, -0.9794,  3.1720, -0.9772, -1.0941,  3.5679, -0.1490, -0.8378],\n",
            "        [-2.1841, -0.3518,  0.0331, -1.2431,  1.8692,  0.7150, -0.9529,  1.4177],\n",
            "        [-2.3142,  0.6361, -1.0774, -1.0983,  2.6585, -0.3615, -1.1150,  1.2499],\n",
            "        [-1.2430, -0.3935,  1.7385, -0.7741,  0.1035,  1.6489, -0.4262, -0.0249],\n",
            "        [-2.0460, -0.0408, -0.4195, -1.3116,  2.8105,  0.7600, -0.7561,  0.5073],\n",
            "        [-2.8003, -0.4970, -0.3250, -0.5906,  2.4279,  0.3632, -0.2913,  1.3581],\n",
            "        [ 0.6773, -0.2796,  1.6658, -0.6620, -1.0594,  2.1263, -0.3092, -1.3659],\n",
            "        [-1.4187, -0.7076,  1.1174, -0.6479,  1.1013,  1.6795, -0.5943, -0.1234],\n",
            "        [-1.1139, -0.1722,  0.1934, -0.7316,  1.8490,  0.3909, -0.8403,  0.2357]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1107, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.0948e+00,  1.1947e+00, -6.2459e-01,  1.4616e-02,  1.9267e+00,\n",
            "         -3.9695e-01, -9.3573e-01,  5.1488e-01],\n",
            "        [-6.9139e-01, -6.1635e-01,  1.4369e+00, -8.5517e-01,  5.6110e-01,\n",
            "          1.6004e+00, -4.0011e-01, -4.4550e-01],\n",
            "        [-2.3888e+00,  3.8622e-01, -1.0853e+00, -1.3668e+00,  3.3959e+00,\n",
            "          4.7680e-01, -7.7289e-01,  8.7220e-01],\n",
            "        [-2.3751e+00, -6.6810e-01, -1.1729e+00,  5.3669e+00,  3.0431e-01,\n",
            "         -9.5214e-02, -5.9448e-01, -2.0206e-01],\n",
            "        [-2.0120e+00,  1.6019e+00, -1.0035e+00,  4.9203e-01,  1.4733e+00,\n",
            "         -5.2574e-01, -1.0400e+00,  6.5359e-01],\n",
            "        [-2.1219e+00,  5.1509e-02, -7.0281e-01, -8.6896e-01,  2.4489e+00,\n",
            "          2.7584e-01, -9.0907e-01,  7.9986e-01],\n",
            "        [-2.2521e+00, -5.0001e-01,  1.1506e-01, -1.5291e+00, -7.0886e-02,\n",
            "          6.7275e+00, -1.1687e+00, -4.9040e-01],\n",
            "        [-2.2878e+00,  1.3821e-01,  3.2227e-01,  1.7384e-01,  1.1832e+00,\n",
            "          8.0139e-01, -4.8487e-01,  2.9421e-01],\n",
            "        [-1.5214e+00,  3.7568e-01, -2.4516e-01,  2.6208e-01,  1.4062e+00,\n",
            "          5.6874e-01, -1.1174e+00,  2.2872e-01],\n",
            "        [-2.0584e+00, -2.2788e-01, -5.0933e-01, -3.3921e-01,  2.4092e+00,\n",
            "          2.3188e-02, -7.1905e-01,  6.4022e-01],\n",
            "        [-2.3568e+00,  9.0594e-01,  1.4379e+00, -8.1987e-01, -9.6348e-02,\n",
            "          1.4321e+00, -3.3731e-01, -4.9199e-01],\n",
            "        [-1.8599e+00, -5.1252e-01,  7.1308e-04, -3.1630e-01,  2.0004e+00,\n",
            "          5.5055e-02, -6.8486e-01,  9.4059e-01],\n",
            "        [-3.0886e+00,  2.8893e+00, -2.1987e+00, -1.1725e+00,  2.1489e+00,\n",
            "         -1.0416e+00, -1.6734e+00,  1.9744e+00],\n",
            "        [-2.1676e+00,  1.5407e+00, -9.9625e-01, -4.6588e-01,  2.3718e+00,\n",
            "         -5.0030e-01, -7.8494e-01,  3.9166e-01],\n",
            "        [-2.0589e+00,  3.8667e-01, -5.6460e-02, -2.3033e-01,  1.6943e+00,\n",
            "          3.3438e-01, -4.7962e-01,  3.6532e-01],\n",
            "        [-2.2847e+00,  2.1768e-01, -3.0811e-01,  4.2870e-01,  1.5195e+00,\n",
            "         -1.2972e-01, -1.5781e-01,  3.1470e-01],\n",
            "        [-2.4159e+00,  1.5128e+00, -1.6522e+00, -2.1173e+00,  3.6792e+00,\n",
            "         -4.1602e-01, -8.5427e-01,  7.5922e-01],\n",
            "        [-1.6480e+00, -5.1516e-01,  3.4244e+00, -1.6498e+00, -4.0914e-01,\n",
            "          1.9723e+00, -7.7871e-01, -8.0586e-01],\n",
            "        [-8.2716e-01,  8.7866e-01,  1.9388e-02, -3.9832e-01,  8.2111e-01,\n",
            "          8.0804e-01, -1.0669e+00, -2.1703e-01],\n",
            "        [-2.7241e+00,  4.7293e-01, -8.2405e-01, -6.1555e-01,  1.8555e+00,\n",
            "         -1.5172e-01, -7.1598e-01,  1.6014e+00],\n",
            "        [-1.1162e+00, -7.3067e-02, -1.3131e-01,  3.4050e-02,  1.2111e+00,\n",
            "          1.0483e+00, -5.9660e-01, -2.5336e-01],\n",
            "        [-2.7793e+00,  2.1844e+00, -1.7938e+00, -1.0042e+00,  1.9961e+00,\n",
            "         -7.5580e-01, -1.3011e+00,  1.4184e+00],\n",
            "        [-1.5907e+00, -8.5264e-01,  1.0906e+00, -5.2799e-01,  1.2653e+00,\n",
            "          8.1382e-01, -8.9039e-02, -1.3033e-01],\n",
            "        [-3.0140e+00,  1.7849e+00, -1.2600e+00, -5.7625e-01,  2.1382e+00,\n",
            "         -4.7308e-01, -7.6415e-01,  1.0217e+00],\n",
            "        [-2.4632e+00,  7.8750e-01, -1.1602e+00, -1.3990e+00,  3.2575e+00,\n",
            "         -4.3325e-01, -8.3385e-01,  1.0294e+00],\n",
            "        [-1.4739e+00, -4.6204e-01,  6.8176e-01, -4.3351e-01,  8.2610e-01,\n",
            "          6.8269e-01,  7.7299e-01, -1.1807e-01],\n",
            "        [-1.3272e+00,  8.3993e-01,  1.9269e+00, -9.0979e-01, -7.6818e-01,\n",
            "          2.3582e+00, -3.8519e-01, -1.2509e+00],\n",
            "        [-4.2260e+00, -1.7815e-01, -1.0516e+00, -6.3251e-01,  1.5972e+00,\n",
            "         -9.6463e-01, -1.3614e+00,  5.0246e+00],\n",
            "        [-3.0506e+00,  2.1572e+00, -2.1617e+00, -1.4867e+00,  2.8495e+00,\n",
            "         -1.1010e+00, -1.5425e+00,  2.2910e+00],\n",
            "        [-2.9222e+00,  1.0466e+00, -1.6357e+00, -1.3044e+00,  3.4835e+00,\n",
            "         -7.6829e-01, -1.0414e+00,  1.5685e+00],\n",
            "        [-2.9587e+00,  1.1557e+00, -1.5792e+00, -1.7303e+00,  3.6827e+00,\n",
            "         -3.3033e-01, -1.0699e+00,  1.0705e+00],\n",
            "        [-2.3659e+00,  1.0772e+00, -1.3601e+00, -1.0429e+00,  2.8975e+00,\n",
            "         -7.0704e-01, -1.3012e+00,  1.3480e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.5300,  0.6890, -0.7376, -1.6325,  2.6044,  0.8657, -1.3479,  0.5219],\n",
            "        [-1.3062, -0.2788,  0.2031, -0.0803,  1.5069,  0.7568, -0.7385,  0.0887],\n",
            "        [-3.0741,  1.0138, -2.3825, -1.0314,  3.1257, -0.9957, -1.4512,  2.8946],\n",
            "        [-2.7786,  1.2957, -0.5597, -1.4299,  1.8497, -0.3230, -1.2188,  2.3991],\n",
            "        [-2.5264,  3.8298, -1.6412, -2.0942,  2.4139, -0.6852, -1.4440,  0.4690],\n",
            "        [-2.8347,  0.1410, -1.0085, -1.4688,  3.7490, -0.2617, -0.2963,  0.8495],\n",
            "        [-1.9636,  1.0021, -0.8723, -1.4517,  2.4998,  0.1238, -1.3087,  0.8895],\n",
            "        [-3.2554,  0.9992, -0.7635, -1.3681,  2.2192, -0.7518, -0.6197,  2.4072],\n",
            "        [-0.5486,  0.8125, -0.2327, -0.4911,  0.9137,  0.2382, -1.0346,  0.2148],\n",
            "        [-2.7370,  4.0825, -1.6877, -1.7760,  1.8211, -0.8690, -1.9816,  0.8921],\n",
            "        [-0.4812, -1.1261,  0.9382, -0.8699,  0.8007,  2.9562, -1.4648, -0.5641],\n",
            "        [-2.6341,  0.1866, -0.8511, -1.0218,  3.0825, -0.1904, -0.6480,  1.1952],\n",
            "        [-2.5946,  2.8871, -1.4860, -0.9171,  2.0256, -0.6437, -1.7048,  0.7097],\n",
            "        [-2.6660,  2.0603, -1.2792, -0.0603,  1.6550, -0.8097, -1.0606,  1.0236],\n",
            "        [-0.6282, -1.0651,  1.3538, -0.4652,  0.4873,  2.0744, -0.7403, -0.4319],\n",
            "        [-2.8694,  0.4963, -0.9010, -0.7710,  2.7130, -0.4238, -0.5595,  1.4366],\n",
            "        [-1.3166, -0.0867,  1.0727, -0.7529,  0.6644,  1.1575,  0.2312, -0.3055],\n",
            "        [-2.2183, -0.0755, -1.2780, -1.1864,  2.9125, -0.2049, -0.8936,  1.7606],\n",
            "        [-1.9348, -0.8171, -1.6742, -1.8807,  6.7128, -0.9158, -0.9629, -0.3404],\n",
            "        [-1.8304, -0.7002, -1.0510,  4.3100,  0.5530,  0.0155, -0.9001, -0.2638],\n",
            "        [-0.4359,  0.0512,  0.8544, -0.7991,  0.0079,  1.8070, -0.1942, -0.5360],\n",
            "        [-2.9376,  0.3745, -0.8390, -0.7009,  2.7302,  0.0094, -0.5211,  0.8872],\n",
            "        [-2.2304, -0.1153, -0.0658, -1.1413,  2.6802,  0.1817, -0.6601,  0.7417],\n",
            "        [-1.7161, -0.5333,  0.3022, -1.1546,  1.7973,  0.9973, -0.2140,  0.3554],\n",
            "        [-2.0845,  1.8548, -0.8146, -1.3222,  1.7405,  0.1106, -1.7411,  1.2335],\n",
            "        [-3.4759,  0.5762, -1.6216, -1.3849,  4.4899, -0.5493, -1.0502,  1.2898],\n",
            "        [-2.3217,  1.2234, -0.7073, -0.4077,  1.4232,  0.0624,  0.0626,  0.1193],\n",
            "        [-1.6740, -0.7268,  3.2090, -1.6660, -0.8526,  2.5805, -0.4906, -0.0445],\n",
            "        [-2.9774,  0.4386, -1.5336, -0.6978,  3.3517, -0.7696, -0.9358,  1.6808],\n",
            "        [-2.5096,  0.5012, -1.4699, -1.0906,  3.3059, -0.6136, -1.0706,  1.7573],\n",
            "        [-1.6155, -0.3959, -0.3039, -0.7755,  1.9876,  2.3544, -1.3046,  0.3026],\n",
            "        [-1.9698,  1.5644, -0.7470, -0.5703,  1.3821, -0.3465, -0.9685,  0.6973]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2202, -0.3797, -0.0534, -1.0105,  2.1616,  0.4541, -1.2134,  0.7257],\n",
            "        [-1.7917,  0.7807, -0.0208, -0.7199,  1.2441,  0.5646, -0.6251,  0.2606],\n",
            "        [-0.7663, -0.2909,  0.8236, -0.8206,  1.3496,  0.8460, -0.4206, -0.4078],\n",
            "        [-2.3609, -0.2753,  0.1253, -0.3992,  1.5931,  0.5993, -0.4113,  0.4534],\n",
            "        [-2.2428,  0.3602,  0.2104, -1.0737,  1.9808,  0.3028, -0.6238,  0.7104],\n",
            "        [-2.2090, -0.4550,  0.3678,  0.6273,  1.4833,  0.3444,  0.1529, -0.2595],\n",
            "        [-1.6499, -0.8309,  1.4711, -1.1975,  0.8699,  1.9710, -0.4120, -0.1888],\n",
            "        [-2.2925,  0.0422, -1.9040, -2.5191,  6.8832, -0.6050, -1.0053, -0.3066],\n",
            "        [-3.0344,  2.1272, -1.5124, -0.6738,  2.2919, -0.9041, -1.2230,  1.5145],\n",
            "        [-1.9788,  0.8718, -0.5500, -0.2644,  1.3235,  1.1556, -0.8617, -0.1116],\n",
            "        [-0.9234, -0.0496,  1.6591, -1.3104,  0.2615,  1.3236, -0.5991, -0.2626],\n",
            "        [-1.9806,  1.3231, -0.3200, -1.2429,  1.6423,  0.4465, -0.7091,  0.5019],\n",
            "        [-1.7121,  0.0443, -1.3763, -1.3015,  2.6222, -0.3919, -0.8800,  2.0686],\n",
            "        [-1.7528,  0.7805,  0.4992, -1.4211,  1.1951,  0.9283, -0.4828,  0.0598],\n",
            "        [-2.1543,  1.4729, -1.3901,  0.2862,  1.9244, -0.6995, -1.3370,  0.8976],\n",
            "        [-2.1498, -0.4659,  0.2192, -0.8128, -0.1018,  6.6135, -1.1211, -0.6200],\n",
            "        [-3.6871,  0.5815, -1.9894, -1.4435,  2.3014, -1.1563, -2.1463,  5.6971],\n",
            "        [-1.9281,  1.9404, -0.8297,  0.1554,  1.1053, -0.3414, -1.3236,  0.8518],\n",
            "        [-1.6275, -0.0983,  1.4216, -1.1037,  0.7762,  0.9613, -0.0123, -0.2689],\n",
            "        [-2.5986,  3.8170, -1.5355, -1.7492,  1.8644, -0.8168, -1.8948,  0.8595],\n",
            "        [-2.8121,  0.6534, -1.4211, -1.1829,  3.2147, -0.5093, -1.0143,  1.7331],\n",
            "        [-1.1700, -0.9273,  1.7570, -0.1451,  0.0981,  1.8412, -0.0372, -0.9050],\n",
            "        [-3.0841,  3.8713, -3.0070, -2.0520,  3.3349, -1.5177, -2.1602,  1.4969],\n",
            "        [-1.9400, -0.7713, -1.5773, -1.8404,  6.9411, -1.0959, -0.7431, -0.3177],\n",
            "        [-2.6114,  6.3104, -1.8210, -1.7740,  0.4264, -1.4810, -1.1824, -0.1635],\n",
            "        [-2.3640,  1.7329, -0.6061, -0.6744,  1.4797,  0.1789, -1.0441,  0.6140],\n",
            "        [-2.3327,  0.4991,  0.3495, -1.8459,  1.7610,  0.6400, -0.4170,  0.8613],\n",
            "        [-0.9462, -0.7567,  0.8544, -0.5975,  0.8489,  0.9468,  0.8142, -0.4736],\n",
            "        [-2.6233,  2.5503, -1.1355, -0.6892,  2.0499, -0.7185, -1.5463,  0.8567],\n",
            "        [-2.4030,  2.1049, -0.6234, -0.6544,  1.2472, -0.1520, -1.2651,  0.8678],\n",
            "        [-2.8980,  2.9882, -2.0178, -2.0273,  3.2213, -0.9346, -1.5924,  0.9014],\n",
            "        [-1.9714, -0.8004, -1.3511, -1.7138,  6.9437, -0.4671, -1.0179, -0.3894]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.5756e+00, -9.4463e-01, -1.0969e+00, -1.8928e+00,  6.8632e+00,\n",
            "         -5.4244e-01, -8.8215e-01, -7.6192e-01],\n",
            "        [-3.1371e+00,  1.8809e+00, -2.2429e+00, -1.7911e+00,  3.9295e+00,\n",
            "         -1.1757e+00, -1.4975e+00,  1.8073e+00],\n",
            "        [-2.8079e+00,  8.6572e-01, -1.4560e+00, -1.6202e+00,  3.3286e+00,\n",
            "         -5.8108e-01, -8.4779e-01,  1.7041e+00],\n",
            "        [-7.8609e-01,  1.7100e-01, -3.6331e-01,  1.2957e+00,  3.1046e-01,\n",
            "          4.8927e-01, -1.2900e+00,  2.6609e-01],\n",
            "        [-1.9192e+00, -1.0366e+00, -1.1970e+00, -1.8665e+00,  6.8798e+00,\n",
            "         -4.6518e-01, -8.9933e-01, -9.0855e-01],\n",
            "        [-2.5396e+00, -1.5525e-01,  2.6850e-01, -1.2393e+00,  1.8711e+00,\n",
            "          1.1394e-01,  6.5961e-01,  5.3755e-01],\n",
            "        [-1.7775e+00,  3.1931e-02, -7.5450e-02,  3.1092e-01,  1.6469e+00,\n",
            "          3.0453e-01, -5.9018e-01,  4.6107e-01],\n",
            "        [-2.9500e+00,  7.1620e-01, -1.5225e+00, -2.3995e+00,  4.4973e+00,\n",
            "         -6.5862e-01, -2.1634e-01,  1.0846e+00],\n",
            "        [-3.2073e+00,  3.5244e+00, -2.4963e+00, -2.3469e+00,  3.1209e+00,\n",
            "         -1.3555e+00, -1.6332e+00,  1.4175e+00],\n",
            "        [-1.5398e+00,  4.8219e-01, -2.8098e-01, -1.1931e+00,  1.9963e+00,\n",
            "         -7.7034e-02, -1.0854e+00,  8.2160e-01],\n",
            "        [-1.6619e+00,  2.0139e+00, -5.8513e-01, -3.6126e-01,  6.2700e-01,\n",
            "          2.1206e-01, -1.0519e+00,  1.0456e-01],\n",
            "        [-2.4936e+00,  1.0315e+00, -7.6520e-01, -6.9052e-01,  1.7325e+00,\n",
            "         -4.9586e-03, -5.7871e-01,  9.3081e-01],\n",
            "        [-3.3574e+00,  3.5266e+00, -1.2808e+00, -2.1275e+00,  2.3729e+00,\n",
            "         -9.3522e-01,  4.2671e-01, -5.2094e-01],\n",
            "        [-2.8098e+00,  9.1371e-01, -1.1494e+00, -1.5170e+00,  3.2494e+00,\n",
            "         -5.1265e-01, -8.6136e-01,  1.0417e+00],\n",
            "        [-1.2774e+00, -7.7282e-01,  3.0154e+00, -1.2044e+00, -1.8469e-01,\n",
            "          2.1893e+00, -7.0448e-01, -3.7987e-01],\n",
            "        [-2.8734e+00,  5.9473e-01, -1.3383e+00, -1.3002e+00,  3.4370e+00,\n",
            "         -6.1510e-01, -7.0762e-01,  1.4450e+00],\n",
            "        [-2.9352e+00,  1.7549e+00, -1.3737e+00, -1.1658e+00,  1.6125e+00,\n",
            "         -7.8619e-01, -1.7424e+00,  3.2168e+00],\n",
            "        [-2.1444e+00,  1.1223e+00, -9.1143e-01, -8.0836e-01,  2.2060e+00,\n",
            "         -4.1061e-01, -9.2116e-01,  8.8368e-01],\n",
            "        [-1.0627e+00, -4.8442e-02,  6.4875e-01, -4.4144e-01, -1.4943e-02,\n",
            "          2.3022e+00, -8.0797e-01, -4.2237e-01],\n",
            "        [-2.2847e+00, -1.0757e+00,  7.0866e-01, -7.4145e-01,  1.3056e-01,\n",
            "         -5.8674e-01,  5.6595e+00,  1.0181e-01],\n",
            "        [-2.2324e+00,  2.9821e-01, -1.6478e+00, -1.6245e+00,  3.3885e+00,\n",
            "         -6.5907e-01, -9.9222e-01,  2.0599e+00],\n",
            "        [-1.9726e+00,  6.5742e-01,  2.6243e-01, -1.0677e+00,  1.6196e+00,\n",
            "          2.5854e-01, -7.4345e-01,  6.5071e-01],\n",
            "        [-2.9079e+00,  3.5101e+00, -2.3796e+00, -1.9457e+00,  2.9201e+00,\n",
            "         -1.4811e+00, -1.4269e+00,  1.6741e+00],\n",
            "        [-1.8028e+00, -5.5613e-01,  5.7777e+00, -1.4428e+00, -4.2631e-01,\n",
            "          7.3338e-02, -9.0982e-01, -5.9707e-01],\n",
            "        [-2.3410e+00,  1.0828e+00, -1.1446e+00, -1.0584e+00,  2.5150e+00,\n",
            "         -2.7991e-01, -1.2433e+00,  1.2129e+00],\n",
            "        [-2.7268e+00,  6.2594e-01, -1.3409e+00, -1.3339e+00,  2.8045e+00,\n",
            "         -4.4910e-01, -1.6740e+00,  2.8286e+00],\n",
            "        [-3.0915e+00,  1.1996e+00, -1.7931e+00, -1.4787e+00,  3.2095e+00,\n",
            "         -7.4478e-01, -1.2194e+00,  1.9887e+00],\n",
            "        [-2.8623e+00,  1.1049e+00, -5.5108e-01, -1.6623e+00,  2.5383e+00,\n",
            "         -1.3462e-01, -5.4034e-01,  9.2589e-01],\n",
            "        [-2.2144e+00,  3.1200e-01, -4.2428e-01, -8.2165e-01,  2.4039e+00,\n",
            "          8.1445e-02, -8.0421e-01,  9.9524e-01],\n",
            "        [-1.6521e+00,  1.5570e+00, -8.0120e-01, -4.1664e-01,  1.2950e+00,\n",
            "          2.2355e-02, -1.4391e+00,  9.1933e-01],\n",
            "        [-2.5144e+00,  4.5860e-01, -5.6216e-01, -1.3590e+00,  2.6594e+00,\n",
            "         -8.3402e-02, -7.6608e-01,  1.2730e+00],\n",
            "        [-1.2366e+00, -1.7162e-01,  9.5539e-01, -1.2340e+00,  9.3808e-01,\n",
            "          1.1759e+00, -6.1035e-01,  1.2516e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.4642,  1.2315, -1.6216, -1.8216,  3.6859, -0.9134, -1.2484,  1.4891],\n",
            "        [-1.7925, -0.9463, -1.4980, -1.9580,  7.1301, -0.6720, -0.7973, -0.5771],\n",
            "        [-2.7760,  1.8592, -2.1055, -2.2999,  3.9056, -0.4755, -1.3599,  1.1292],\n",
            "        [ 5.6742, -0.1353, -1.7829,  0.1563, -0.7599, -1.7493, -0.9447, -1.0861],\n",
            "        [-3.2291,  3.0865, -2.1762, -2.0287,  3.4120, -1.0461, -1.4213,  1.2087],\n",
            "        [-2.9616,  0.1434, -2.0098, -1.6645,  3.6797, -0.7490, -1.3819,  3.3194],\n",
            "        [-1.1374, -0.1756,  0.0646, -1.3614,  1.9177,  0.8384, -0.9437,  0.3630],\n",
            "        [-2.3390,  0.7609, -0.4966, -0.9600,  1.8743, -0.1448, -0.8890,  1.4228],\n",
            "        [-2.7438,  1.3028, -1.9422, -2.3895,  4.1310, -0.5836, -1.2828,  0.9801],\n",
            "        [-2.3371,  2.2915, -1.1062, -0.7626,  1.6728, -0.3323, -1.4382,  0.9225],\n",
            "        [-1.9425,  1.5333, -0.7215, -1.6168,  1.9455, -0.2710, -1.0416,  0.7592],\n",
            "        [-2.6608,  0.3365, -1.2946, -1.0911,  3.2272, -1.0009,  0.3203,  0.7784],\n",
            "        [-1.9649,  1.4277, -0.6842, -0.2883,  1.7735, -0.4069, -1.2047,  0.5105],\n",
            "        [-1.5631, -0.4730,  2.5083, -1.0756, -1.0986,  3.1369, -0.0830, -0.8601],\n",
            "        [-2.1185,  0.0192, -0.7908, -1.3723,  2.6274,  0.4072, -0.6518,  0.8433],\n",
            "        [-2.0925,  1.0654, -0.7214, -1.1450,  2.3031, -0.0286, -0.9516,  0.9239],\n",
            "        [-1.8115, -0.0721, -0.2347, -1.0597,  0.0147,  6.9065, -0.8920, -0.8804],\n",
            "        [-2.0707, -0.2868, -1.9336, -2.4167,  6.6371, -0.5337, -0.7288, -0.4938],\n",
            "        [-2.4633,  1.4192, -0.5821, -1.7000,  2.1078, -0.5079, -1.3192,  1.6229],\n",
            "        [-1.5860, -0.5869,  2.4949, -1.1811, -0.5147,  3.0431, -0.4607, -0.4073],\n",
            "        [-2.8164,  1.7596, -1.3447, -0.7239,  2.3500, -0.8437, -0.9298,  1.1829],\n",
            "        [-2.6396,  0.8411, -0.6761, -0.4204,  2.2734, -0.5067, -0.0248,  0.6022],\n",
            "        [-2.9832,  3.6840, -2.2773, -1.8923,  2.6718, -1.3981, -1.8678,  1.6052],\n",
            "        [-1.7764, -0.5008,  1.6455, -1.5664,  0.1731,  2.1823, -0.7191,  0.5028],\n",
            "        [-2.4301,  1.2458, -0.9944, -0.4785,  2.0619, -0.3058, -1.0929,  0.9954],\n",
            "        [-2.8802,  3.7898, -2.7304, -2.1366,  3.1938, -1.3903, -2.2559,  1.6311],\n",
            "        [-1.5466, -0.6141,  0.3216, -0.0703,  1.3634,  0.6073, -0.3434,  0.3528],\n",
            "        [-3.2848,  2.9609, -2.5120, -1.3742,  2.6882, -1.4114, -1.2529,  1.9738],\n",
            "        [-2.3145,  0.3341,  1.3816, -1.4454,  0.5184,  1.2466, -0.3261,  0.5963],\n",
            "        [-1.9817,  0.0290,  1.8697, -0.7377,  0.0901,  1.5580, -0.1849, -0.3369],\n",
            "        [-2.7659,  1.3201, -0.7527, -1.6963,  2.1523, -0.4076, -0.7534,  1.3668],\n",
            "        [-1.6452, -0.5626,  2.0026, -1.2455, -0.0126,  2.4628, -0.4146, -0.2037]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.7905e+00,  4.0874e+00, -1.7164e+00, -1.8693e+00,  1.7506e+00,\n",
            "         -1.1740e+00, -1.3011e+00,  8.4676e-01],\n",
            "        [-3.7484e+00,  8.2593e-01, -1.4917e+00, -1.2264e-02,  2.5482e-01,\n",
            "         -1.4677e+00, -1.4377e+00,  5.3341e+00],\n",
            "        [-1.0890e+00,  3.4806e-01,  1.0718e-01, -6.2468e-01,  1.4555e+00,\n",
            "          2.3548e-01, -7.5934e-01,  1.8042e-01],\n",
            "        [-3.8494e+00,  3.4227e+00, -2.0246e+00,  2.9487e+00,  2.3877e-01,\n",
            "         -1.9735e+00, -7.9155e-01, -3.0294e-02],\n",
            "        [-2.5914e+00,  7.2502e-01, -1.3335e+00, -1.2157e+00,  2.6437e+00,\n",
            "         -3.3687e-01, -6.1511e-01,  1.4296e+00],\n",
            "        [-1.0711e+00,  2.7797e-01, -6.9903e-02, -1.4496e+00,  1.9218e+00,\n",
            "          6.6563e-01, -8.6389e-01,  3.4963e-01],\n",
            "        [-2.2645e+00,  2.2975e+00, -1.1130e+00, -9.8480e-01,  8.2456e-01,\n",
            "         -3.5091e-01, -1.2197e+00,  1.2203e+00],\n",
            "        [-8.6986e-01,  1.0415e+00, -1.1392e-01,  6.1398e-03,  3.8172e-01,\n",
            "          5.5756e-01, -1.1911e+00,  7.9085e-02],\n",
            "        [-1.4103e+00, -5.2043e-01,  9.6130e-01, -4.8090e-01,  7.2952e-01,\n",
            "          1.5500e+00, -5.6839e-01, -8.5516e-02],\n",
            "        [-2.6738e+00,  4.1110e+00, -1.8371e+00, -1.7899e+00,  1.7028e+00,\n",
            "         -1.0978e+00, -1.0636e+00,  4.6237e-01],\n",
            "        [-2.2007e+00, -1.6102e-01,  3.4598e-01,  7.0572e-01,  1.2548e+00,\n",
            "          6.4096e-01, -2.2145e-01, -3.0821e-02],\n",
            "        [-2.0526e+00, -2.4647e-01, -3.6392e-01, -1.1395e+00,  3.1668e-02,\n",
            "          6.7401e+00, -1.3052e+00, -6.5828e-01],\n",
            "        [-1.3658e+00, -5.8224e-01,  1.8377e+00, -6.4842e-01,  2.4332e-01,\n",
            "          1.4687e+00, -4.2292e-01, -2.9401e-01],\n",
            "        [-2.7749e+00,  4.0922e-01, -5.7023e-01,  5.4455e-02,  2.2918e+00,\n",
            "          7.4578e-02, -8.4458e-01,  1.0074e+00],\n",
            "        [-1.6728e+00,  8.8210e-01, -6.1375e-01, -1.4083e+00,  1.6840e+00,\n",
            "          1.4140e+00, -1.3415e+00,  4.2200e-01],\n",
            "        [-2.2530e+00,  1.1716e+00, -1.2994e+00, -5.9905e-01,  2.3009e+00,\n",
            "         -5.6555e-01, -1.2065e+00,  1.1882e+00],\n",
            "        [-3.0656e+00,  8.2411e-01, -1.5848e+00, -1.7477e+00,  2.7768e+00,\n",
            "         -1.2519e+00, -1.1578e+00,  2.9589e+00],\n",
            "        [-8.6713e-01, -7.2177e-01,  2.3018e+00, -9.5812e-01,  2.3203e-01,\n",
            "          1.5192e+00, -2.9824e-01, -6.4261e-01],\n",
            "        [-3.4306e+00,  2.6755e+00, -4.5907e-01, -1.4120e+00,  5.1651e-01,\n",
            "          5.7395e-01, -1.5559e+00,  1.6261e+00],\n",
            "        [-2.4335e+00,  6.2830e-01, -8.9993e-01, -1.1511e+00,  2.5784e+00,\n",
            "          1.4474e-01, -7.3719e-01,  8.6470e-01],\n",
            "        [-3.3094e+00,  3.3800e+00, -2.6150e+00, -2.1602e+00,  3.3112e+00,\n",
            "         -1.4084e+00, -1.9389e+00,  2.1937e+00],\n",
            "        [-2.3348e+00,  5.8393e-01, -1.1155e+00, -1.1974e+00,  3.1751e+00,\n",
            "         -9.6392e-02, -9.8366e-01,  1.0966e+00],\n",
            "        [-2.5817e+00,  6.7961e-01, -1.7855e+00, -1.8318e+00,  3.9905e+00,\n",
            "         -1.0798e+00, -7.2012e-01,  1.5919e+00],\n",
            "        [-1.8721e+00,  1.6450e+00, -8.9188e-01, -1.4427e+00,  2.3646e+00,\n",
            "         -7.9963e-01, -1.6974e+00,  1.4455e+00],\n",
            "        [-3.1778e+00,  1.7318e+00, -2.2772e+00, -1.5880e+00,  3.6173e+00,\n",
            "         -1.4000e+00, -1.3581e+00,  2.0162e+00],\n",
            "        [-5.8486e-01, -9.8383e-01,  1.7321e+00, -3.0108e-01,  1.9022e-01,\n",
            "          1.2609e+00, -5.8311e-01, -3.2745e-01],\n",
            "        [-2.3804e+00,  1.3605e+00, -9.6310e-01, -1.0639e+00,  2.4551e+00,\n",
            "         -3.5758e-01, -3.6584e-01,  8.9401e-01],\n",
            "        [-2.8347e+00,  1.8231e+00, -1.5498e+00, -1.3134e+00,  2.7008e+00,\n",
            "         -7.2789e-01, -1.0773e+00,  1.6314e+00],\n",
            "        [-1.7049e+00, -4.1621e-01,  2.1230e+00, -1.0410e+00, -6.0950e-02,\n",
            "          2.3719e+00,  1.8345e-02, -5.2128e-01],\n",
            "        [-2.3036e+00, -4.9975e-02,  3.2025e+00, -1.6288e+00, -7.3522e-01,\n",
            "          1.0385e+00, -3.4381e-01,  1.2267e+00],\n",
            "        [-2.7496e+00,  2.6299e+00, -1.4646e+00, -5.7732e-01,  1.9500e+00,\n",
            "         -7.7600e-01, -1.6462e+00,  1.3849e+00],\n",
            "        [-2.7126e+00,  1.0506e+00, -1.6034e+00, -1.4362e+00,  2.8738e+00,\n",
            "         -9.5187e-01, -1.1105e+00,  2.2096e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.1522,  0.2150, -1.2097, -1.6981,  3.0372, -0.1855, -0.5166,  2.5011],\n",
            "        [-3.2366,  0.8567, -1.5245, -1.6889,  3.7033, -0.8522, -0.2794,  1.2282],\n",
            "        [-1.9888,  0.4999, -0.6847, -1.0409,  2.0449,  0.1973, -0.8085,  0.9371],\n",
            "        [ 0.6296, -0.9052,  2.4230, -1.3537, -0.7354,  2.0544, -0.6635, -1.0193],\n",
            "        [-2.9509,  1.0528, -2.0042, -1.6871,  3.6260, -0.8110, -1.3495,  1.9175],\n",
            "        [-3.0576,  2.2326, -1.8830, -1.2341,  3.0082, -1.0300, -0.6717,  1.0484],\n",
            "        [-2.4512,  0.3971, -1.7807, -1.5441,  3.2645, -1.3130, -1.6025,  3.3577],\n",
            "        [-2.8397,  4.0210, -1.7899, -1.7741,  1.9596, -1.0214, -1.6380,  0.6975],\n",
            "        [-3.2169,  2.3278, -2.1352, -1.3390,  2.6283, -1.0673, -1.2733,  2.1735],\n",
            "        [-2.6561,  0.6209, -0.3910, -1.1043,  1.6520,  0.0271,  1.0479,  0.3445],\n",
            "        [-2.6755,  1.5643, -1.8742, -2.4324,  3.8358, -0.9120, -1.2767,  1.1625],\n",
            "        [-1.8035, -0.6549, -1.4535, -2.0265,  6.7156, -0.6136, -0.8563, -0.3572],\n",
            "        [-2.7728,  1.4207, -1.5389, -0.0194,  1.7137, -0.8858, -1.5451,  1.8737],\n",
            "        [-2.3957, -0.2565, -0.0893, -1.3905,  0.4029,  6.7069, -0.9335, -0.7793],\n",
            "        [-2.7037,  0.6359, -0.2564, -1.5196,  2.1528,  0.0300, -0.7062,  1.3683],\n",
            "        [-2.1598,  0.1440, -0.4960,  0.4431,  1.8040,  0.1791, -0.9645,  0.5905],\n",
            "        [-1.8744, -0.0629, -0.1157, -0.8190,  0.0753,  6.1819, -1.0460, -0.7778],\n",
            "        [-2.9495,  1.0385, -1.8875, -1.9621,  4.2348, -0.9282, -0.9184,  1.6294],\n",
            "        [-2.2962,  0.8496, -0.4152, -0.9831,  1.9053, -0.2024, -0.3994,  0.6450],\n",
            "        [-2.0550,  1.2601, -1.1989, -0.8959,  2.0223, -0.2356, -1.1591,  1.0242],\n",
            "        [-0.9295, -0.3708,  0.6493, -0.5774,  0.8922,  1.4654, -0.5917, -0.4704],\n",
            "        [-3.0582,  2.0465, -1.9347, -2.1890,  3.0952, -1.2068, -1.7913,  2.6406],\n",
            "        [-2.0355, -0.4488,  5.9054, -2.4514, -0.3726, -0.2181, -0.9089, -0.3139],\n",
            "        [-1.6491,  0.4777, -0.3210, -1.0800,  1.9819, -0.4988, -0.5818,  0.5762],\n",
            "        [-3.0085,  0.7996, -1.0990, -0.9272,  2.6902, -0.1137, -0.9515,  1.5797],\n",
            "        [-1.8298,  0.1273,  0.5616, -0.2714,  0.9443,  0.9168, -0.2018,  0.1210],\n",
            "        [-3.2062,  3.7903, -2.3564, -2.2661,  2.7130, -1.5389, -1.8020,  1.7342],\n",
            "        [-2.0998,  0.7627, -0.8940, -1.5122,  2.5165, -0.3215, -0.8098,  1.2136],\n",
            "        [-1.2480, -0.8683,  2.2520, -1.1350, -0.0328,  1.9489, -0.0439, -0.4350],\n",
            "        [-0.6072, -0.7018,  1.1548, -1.2491,  0.7714,  1.6239, -0.4768, -0.1776],\n",
            "        [-2.1439, -0.3338,  1.6085, -1.1269, -0.0918,  2.8996, -0.3838, -0.3343],\n",
            "        [-1.7212, -0.7586,  3.3675, -1.2798, -0.8290,  2.5508, -0.5995, -0.1476]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3333, -0.2547,  0.3593, -1.1298,  1.2153,  2.4149, -1.2290, -0.1383],\n",
            "        [-1.1246, -0.7270,  2.1003, -1.1060, -0.1446,  2.1750, -0.5701, -0.1926],\n",
            "        [-2.0817, -0.1689, -1.1740,  4.6083,  0.6575, -0.8109, -1.1475, -0.1771],\n",
            "        [-1.7084, -0.0885,  1.5689, -1.4823, -0.0224,  1.9630, -0.7816,  0.2505],\n",
            "        [-1.8465,  1.3164, -1.7300, -1.9775,  2.6217,  0.7489, -1.7617,  0.8785],\n",
            "        [-1.3947, -0.4205, -0.5629, -1.0429,  2.3372,  0.4082, -0.5184,  0.6762],\n",
            "        [-2.8540,  2.4643, -2.2980, -1.5424,  3.0701, -1.3263, -1.1903,  1.9401],\n",
            "        [-2.8187,  2.4821, -1.5854, -0.7413,  1.8173, -0.9273, -1.5857,  1.6988],\n",
            "        [-3.5277,  5.1005, -2.5243, -2.6642,  2.3768, -2.0475, -1.6992,  0.5075],\n",
            "        [-1.7738,  1.2438,  0.0324, -1.1548,  1.3926,  0.2245, -1.1806,  0.8456],\n",
            "        [-1.8420,  0.8109, -0.2918, -1.0906,  1.7076,  0.3606, -0.8248,  0.8218],\n",
            "        [-2.1751,  1.6187, -0.8321, -0.3737,  1.6943, -0.3505, -0.8984,  0.5633],\n",
            "        [-1.7510, -0.2080,  0.8978, -1.1727,  1.0960,  0.7912, -0.4029,  0.7293],\n",
            "        [-1.7462,  1.3283, -0.9456, -0.8685,  2.0519, -0.3183, -1.3067,  0.8823],\n",
            "        [-3.0372,  5.7571, -2.1553, -2.7269,  1.2754, -1.5437, -2.5413,  1.0568],\n",
            "        [-2.5213,  1.2322, -1.6922, -1.9156,  3.8054, -0.5554, -0.9500,  1.0030],\n",
            "        [-2.6169,  1.8583, -1.2164, -0.7830,  1.9398, -0.6850, -1.2652,  1.2433],\n",
            "        [-2.7143,  0.8472, -0.8009, -0.5601,  2.3690, -0.2706, -0.6640,  1.0679],\n",
            "        [-1.9623, -0.0778,  5.6547, -2.1481, -0.6887,  0.0149, -1.1574, -0.3004],\n",
            "        [-1.6068,  0.4108,  0.4121, -1.1161,  1.3579, -0.2581, -0.3722,  0.8197],\n",
            "        [-1.2209,  0.5383,  0.4279,  0.0635,  0.8855,  0.4690, -0.9220,  0.0912],\n",
            "        [-1.4544, -0.6486, -1.6925, -2.0898,  6.9540, -0.7740, -1.1623, -0.6384],\n",
            "        [-1.7810, -0.5195,  2.6115, -0.6792, -0.7820,  2.2453, -0.0086, -0.2512],\n",
            "        [-1.4162,  0.1511,  0.6210, -0.3318,  0.6582,  0.9971, -0.1939, -0.1248],\n",
            "        [-1.4714, -0.4873,  0.0407, -1.3223,  0.2907,  6.3381, -0.4860, -1.6940],\n",
            "        [-3.1887,  0.1716, -1.2007, -1.2911,  3.0521, -1.2296, -0.6098,  3.1518],\n",
            "        [-2.5403,  2.2581, -1.3657, -0.7307,  1.7886, -0.7745, -1.4371,  1.5979],\n",
            "        [-1.2874,  0.5592, -0.4502, -1.2216,  1.9977,  0.4439, -1.1278,  0.5100],\n",
            "        [-2.0409, -0.4063, -2.0283, -2.0520,  6.8914, -0.5790, -0.9265, -0.3961],\n",
            "        [-3.0241,  1.0027, -1.7969, -2.2607,  4.3309, -0.9494, -0.9194,  1.4060],\n",
            "        [-2.9576,  3.0120, -2.2355, -2.1969,  3.0893, -0.7989, -1.4299,  1.5844],\n",
            "        [-2.8296,  2.5937, -1.4909, -1.0193,  1.8383, -0.5670, -1.1748,  1.3136]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3727, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3789,  0.5010,  0.4502, -0.8794,  1.3941,  0.0437, -0.9856,  0.4250],\n",
            "        [-3.2077,  2.4144, -2.6461, -1.7989,  3.8094, -1.3189, -1.6140,  2.2389],\n",
            "        [-0.9329, -0.3988,  0.2619, -0.2083,  1.2624,  1.0125, -1.1619,  0.2453],\n",
            "        [-2.7239,  1.2618, -1.5758, -0.5601,  2.1035, -0.8849, -1.6456,  2.1950],\n",
            "        [-2.8971,  1.0008, -1.8660, -2.0823,  4.2312, -0.7054, -0.8556,  1.0357],\n",
            "        [-2.9929,  1.1162, -2.3293, -1.7284,  3.6486, -1.1908, -1.3347,  2.4334],\n",
            "        [-2.0904,  0.7087,  0.1235, -0.4776,  1.5592,  0.0576, -0.6962,  0.5430],\n",
            "        [-1.8266, -0.9085, -1.3960, -2.0142,  6.9893, -0.7897, -0.9125, -0.5178],\n",
            "        [-3.1590,  1.2556,  0.2760, -1.7429,  0.2821, -1.0706, -1.4075,  4.5872],\n",
            "        [-0.6431, -0.1395,  0.3219, -1.2733,  1.8472,  0.1631, -0.9986,  0.2618],\n",
            "        [-2.0068, -0.2652, -0.3739,  2.6990,  0.7229,  0.1745, -0.3357, -0.1874],\n",
            "        [ 0.2192, -0.8380,  2.5559, -1.0499, -0.7032,  2.3829, -0.2334, -1.0540],\n",
            "        [-2.7396,  0.8442, -1.3681, -0.4232,  2.5989, -1.2879, -0.6069,  1.3759],\n",
            "        [-2.6091,  0.9787, -1.4486, -0.8178,  2.9780, -0.6183, -0.9634,  1.5091],\n",
            "        [-3.1792,  2.2404, -1.8874, -1.0284,  2.5557, -1.1753, -0.7438,  1.9809],\n",
            "        [-3.2492,  1.1913, -1.8279, -0.8327,  2.7199, -1.0837, -1.5392,  3.2271],\n",
            "        [-0.2999,  0.1912,  0.1172, -0.5854,  1.0804,  0.1334, -0.9461,  0.0680],\n",
            "        [-1.2621,  0.6788,  0.5889, -0.3859,  0.7953,  0.5909, -0.6324,  0.0511],\n",
            "        [-2.9146,  5.8718, -2.3941, -2.5446,  1.9743, -1.9759, -1.9651,  0.6810],\n",
            "        [-3.0539,  5.8599, -2.2060, -2.5317,  1.6498, -1.4829, -2.1763,  0.9665],\n",
            "        [-0.8823,  0.8370,  0.5500, -0.3614,  0.1978,  0.8001, -0.2990, -0.4917],\n",
            "        [-2.8155,  2.6681, -1.7308, -0.6351,  2.1751, -1.1277, -1.5535,  1.5363],\n",
            "        [-1.6077, -0.6226,  2.0517, -0.7151, -0.3939,  2.7087, -0.3838, -0.4166],\n",
            "        [-1.8435,  0.1265,  0.1857, -1.5871,  1.7872,  0.5348, -1.0217,  1.3096],\n",
            "        [-3.5003,  1.3039, -2.3406, -2.4864,  5.5608, -1.1311, -0.4109,  0.6023],\n",
            "        [-2.8787,  2.2094, -1.5910, -1.6802,  2.3863, -0.6269, -1.4674,  1.4570],\n",
            "        [-2.1141,  0.1784,  0.5824, -1.2618,  1.2063,  0.5470, -0.0390,  0.4409],\n",
            "        [-2.0728,  0.1426, -0.2487, -1.4725,  2.2329,  0.5811, -0.5736,  0.8313],\n",
            "        [-2.0531,  0.6998, -1.8949, -1.8282,  3.2117, -0.2181, -0.5175,  1.0650],\n",
            "        [-2.3058, -0.4890,  2.1157, -1.2138, -0.2518,  2.8241, -0.3688, -0.0565],\n",
            "        [-1.8900,  0.7887,  0.4306, -1.1387,  0.9325, -0.2569, -0.7503,  1.3361],\n",
            "        [-3.0882,  0.7230, -1.9228, -2.0845,  4.3667, -0.6838, -0.3764,  1.4966]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2269, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.9379e+00,  2.1377e+00, -2.3648e+00, -1.4593e+00,  3.6150e+00,\n",
            "         -1.2071e+00, -1.5421e+00,  1.6876e+00],\n",
            "        [-2.2246e+00,  1.2107e+00, -6.6894e-01, -1.6136e+00,  1.9394e+00,\n",
            "          2.3150e-01, -1.1140e+00,  1.3954e+00],\n",
            "        [-1.5617e+00,  1.4872e-01, -4.0759e-01,  1.4321e+00,  1.0428e+00,\n",
            "         -1.9977e-01, -6.2698e-01,  2.3373e-01],\n",
            "        [-2.9292e+00,  2.3404e+00, -2.0385e+00, -8.1797e-01,  2.2079e+00,\n",
            "         -9.2287e-01, -1.3788e+00,  1.9968e+00],\n",
            "        [-1.6681e+00, -7.6014e-01,  2.5995e+00, -9.0914e-01, -8.7460e-01,\n",
            "          3.4036e+00, -1.0458e-01, -9.2656e-01],\n",
            "        [-1.5067e+00,  3.2895e-01, -1.3565e-01, -1.3762e-01,  1.0308e+00,\n",
            "          7.5153e-01, -1.5311e-01, -1.7876e-01],\n",
            "        [-1.0605e+00, -4.3355e-01,  1.0793e+00, -1.7488e-01,  9.8537e-01,\n",
            "          9.2504e-01, -8.2359e-01, -1.5364e-01],\n",
            "        [-2.5898e+00, -3.4906e-01,  3.6797e-01, -2.8989e-01,  9.9386e-01,\n",
            "          5.0969e-01, -3.8740e-01,  1.4671e+00],\n",
            "        [-1.6497e+00,  5.8237e-01, -4.2801e-01, -1.2651e+00,  1.6382e+00,\n",
            "          3.3239e-01, -5.1140e-01,  9.5832e-01],\n",
            "        [-1.8976e+00,  4.1625e-01,  4.4019e-01, -7.0277e-01,  1.0344e+00,\n",
            "          8.8647e-01, -5.9467e-01,  5.2950e-01],\n",
            "        [-1.8659e+00, -1.2305e-01, -1.9119e+00, -2.4355e+00,  6.7369e+00,\n",
            "         -7.8661e-01, -6.2412e-01, -2.3593e-01],\n",
            "        [-2.1180e+00,  1.6016e+00, -1.1484e+00, -9.7556e-01,  2.3676e+00,\n",
            "         -8.5968e-01, -1.0757e+00,  1.0922e+00],\n",
            "        [-3.1258e+00,  1.8339e+00, -2.9558e+00, -2.0379e+00,  4.2405e+00,\n",
            "         -1.9616e+00, -1.1198e+00,  2.2609e+00],\n",
            "        [-2.5629e+00,  2.2324e+00, -1.5565e+00, -5.0774e-01,  1.8242e+00,\n",
            "         -7.2156e-01, -1.4612e+00,  1.2096e+00],\n",
            "        [-3.8233e+00,  2.7137e+00, -1.7766e+00, -1.3958e+00,  1.6412e+00,\n",
            "         -5.9183e-01, -1.7147e+00,  2.9074e+00],\n",
            "        [-2.0116e+00,  1.2052e+00, -4.6865e-01, -5.7944e-01,  1.3369e+00,\n",
            "          2.0861e-01, -8.9761e-01,  8.0640e-01],\n",
            "        [-2.7797e+00,  1.9037e+00, -2.4638e+00, -1.5080e+00,  2.9895e+00,\n",
            "         -1.3978e+00, -1.5599e+00,  2.7656e+00],\n",
            "        [-6.9735e-01, -5.4135e-01,  2.7074e+00, -1.2627e+00,  7.9918e-02,\n",
            "          1.4515e+00, -4.4335e-01, -6.7340e-01],\n",
            "        [-3.2207e+00,  1.4524e+00, -2.3585e+00, -1.3275e+00,  3.2934e+00,\n",
            "         -1.3186e+00, -1.4576e+00,  2.9256e+00],\n",
            "        [-2.4805e+00,  7.6434e-01, -8.0772e-01, -8.2308e-01,  2.4181e+00,\n",
            "         -6.5432e-02, -6.4283e-01,  9.1607e-01],\n",
            "        [-1.1225e+00, -1.0474e+00,  5.3433e-01,  8.2003e-02, -5.9510e-02,\n",
            "         -1.1589e+00,  5.1570e+00,  6.6009e-03],\n",
            "        [-2.7078e+00,  1.0720e+00, -1.6735e+00, -1.5998e+00,  3.6015e+00,\n",
            "         -1.0337e+00, -1.0024e+00,  1.7201e+00],\n",
            "        [-1.7053e+00,  6.6478e-02,  2.6111e-01, -2.0432e-01,  1.4008e+00,\n",
            "          4.0417e-01, -5.7463e-01,  2.3964e-01],\n",
            "        [-2.1177e+00, -8.6570e-01,  5.7820e+00, -1.9214e+00,  8.5927e-02,\n",
            "         -3.2177e-02, -2.7242e-01, -5.4135e-01],\n",
            "        [-3.0072e+00,  1.6177e+00, -2.3274e+00, -1.3511e+00,  3.1238e+00,\n",
            "         -1.2274e+00, -1.1311e+00,  2.6090e+00],\n",
            "        [-3.4085e+00,  3.4974e+00, -2.6687e+00, -2.6091e+00,  3.6810e+00,\n",
            "         -1.8601e+00, -2.0633e+00,  2.4028e+00],\n",
            "        [-3.0160e+00,  8.7568e-01, -2.0748e+00, -2.6674e+00,  4.8686e+00,\n",
            "         -6.5276e-01, -6.0838e-01,  1.4609e+00],\n",
            "        [-2.4764e+00,  1.8518e+00, -1.7150e+00, -1.9965e+00,  3.1302e+00,\n",
            "         -7.4471e-01, -1.0207e+00,  1.6850e+00],\n",
            "        [-2.2696e+00,  5.9045e-01, -6.8456e-01, -3.3762e-01,  2.2770e+00,\n",
            "         -1.1813e-01, -6.6794e-01,  8.2158e-01],\n",
            "        [-1.8487e+00,  7.1384e-01, -1.7270e-01, -9.0736e-01,  1.4743e+00,\n",
            "          4.0308e-01, -1.0353e+00,  6.8621e-01],\n",
            "        [-1.5653e+00,  1.1542e+00, -7.7114e-01, -1.1252e+00,  1.7615e+00,\n",
            "          5.3930e-01, -1.1234e+00,  5.2226e-01],\n",
            "        [-3.5224e+00,  2.0780e+00, -2.5499e+00, -1.1910e+00,  2.9183e+00,\n",
            "         -1.9204e+00, -1.6978e+00,  3.1309e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.7397e+00,  2.8311e-01, -3.5491e-01, -1.3067e+00,  2.0466e+00,\n",
            "          5.8802e-01, -8.3425e-01,  8.6487e-01],\n",
            "        [-3.0488e+00,  1.5544e+00, -2.0090e+00, -7.6825e-01,  2.9965e+00,\n",
            "         -1.2539e+00, -1.2109e+00,  1.9970e+00],\n",
            "        [-7.8078e-01, -2.3326e-01,  5.9807e-01, -1.1219e+00,  1.7016e+00,\n",
            "          2.0596e-01, -9.6199e-01,  3.0751e-01],\n",
            "        [-9.9300e-01, -9.1383e-02,  1.6097e+00, -5.9830e-01, -9.7417e-02,\n",
            "          1.7957e+00, -3.4147e-01, -3.9212e-01],\n",
            "        [-1.8531e+00,  1.8882e+00, -3.1942e-02, -7.6091e-01,  8.2836e-01,\n",
            "          1.6574e-01, -7.9179e-01,  1.3001e-01],\n",
            "        [-2.8150e+00,  5.9335e+00, -2.2279e+00, -2.1561e+00,  1.4080e+00,\n",
            "         -1.9971e+00, -1.9595e+00,  4.6468e-01],\n",
            "        [-2.9598e+00,  2.6533e+00, -2.0524e+00, -1.7881e+00,  2.9614e+00,\n",
            "         -1.3923e+00, -1.6921e+00,  1.6828e+00],\n",
            "        [-3.1211e+00,  3.2474e+00, -2.3786e+00, -1.6482e+00,  2.8347e+00,\n",
            "         -1.1999e+00, -1.9064e+00,  1.5971e+00],\n",
            "        [-2.9612e+00,  2.2653e+00, -2.7464e+00, -2.1403e+00,  4.3990e+00,\n",
            "         -1.3272e+00, -1.3834e+00,  1.4334e+00],\n",
            "        [-1.8675e+00,  1.4303e+00, -9.6962e-01, -9.3853e-01,  1.9473e+00,\n",
            "         -9.1188e-02, -1.1095e+00,  8.5040e-01],\n",
            "        [-9.0452e-01,  1.4698e-01, -4.3957e-01, -6.1104e-01,  1.6579e+00,\n",
            "          5.5201e-01, -7.6227e-01,  2.8684e-01],\n",
            "        [-1.3272e+00, -4.4074e-01,  7.8969e-01, -1.1031e+00,  9.1575e-01,\n",
            "          1.4122e+00, -5.5986e-01,  3.2562e-01],\n",
            "        [ 4.7368e-02, -6.4458e-01,  2.4825e+00, -1.2306e+00, -7.2158e-01,\n",
            "          2.3314e+00, -6.0790e-01, -8.3013e-01],\n",
            "        [-2.3351e+00,  1.7198e+00, -7.5749e-01, -1.5298e+00,  1.7548e+00,\n",
            "          7.0123e-02, -8.6186e-01,  1.1626e+00],\n",
            "        [-1.8607e+00, -2.8794e-01,  4.4073e+00, -1.8983e+00, -1.1553e+00,\n",
            "          1.7240e+00, -6.7953e-01, -1.2450e-01],\n",
            "        [-6.5917e-01, -4.5192e-01,  1.1916e+00, -1.2794e+00,  6.2235e-01,\n",
            "          1.2414e+00, -6.8262e-01, -1.2444e-01],\n",
            "        [-1.7738e+00,  1.5244e+00, -6.6720e-01, -1.1990e+00,  1.7032e+00,\n",
            "         -1.5217e-01, -1.1370e+00,  9.2043e-01],\n",
            "        [-1.5304e+00, -7.3370e-01,  4.8322e-01, -8.4323e-01,  1.6541e+00,\n",
            "          7.2881e-01, -4.4896e-01,  3.4398e-01],\n",
            "        [-2.5235e+00,  1.9013e+00, -2.1926e+00, -1.5188e+00,  2.7498e+00,\n",
            "         -8.3057e-01, -1.8320e+00,  2.5113e+00],\n",
            "        [-3.3033e+00,  2.1526e+00, -2.3599e+00, -1.1613e+00,  3.0715e+00,\n",
            "         -1.4325e+00, -1.4505e+00,  2.3101e+00],\n",
            "        [-1.8006e+00,  5.4889e-02, -6.8430e-01, -2.1880e+00,  3.0959e+00,\n",
            "         -2.9351e-01, -1.1477e+00,  1.1164e+00],\n",
            "        [-1.8192e+00, -4.6672e-02,  2.0821e-01, -4.0455e-01,  9.6604e-01,\n",
            "         -1.1661e-01,  1.1174e+00,  2.8383e-03],\n",
            "        [-1.3023e+00,  5.2039e-01, -5.3091e-01, -5.6625e-01,  1.9702e+00,\n",
            "          1.5559e-01, -1.1586e+00,  3.6286e-01],\n",
            "        [-1.3693e+00, -1.2413e+00, -1.3749e+00, -1.6279e+00,  6.9937e+00,\n",
            "         -6.1389e-01, -9.3598e-01, -6.6536e-01],\n",
            "        [-1.1460e+00, -2.8222e-01,  1.8749e+00, -1.3505e+00,  3.5420e-01,\n",
            "          1.3704e+00, -1.7494e-01, -2.3340e-01],\n",
            "        [-8.7815e-01,  1.9839e-01,  7.3319e-01, -9.4319e-01,  6.8037e-01,\n",
            "          4.9943e-01, -6.1954e-01,  3.1392e-01],\n",
            "        [-2.8443e+00,  6.9933e-01, -1.3563e+00, -1.4343e+00,  3.4293e+00,\n",
            "         -6.9198e-01, -8.3803e-01,  1.3991e+00],\n",
            "        [-1.9838e+00, -3.4114e-01, -2.5164e-01, -1.1212e+00,  7.1589e-02,\n",
            "          6.3583e+00, -1.0664e+00, -6.5868e-01],\n",
            "        [-2.3345e+00,  1.4830e+00, -1.6231e+00, -1.7202e+00,  3.2636e+00,\n",
            "         -1.6808e-01, -1.1003e+00,  8.9937e-01],\n",
            "        [-2.4015e+00,  1.0765e+00, -1.5430e+00, -1.5866e+00,  3.0289e+00,\n",
            "         -7.1633e-01, -1.4000e+00,  2.0663e+00],\n",
            "        [-1.0510e+00, -7.6582e-01,  4.4219e-01,  1.3392e+00,  6.6126e-01,\n",
            "          1.4193e+00, -7.9698e-01, -5.9975e-01],\n",
            "        [-2.3183e+00,  1.5024e+00,  3.1631e-01, -1.2135e+00,  4.4178e-01,\n",
            "          8.0409e-01, -9.1827e-01,  7.4756e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.1795e+00,  6.7028e-01, -1.7654e+00, -2.1382e+00,  4.5155e+00,\n",
            "         -8.4966e-01, -4.6962e-01,  1.5423e+00],\n",
            "        [-3.5121e+00,  3.3031e+00, -3.2682e+00, -2.1002e+00,  3.5175e+00,\n",
            "         -2.0967e+00, -1.7037e+00,  2.6599e+00],\n",
            "        [-2.5783e+00,  1.7065e+00, -7.8599e-01, -6.5090e-01,  1.1423e+00,\n",
            "         -4.5980e-01, -5.7046e-01,  1.1902e+00],\n",
            "        [-2.8398e+00,  6.9822e-01, -1.5610e+00, -1.2448e+00,  2.9524e+00,\n",
            "         -9.9502e-01, -1.4832e+00,  2.7548e+00],\n",
            "        [-2.6227e+00,  7.1995e-01, -1.5486e+00, -2.0050e+00,  3.9233e+00,\n",
            "         -1.5237e-01, -8.4929e-01,  1.0850e+00],\n",
            "        [-3.6100e+00,  3.3264e+00, -2.3350e+00,  1.5904e+00,  1.3612e+00,\n",
            "         -2.2359e+00, -8.6587e-01,  6.8229e-01],\n",
            "        [-1.9277e+00,  6.0236e-01,  3.8202e-02, -7.6724e-01,  1.4004e+00,\n",
            "          2.0448e-01, -8.5404e-01,  7.5796e-01],\n",
            "        [-2.8391e+00,  8.0281e-01, -1.8789e+00, -1.6945e+00,  3.7227e+00,\n",
            "         -6.5433e-01, -4.7400e-01,  1.4463e+00],\n",
            "        [-9.9863e-01,  3.8776e-01, -4.5172e-01, -4.9239e-01,  1.6186e+00,\n",
            "          2.5599e-01, -1.0683e+00,  5.4038e-01],\n",
            "        [-6.4636e-01, -4.7940e-01,  2.9617e-01, -8.6982e-01,  1.4488e+00,\n",
            "          1.1659e+00, -8.4524e-01, -1.0911e-01],\n",
            "        [-1.3633e+00,  6.6393e-02,  1.1039e+00, -5.4592e-01,  7.8372e-01,\n",
            "          7.2819e-01, -7.0339e-01,  4.4646e-02],\n",
            "        [-2.4374e+00,  2.1124e+00, -1.1549e+00, -6.8675e-01,  1.3010e+00,\n",
            "         -1.6980e-01, -1.4512e+00,  1.4321e+00],\n",
            "        [-2.6340e+00,  1.9874e+00, -1.6891e+00, -1.1829e+00,  2.2630e+00,\n",
            "         -6.7049e-01, -1.3495e+00,  1.4067e+00],\n",
            "        [-1.8611e+00,  5.3188e-01, -1.4369e-01, -9.9807e-01,  1.9098e+00,\n",
            "         -9.9901e-02, -8.9824e-01,  9.3700e-01],\n",
            "        [-1.7427e+00,  1.2100e+00, -7.9176e-01, -1.2449e+00,  2.1982e+00,\n",
            "         -9.8448e-02, -1.1046e+00,  9.7631e-01],\n",
            "        [-1.6573e+00, -8.9789e-01, -1.4538e+00, -1.5355e+00,  6.9726e+00,\n",
            "         -4.4774e-01, -1.1878e+00, -8.2956e-01],\n",
            "        [-3.1048e+00,  4.9267e-01, -1.8075e+00, -1.1740e+00,  2.8573e+00,\n",
            "         -1.0137e+00, -1.5076e+00,  3.1853e+00],\n",
            "        [-1.9525e+00,  3.7404e-01, -2.0502e-01, -7.5966e-01,  2.0067e+00,\n",
            "          3.8914e-01, -7.0587e-01,  4.9365e-01],\n",
            "        [-2.6150e+00,  1.2149e+00, -6.5889e-01, -2.5060e-01,  1.6080e+00,\n",
            "         -2.7851e-01, -1.1428e+00,  1.4144e+00],\n",
            "        [-1.5966e+00,  5.8091e-01, -2.3024e-01, -7.6497e-01,  1.5759e+00,\n",
            "          1.6683e-01, -9.0636e-01,  6.4467e-01],\n",
            "        [-1.5481e+00,  6.5667e-01, -1.5758e+00, -1.0479e+00,  2.8283e+00,\n",
            "          6.8211e-01, -1.4566e+00,  1.4391e-01],\n",
            "        [-3.0309e+00,  2.0315e+00, -1.6390e+00, -1.4307e+00,  1.8316e+00,\n",
            "         -5.8830e-01, -1.5398e+00,  2.7381e+00],\n",
            "        [-1.9927e+00,  5.2830e-01,  4.6058e-02,  1.1074e+00,  7.4201e-01,\n",
            "          1.4579e-01, -5.4037e-01,  5.7516e-02],\n",
            "        [-1.2293e+00, -5.6565e-02,  1.5286e+00, -3.3074e-01, -4.3915e-01,\n",
            "          1.9722e+00,  2.3282e-01, -9.4186e-01],\n",
            "        [-3.2142e+00,  2.0358e+00, -2.4830e+00, -1.2414e+00,  3.0835e+00,\n",
            "         -1.3461e+00, -1.9631e+00,  3.2859e+00],\n",
            "        [-1.1456e+00, -1.0532e+00, -9.1287e-02,  1.3083e-01, -6.3736e-02,\n",
            "          5.4618e+00, -5.3347e-01, -1.4746e+00],\n",
            "        [-1.4975e+00,  9.6948e-02,  4.6549e-01, -1.4694e+00,  1.9813e+00,\n",
            "          6.5764e-03, -7.6831e-01,  8.3027e-01],\n",
            "        [-3.2920e+00, -2.3593e-02, -7.5327e-01,  4.6539e+00,  5.7987e-01,\n",
            "         -1.2638e+00,  4.3653e-01, -1.1841e-01],\n",
            "        [-2.7375e+00,  1.6576e+00, -2.1289e+00, -1.5761e+00,  3.1523e+00,\n",
            "         -1.0382e+00, -1.6212e+00,  2.2310e+00],\n",
            "        [-3.0266e+00,  3.0608e+00, -2.6963e+00, -2.1829e+00,  3.2738e+00,\n",
            "         -1.4958e+00, -1.8468e+00,  2.0768e+00],\n",
            "        [-3.2347e+00,  2.0498e+00, -2.4072e+00, -1.1344e+00,  2.4285e+00,\n",
            "         -1.5913e+00, -1.5268e+00,  3.6267e+00],\n",
            "        [-2.8108e+00,  2.6964e+00, -2.4471e+00, -2.2316e+00,  3.4976e+00,\n",
            "         -1.1591e+00, -1.3113e+00,  1.4467e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.7517, -0.0455,  0.9189, -0.9158,  0.6441,  0.8905, -0.7861, -0.0623],\n",
            "        [-2.4020,  0.4828, -2.2488, -2.0322,  3.5391, -0.4578, -1.3552,  2.5848],\n",
            "        [-2.6316,  0.9900, -0.8809,  0.6313,  1.4200, -0.2340, -0.9217,  0.6570],\n",
            "        [-2.5814,  1.7879, -1.8498,  0.2532,  1.9139, -0.8650, -1.5636,  1.5260],\n",
            "        [-2.5989,  1.9795, -1.4072, -0.7296,  2.0356, -0.6064, -1.4189,  1.5401],\n",
            "        [-2.9730,  0.3064, -0.5653, -0.8773,  1.7592,  0.0638, -1.3637,  3.2024],\n",
            "        [-1.7564, -0.0195,  1.6420, -1.1604,  0.0212,  1.4975, -0.3757,  0.1719],\n",
            "        [-1.2064,  0.0085,  0.4778,  0.2941,  1.2087,  0.4153, -0.9611, -0.0975],\n",
            "        [-1.2473, -0.4543,  2.7290, -1.0280, -1.2084,  3.4071, -0.2996, -0.7068],\n",
            "        [-2.2198,  2.3758, -0.9075, -0.9467,  0.7254,  0.0417, -1.3221,  1.3117],\n",
            "        [-1.0348, -0.4915,  1.6983, -0.9816,  0.4239,  1.5777,  0.1508, -0.5466],\n",
            "        [-1.9329, -0.9257,  0.6542, -0.4675,  0.0471, -0.8608,  5.2469,  0.3212],\n",
            "        [-2.1230,  0.6540, -0.0788, -1.0787,  1.7259,  0.4992, -0.2691,  0.5660],\n",
            "        [-1.9496, -0.4587, -2.0022, -2.1505,  7.0706, -0.7440, -0.6581, -0.3925],\n",
            "        [-1.2275, -0.6326,  1.7184, -0.6116,  0.1743,  1.8723, -0.4540, -0.3947],\n",
            "        [-1.3062,  0.3468,  0.9276, -0.2530, -0.3324,  1.4954,  0.1446, -0.5519],\n",
            "        [-3.1138,  2.8382, -2.6626, -2.0200,  3.7302, -1.0774, -1.6807,  1.5378],\n",
            "        [-2.4361,  2.7027,  0.5959, -2.3945,  0.8182, -0.3502, -1.4881,  0.7503],\n",
            "        [-1.4287,  0.1569,  1.3692, -0.4015, -0.0148,  1.4637, -0.0502, -0.3431],\n",
            "        [-3.0931,  2.3054, -2.7308, -2.1915,  3.9356, -1.1461, -1.5592,  1.7920],\n",
            "        [-1.2088,  0.2058, -0.5673, -0.9873,  2.1251,  0.0918, -1.0661,  0.8034],\n",
            "        [-1.4280, -0.2364, -0.2922, -1.2243,  2.1457,  0.6477, -0.2384,  0.3927],\n",
            "        [-2.2149,  0.4035,  3.8444, -2.1454, -0.5036,  0.9387, -1.1291,  0.2567],\n",
            "        [-2.5946,  2.7962, -0.2878, -0.8561,  0.5186, -0.1627, -1.3695,  0.3970],\n",
            "        [-3.1196,  0.2080, -1.6657, -1.0211,  1.3312, -1.5378, -1.4898,  5.5018],\n",
            "        [-2.7355,  0.6734, -1.5505, -1.0575,  3.3380, -0.8499, -0.3382,  1.2467],\n",
            "        [-2.1331,  3.6062, -1.0793, -1.1133,  0.9611, -0.9880, -1.5716,  0.7026],\n",
            "        [-1.9899, -0.1613, -0.4182, -1.4637,  0.7269,  6.4990, -1.3082, -0.8939],\n",
            "        [-2.5130,  2.1573, -1.8149, -0.4603,  2.2619, -0.8755, -1.5647,  1.3622],\n",
            "        [-3.0119,  0.7309, -1.9597, -1.9668,  4.3047, -0.8403, -0.3332,  1.1071],\n",
            "        [-2.6261,  1.7443, -2.2872, -1.6873,  3.0892, -0.9444, -1.2678,  1.9348],\n",
            "        [-0.8202,  0.1463, -0.3073, -1.1522,  1.9052,  0.2124, -1.4748,  1.0124]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.8140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.0719,  1.3272, -2.4996, -1.3830,  2.3252, -1.1621, -1.7167,  4.7322],\n",
            "        [-1.5200,  0.5868,  0.3080, -0.7530,  0.3588,  0.7894, -0.9474,  0.9984],\n",
            "        [-2.6941,  1.0070, -2.3621, -2.2091,  4.4909, -0.4137, -0.8401,  0.9258],\n",
            "        [-2.7311,  0.4876, -1.2842, -1.9162,  4.4470, -0.4024, -0.5573,  0.4739],\n",
            "        [-1.3072, -0.5838, -1.4406, -1.9237,  6.5792, -0.5574, -1.2911, -0.6832],\n",
            "        [-1.0910, -0.4118,  1.7533, -0.2308,  0.4291,  1.4565, -0.4596, -0.4220],\n",
            "        [-1.7170,  0.6368, -0.7833, -0.7650,  2.2478,  0.1063, -0.8554,  0.9105],\n",
            "        [ 0.4305, -0.4399,  2.1706, -1.3075, -0.8656,  2.5493, -0.2908, -1.3664],\n",
            "        [-1.7165,  0.7723, -0.6965, -0.5725,  2.0144,  0.0741, -1.2515,  0.8905],\n",
            "        [-1.5168, -0.7200, -1.5090, -1.8859,  6.6642, -0.5197, -0.9535, -0.6602],\n",
            "        [-1.1681,  0.2438, -1.5911, -1.1341,  1.8470,  3.2661, -1.8680, -0.0555],\n",
            "        [-1.8020, -0.0737, -0.9604,  4.3026,  0.4632, -0.2176, -1.3598, -0.1977],\n",
            "        [-1.3561,  0.9240, -0.2304,  1.3696,  0.1372,  0.1911, -0.5860, -0.5867],\n",
            "        [-0.7830,  0.0539,  1.7468, -1.1561,  0.1731,  0.8002,  0.0277, -0.6444],\n",
            "        [-1.9134,  0.0820, -0.5059,  2.5896,  0.5957,  0.0730, -0.4092, -0.3021],\n",
            "        [-0.8158, -0.1834,  0.6540, -0.6112,  1.0281,  1.2975, -0.5124, -0.2412],\n",
            "        [-1.6999, -0.7210, -1.7689, -2.1128,  6.8735, -0.5912, -0.8931, -0.5080],\n",
            "        [-2.3179,  0.7235, -1.2660, -1.3077,  2.5746, -0.2677, -0.8849,  1.5949],\n",
            "        [-3.9498,  0.7850, -2.5211, -1.0370,  2.6228, -1.8571, -1.8557,  5.4363],\n",
            "        [-1.9426, -0.3211, -0.3796, -1.1567,  0.0567,  6.9291, -1.0912, -0.6361],\n",
            "        [-2.0085,  0.0750,  0.2294, -0.6095,  1.5661,  0.6506, -0.6390,  0.7140],\n",
            "        [-1.7485,  0.3086,  1.6346, -1.4532,  0.1975,  1.1299, -0.2673,  0.2412],\n",
            "        [-1.5247,  0.9923, -0.1381, -1.4317,  1.3317, -0.0480, -1.0848,  0.9407],\n",
            "        [-3.4217,  1.5681, -1.7459, -0.9035,  2.0896, -0.9120, -1.4303,  3.0984],\n",
            "        [-0.1699, -0.2623,  1.2322, -1.2845,  0.4221,  1.2264, -0.7685, -0.3205],\n",
            "        [-2.9662,  3.0807, -2.6174, -1.5362,  2.5705, -1.6221, -1.9608,  2.5020],\n",
            "        [-1.7967, -0.8293, -1.4676, -1.5251,  6.8581, -0.6050, -0.8719, -0.5189],\n",
            "        [-3.3281,  1.9334, -2.3713, -1.2656,  2.6474, -1.4530, -1.9261,  3.2723],\n",
            "        [-1.7450,  0.5723, -1.1170, -1.1940,  2.6068, -0.0713, -1.2494,  1.3671],\n",
            "        [-3.0931,  2.9177, -2.7368, -1.3886,  2.5077, -1.6079, -1.7055,  2.6049],\n",
            "        [-2.4537,  0.5241, -1.5022, -1.2449,  1.7944, -0.5572, -1.7106,  3.5395],\n",
            "        [-2.8499,  1.9213, -1.6751, -0.9789,  2.0613, -0.5670, -1.0054,  2.0292]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.9592,  0.4435, -1.1922, -1.2994,  2.2449, -0.2918, -0.8579,  2.5712],\n",
            "        [-1.3678, -0.7121, -1.5452, -1.7800,  7.0653, -0.3282, -0.9948, -0.6761],\n",
            "        [-3.1128,  2.7657, -2.1324, -0.8629,  2.5469, -1.1978, -1.5038,  1.7963],\n",
            "        [-2.0047,  1.3430, -1.5604, -0.9851,  2.6566, -0.5669, -1.3077,  1.0948],\n",
            "        [-1.4050,  1.4731, -0.7457, -0.2292,  0.5905,  0.2442, -1.1723,  0.6713],\n",
            "        [-2.5359,  0.7404, -1.3244, -0.3647,  2.7343, -0.4538, -0.4903,  0.8803],\n",
            "        [ 6.0781, -0.4944, -1.0286, -1.0160, -0.6416, -1.1834, -0.4578, -1.1443],\n",
            "        [-1.6937,  0.1989, -0.8541, -1.5562,  0.2506,  6.1066, -1.6379, -0.3993],\n",
            "        [-0.1327,  0.1070,  0.2264, -1.1499,  1.0228,  0.9380, -1.2113, -0.0526],\n",
            "        [-1.7947,  0.5971, -0.7342, -0.4292,  1.7414,  0.1041, -1.1984,  0.8979],\n",
            "        [-2.6950,  1.5319, -2.3928, -1.6118,  3.1096, -1.2007, -1.8546,  3.5490],\n",
            "        [-1.8536,  1.5114, -0.4216, -0.3242,  1.2230,  0.0166, -1.0383,  0.4111],\n",
            "        [-2.7037,  0.4651, -1.3229, -0.5964,  2.7758, -0.3902, -1.2323,  1.9830],\n",
            "        [-1.4057,  0.1782,  2.1949, -1.4761, -0.5977,  2.1678, -0.4632, -0.1120],\n",
            "        [-0.6294, -0.4970,  0.8167, -0.5174,  1.1851,  0.6139, -0.5476, -0.2252],\n",
            "        [-1.1820,  0.4791, -0.0750, -1.2591,  1.4971,  0.6513, -0.9654,  0.5066],\n",
            "        [-2.5917,  1.4955, -1.8268, -1.7657,  3.3493, -0.4798, -1.3848,  1.9023],\n",
            "        [-0.2594,  0.1325,  0.5281, -1.0653,  0.6807,  1.3910, -0.8330, -0.1773],\n",
            "        [ 0.8552, -0.7632,  1.3416, -1.2852, -0.0576,  1.3836, -0.9941, -0.3660],\n",
            "        [-3.0860,  0.8308, -1.4955, -0.9479,  2.3363, -0.6144, -1.5159,  3.0533],\n",
            "        [-0.3828,  1.1822, -0.3189, -0.5160,  0.6037,  0.6678, -0.9048, -0.2192],\n",
            "        [-1.7337, -0.6097, -1.9884, -2.1271,  6.8682, -0.6302, -0.7039, -0.5561],\n",
            "        [-2.9040,  0.1127, -0.7376, -1.7607,  3.1764, -0.0662, -1.0651,  2.0505],\n",
            "        [-1.1267, -0.5311,  1.5863, -1.2541,  0.9459,  0.9416, -1.0743,  0.2795],\n",
            "        [-2.8276,  4.9775, -1.3107, -1.5032,  0.2632, -0.6960, -0.9703, -0.1778],\n",
            "        [-1.5967,  1.4864, -0.5218, -0.2337,  1.3656, -0.0581, -1.2226,  0.3277],\n",
            "        [-1.1813, -0.0342,  0.5565, -0.2348,  0.8421,  1.1755, -0.8167, -0.1310],\n",
            "        [-2.1219,  1.9824, -0.9811, -0.2751,  1.3436, -0.3682, -1.1115,  0.9186],\n",
            "        [-2.3033,  1.0413, -1.2251, -1.0835,  2.4042, -0.5502, -1.0912,  1.5554],\n",
            "        [-2.1046,  0.1659,  5.2480, -2.4141, -0.5622,  0.7005, -1.2750,  0.0236],\n",
            "        [-2.5804,  1.6161, -2.1842, -1.7723,  3.2522, -0.9885, -1.7534,  2.4107],\n",
            "        [-2.2731,  5.4244, -2.4599,  0.8637,  0.0731, -2.8188, -1.2230,  0.2488]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2224, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1472e+00, -3.1621e-01,  4.3240e-01, -9.3494e-01,  1.2793e+00,\n",
            "          5.1372e-01, -9.5268e-01,  8.2786e-01],\n",
            "        [-2.3030e+00,  1.4302e+00, -1.8672e+00, -1.8009e+00,  3.1484e+00,\n",
            "         -5.3804e-01, -1.3911e+00,  1.5378e+00],\n",
            "        [-2.0784e+00, -3.1741e-01, -3.3546e-01, -1.2074e+00, -3.1377e-02,\n",
            "          6.6571e+00, -1.1337e+00, -7.6037e-01],\n",
            "        [-1.4184e+00, -2.6318e-01,  2.3944e-01,  5.8729e-01,  1.1643e+00,\n",
            "          4.6099e-01, -8.1770e-01,  9.8934e-02],\n",
            "        [-1.1589e+00, -8.5065e-01,  7.5822e-01, -6.6442e-02,  8.3873e-01,\n",
            "          1.4177e+00,  2.2218e-03, -4.8653e-01],\n",
            "        [-1.7301e+00,  7.7055e-01, -4.4645e-01, -9.4089e-01,  1.5262e+00,\n",
            "          4.5380e-01, -8.8205e-01,  5.7676e-01],\n",
            "        [-3.7902e-01, -3.9312e-01,  1.0694e-01, -1.1628e+00,  1.8344e+00,\n",
            "          7.2880e-01, -9.7140e-01,  3.2038e-02],\n",
            "        [-2.2529e+00,  6.9404e-01, -5.1555e-01, -8.6142e-01,  2.3383e+00,\n",
            "         -3.6397e-01, -5.8119e-01,  7.0699e-01],\n",
            "        [-2.9730e+00,  3.7274e+00, -2.4477e+00, -2.0130e+00,  2.8263e+00,\n",
            "         -1.3559e+00, -2.0347e+00,  1.7244e+00],\n",
            "        [-2.8288e+00,  1.1692e+00, -1.9181e+00, -7.9272e-01,  2.9548e+00,\n",
            "         -7.8055e-01, -1.2721e+00,  2.2587e+00],\n",
            "        [-1.8390e+00,  9.7498e-01, -1.0287e+00, -6.3541e-01,  2.1538e+00,\n",
            "         -2.6996e-02, -7.1332e-01,  7.9877e-01],\n",
            "        [-2.5130e+00,  1.8617e+00, -2.0330e+00, -1.5166e+00,  3.2608e+00,\n",
            "         -9.5952e-01, -1.6714e+00,  1.9842e+00],\n",
            "        [-1.8150e+00,  7.2446e-01, -2.0844e-01, -3.0225e-01,  1.3340e+00,\n",
            "          1.1020e-01, -7.9717e-01,  8.7842e-01],\n",
            "        [-2.0569e+00, -1.3330e-01, -1.4425e+00,  4.8323e+00,  6.5313e-01,\n",
            "         -5.9712e-01, -8.2607e-01, -2.7133e-01],\n",
            "        [-1.9868e+00,  7.2027e-03, -2.0771e-01, -1.2728e+00, -3.2252e-02,\n",
            "          6.8275e+00, -1.1287e+00, -8.0010e-01],\n",
            "        [-3.1912e+00,  5.5700e-01, -1.8576e+00, -2.0146e+00,  3.9032e+00,\n",
            "         -7.0831e-01, -3.2826e-01,  2.5449e+00],\n",
            "        [-1.6285e+00, -6.8605e-02,  4.7561e-01,  3.3840e-01,  4.9413e-01,\n",
            "          1.1381e+00, -3.9818e-01, -2.1311e-01],\n",
            "        [-1.8702e+00,  3.0072e-01, -3.0738e-01, -9.6149e-01,  1.8947e+00,\n",
            "          4.0028e-01, -4.7310e-01,  6.7114e-01],\n",
            "        [-2.7454e+00,  6.6819e-01, -1.6322e+00, -1.3079e+00,  2.6560e+00,\n",
            "         -6.8649e-01, -2.1087e+00,  3.4765e+00],\n",
            "        [-1.5127e+00,  1.7418e+00, -4.6969e-01, -2.2364e-01,  2.9180e-01,\n",
            "          6.8835e-01, -9.4844e-01,  1.5177e-01],\n",
            "        [-1.7973e+00, -3.1225e-01, -3.4667e-01, -1.3934e+00,  2.9183e-01,\n",
            "          6.5533e+00, -7.6725e-01, -1.1004e+00],\n",
            "        [-1.1298e+00,  4.2423e-02, -4.4484e-01, -1.0042e+00,  1.9597e+00,\n",
            "          4.8510e-03, -1.0429e+00,  9.5002e-01],\n",
            "        [-2.7997e+00,  1.2500e+00, -2.1055e+00, -1.2287e+00,  2.9808e+00,\n",
            "         -1.1152e+00, -1.4677e+00,  2.4246e+00],\n",
            "        [-2.8044e+00,  1.7484e+00, -2.0375e+00, -1.8400e+00,  3.0499e+00,\n",
            "         -7.2478e-01, -1.6954e+00,  2.4422e+00],\n",
            "        [-1.8496e+00,  4.0315e-01, -7.7922e-01, -7.8487e-01,  2.2317e+00,\n",
            "         -6.9126e-02, -1.0409e+00,  9.7257e-01],\n",
            "        [-1.2542e+00, -4.2104e-01,  7.8265e-01, -9.5963e-01,  8.7033e-01,\n",
            "          1.8685e+00, -6.9597e-01,  2.4748e-04],\n",
            "        [-2.8576e+00,  8.4804e-01, -1.1567e+00, -1.5881e+00,  2.5550e+00,\n",
            "         -4.2535e-01, -8.5558e-01,  2.0911e+00],\n",
            "        [-2.5297e+00,  1.7985e+00, -7.5310e-01, -1.0141e+00,  1.3668e+00,\n",
            "         -9.2617e-02, -1.2434e+00,  1.4601e+00],\n",
            "        [-1.9500e+00,  1.3082e+00, -4.2395e-01, -1.2776e+00,  1.2788e+00,\n",
            "          4.1865e-01, -1.0774e+00,  1.0120e+00],\n",
            "        [-2.9438e+00,  1.0933e+00, -1.9237e+00, -1.6565e+00,  3.1534e+00,\n",
            "         -8.7506e-01, -1.4116e+00,  2.6843e+00],\n",
            "        [-1.2394e+00, -4.3265e-01,  9.1806e-01,  1.2879e+00,  1.1231e-01,\n",
            "          1.1213e+00, -1.9979e-01, -6.0065e-01],\n",
            "        [-8.4097e-01,  5.3610e-01, -1.7630e+00, -1.9974e+00,  2.0034e+00,\n",
            "         -9.3738e-01, -1.3453e+00,  2.7307e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5254, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.4306e+00, -1.0620e-02,  6.9017e-02, -1.0058e+00,  1.6157e+00,\n",
            "          2.8451e-01, -9.4683e-01,  9.5932e-01],\n",
            "        [-1.6096e+00,  5.2996e-01,  4.4266e-01,  1.1288e+00,  8.9412e-01,\n",
            "          2.8873e-01, -9.6538e-01, -3.8873e-01],\n",
            "        [-3.3470e-01,  3.1760e-02,  2.8747e-01, -8.5025e-01,  1.1937e+00,\n",
            "          6.3800e-01, -1.1854e+00,  1.2494e-01],\n",
            "        [-1.7264e+00, -7.6181e-04,  5.7731e+00, -1.9586e+00, -6.5421e-01,\n",
            "         -3.1218e-01, -1.0288e+00, -2.0363e-01],\n",
            "        [-2.5293e+00,  2.5808e+00, -1.8092e+00, -1.4507e+00,  2.0673e+00,\n",
            "         -8.7353e-01, -1.8625e+00,  1.8871e+00],\n",
            "        [-3.0199e+00,  1.1338e+00, -1.8640e+00, -2.5360e+00,  4.4397e+00,\n",
            "         -7.5494e-01, -7.7002e-01,  1.7976e+00],\n",
            "        [-9.1398e-01,  6.7652e-01, -5.9876e-01, -6.6957e-01,  1.2387e+00,\n",
            "          1.4288e-01, -1.1579e+00,  4.5941e-01],\n",
            "        [-1.8975e+00,  1.5134e+00,  5.2081e-02, -9.6363e-01,  4.3963e-01,\n",
            "          4.4259e-01, -7.3361e-01,  5.9615e-01],\n",
            "        [-2.3770e+00,  2.0720e+00, -1.7490e+00, -5.8234e-01,  1.7185e+00,\n",
            "         -7.7294e-01, -1.3026e+00,  1.7083e+00],\n",
            "        [-2.6178e+00,  2.5894e+00, -2.6943e+00, -9.2446e-01,  2.3990e+00,\n",
            "         -1.2853e+00, -1.4994e+00,  2.5881e+00],\n",
            "        [-8.1666e-01,  6.3195e-01, -1.8149e-02,  3.7543e-01,  7.3753e-01,\n",
            "          1.0775e-01, -7.9486e-01,  1.5726e-01],\n",
            "        [-5.4710e-01, -2.2293e-01,  4.9068e-01, -8.4357e-01,  5.7506e-01,\n",
            "          7.6598e-01, -1.1999e+00,  6.0924e-01],\n",
            "        [-2.2114e+00, -1.9810e-01, -2.2025e+00, -2.2484e+00,  6.8839e+00,\n",
            "         -7.4222e-01, -9.4127e-01,  4.9720e-02],\n",
            "        [-1.5359e-01,  4.1509e-01, -3.7446e-01, -5.7270e-01,  1.2972e+00,\n",
            "          5.5311e-01, -1.4332e+00, -9.1488e-02],\n",
            "        [-1.4781e+00,  1.5660e+00, -1.4701e+00, -1.7526e-01,  8.7583e-01,\n",
            "         -2.0715e-01, -1.3865e+00,  1.4891e+00],\n",
            "        [-1.9557e+00, -5.9989e-01, -1.8519e-02, -4.2149e-01,  2.3319e+00,\n",
            "          2.8609e-01, -4.6191e-01,  7.8593e-01],\n",
            "        [ 2.5325e-01, -7.7835e-01,  2.0762e+00, -7.9595e-01, -6.4858e-01,\n",
            "          2.5968e+00, -9.6741e-01, -1.0022e+00],\n",
            "        [-2.3953e+00,  2.0715e+00, -1.1349e+00, -1.2631e+00,  1.6372e+00,\n",
            "         -5.6929e-01, -8.7534e-01,  1.1618e+00],\n",
            "        [-1.4302e+00,  1.5892e-02,  7.3712e-01, -9.2514e-01,  1.1561e-01,\n",
            "          3.4660e+00, -5.6400e-01, -9.5086e-01],\n",
            "        [-1.6969e+00,  1.2250e+00, -1.1678e+00, -6.4828e-01,  1.3346e+00,\n",
            "         -7.1058e-02, -8.2238e-01,  9.8632e-01],\n",
            "        [-4.0063e-02,  5.6399e-01,  9.5214e-01, -9.7755e-01, -5.3798e-01,\n",
            "          1.9579e+00, -5.3131e-01, -1.0379e+00],\n",
            "        [-2.3846e+00,  1.4604e+00, -1.2896e+00, -1.3162e+00,  2.5217e+00,\n",
            "         -5.8675e-01, -1.2865e+00,  1.6305e+00],\n",
            "        [-2.0160e+00,  1.9528e+00, -1.5424e+00, -1.0462e+00,  1.6956e+00,\n",
            "         -2.0207e-01, -1.1389e+00,  1.0148e+00],\n",
            "        [-1.4672e+00,  1.6823e+00, -8.6738e-01, -1.3728e+00,  1.3731e+00,\n",
            "          3.3551e-01, -1.2902e+00,  7.6103e-01],\n",
            "        [-2.5764e+00,  4.3249e+00, -2.0521e+00, -1.4944e+00,  1.5500e+00,\n",
            "         -1.2360e+00, -2.3121e+00,  1.1325e+00],\n",
            "        [-9.9484e-01, -3.8857e-01,  6.1851e-01,  1.1064e-01,  7.3309e-01,\n",
            "          4.0590e-01, -2.8803e-01, -7.4590e-02],\n",
            "        [-2.0464e+00, -3.0508e-01, -1.3804e+00,  4.7760e+00,  3.8635e-01,\n",
            "         -5.7200e-01, -1.1003e+00, -1.7193e-01],\n",
            "        [-1.8313e+00, -6.6423e-01, -1.7935e+00, -1.9710e+00,  7.0492e+00,\n",
            "         -8.2443e-01, -7.3117e-01, -6.9035e-01],\n",
            "        [-1.6603e+00, -5.9395e-01, -1.7950e+00, -1.5378e+00,  6.5900e+00,\n",
            "         -4.3115e-01, -7.1729e-01, -7.0171e-01],\n",
            "        [-1.9252e+00,  9.1538e-02, -6.7257e-01, -1.5907e+00,  2.7040e+00,\n",
            "          1.3213e-01, -5.8229e-01,  1.3806e+00],\n",
            "        [-6.8106e-01, -4.4704e-01,  1.1852e-01,  9.4960e-01,  9.3237e-01,\n",
            "          6.9422e-01, -9.3708e-01, -2.2399e-02],\n",
            "        [-1.5062e+00,  8.5122e-01,  7.7803e-02, -8.6525e-01,  7.7120e-01,\n",
            "          4.7909e-01, -5.9420e-01,  5.4657e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 5.8196e+00, -1.4152e+00,  3.7598e-01, -1.2102e+00, -4.2543e-01,\n",
            "         -1.6039e+00, -5.0979e-01, -1.6445e+00],\n",
            "        [-9.2510e-01,  6.5504e-02, -3.7004e-02, -1.5245e-01,  1.4220e+00,\n",
            "          4.8117e-01, -1.0406e+00,  2.5786e-01],\n",
            "        [-1.1207e+00,  6.8699e-01, -1.9088e-01, -9.4103e-02,  8.6582e-01,\n",
            "          5.9595e-01, -1.1838e+00,  2.1076e-01],\n",
            "        [-1.9518e+00,  2.4242e+00, -1.4094e+00, -2.5160e-01,  1.1842e+00,\n",
            "         -4.7602e-01, -1.6321e+00,  8.2730e-01],\n",
            "        [-2.6279e+00,  3.8312e+00, -1.9330e+00, -1.2012e+00,  1.2655e+00,\n",
            "         -8.1206e-01, -1.9760e+00,  1.8967e+00],\n",
            "        [-1.8871e+00, -4.3523e-01, -2.0756e-01, -6.9651e-01, -1.2364e-01,\n",
            "          6.6774e+00, -8.5031e-01, -8.5936e-01],\n",
            "        [-1.2854e+00,  1.1883e+00, -5.8905e-01, -1.9698e-01,  1.3541e+00,\n",
            "         -1.8068e-03, -1.1819e+00,  3.7697e-01],\n",
            "        [-2.7541e+00,  3.6675e+00, -1.8345e+00, -1.5340e+00,  1.5739e+00,\n",
            "         -9.5072e-01, -1.9994e+00,  1.5732e+00],\n",
            "        [-2.1757e+00,  8.1102e-01, -1.0877e-01, -2.0109e-01,  7.4244e-01,\n",
            "          1.2283e-01, -1.3932e+00,  1.5607e+00],\n",
            "        [-1.6065e+00,  8.7383e-01, -1.1579e+00, -5.2884e-01,  1.8696e+00,\n",
            "         -5.5648e-01, -1.2564e+00,  1.5008e+00],\n",
            "        [-1.8321e+00,  1.0194e-02, -3.8701e-01,  4.3695e-02,  1.8158e+00,\n",
            "          3.9698e-01, -8.5308e-01,  7.7694e-01],\n",
            "        [-1.7025e+00, -1.1380e+00, -1.5057e+00, -1.8599e+00,  6.8812e+00,\n",
            "         -4.8439e-01, -7.4276e-01, -6.1434e-01],\n",
            "        [-2.1765e+00,  4.7815e-01, -4.8523e-01, -1.2830e+00,  2.1238e+00,\n",
            "         -6.1969e-02,  3.4702e-01,  4.8677e-01],\n",
            "        [-2.2935e+00,  1.5345e+00, -1.4766e+00, -4.7365e-01,  2.1915e+00,\n",
            "         -5.5348e-01, -1.4494e+00,  1.2121e+00],\n",
            "        [-1.9866e+00,  5.5530e-01, -2.2131e-01, -7.0930e-01,  1.5210e+00,\n",
            "          2.6202e-01, -7.2161e-01,  9.2511e-01],\n",
            "        [-2.5606e+00,  1.0658e+00, -1.9530e+00, -1.7365e+00,  3.5599e+00,\n",
            "         -9.7388e-01, -1.3486e+00,  2.2334e+00],\n",
            "        [-2.0793e+00,  2.1016e-01, -6.0264e-01,  4.4395e-01,  1.4778e+00,\n",
            "          1.9573e-01, -8.7041e-01,  6.9383e-01],\n",
            "        [-1.9360e+00,  1.5641e+00, -1.1896e+00, -8.7503e-01,  2.0783e+00,\n",
            "         -2.4838e-01, -1.5175e+00,  1.0999e+00],\n",
            "        [-1.8763e+00,  3.7375e-01, -9.8952e-01, -9.3591e-01,  2.4417e+00,\n",
            "         -1.3751e-01, -1.3567e+00,  1.7232e+00],\n",
            "        [-2.2746e+00,  8.1815e-01, -5.2226e-01, -6.5686e-01,  1.5662e+00,\n",
            "          2.3129e-01, -1.1559e+00,  1.3061e+00],\n",
            "        [-1.3690e+00,  1.5782e-01,  2.0476e-01,  4.6565e-01,  7.7252e-01,\n",
            "          4.4202e-01, -5.0150e-01, -1.5831e-01],\n",
            "        [-1.6443e+00, -4.0798e-01,  5.9742e+00, -2.0644e+00, -5.7801e-01,\n",
            "          3.0336e-01, -1.1081e+00, -7.0027e-01],\n",
            "        [-9.6144e-01,  7.0226e-01, -3.4330e-01, -5.9466e-01,  1.4382e+00,\n",
            "          3.9939e-01, -1.2296e+00,  3.4415e-01],\n",
            "        [-2.7908e+00,  1.1317e+00, -1.5260e+00, -3.0026e-01,  1.4530e+00,\n",
            "         -8.3818e-01, -1.9131e+00,  2.7925e+00],\n",
            "        [-9.4094e-01, -2.3853e-01,  1.4317e+00, -2.1364e-01, -1.8082e-01,\n",
            "          2.0934e+00, -7.7969e-01, -6.6265e-01],\n",
            "        [-1.2193e+00,  6.8482e-01, -1.1446e+00, -1.0490e+00,  1.7243e+00,\n",
            "         -2.9281e-01, -9.5010e-01,  1.3831e+00],\n",
            "        [-5.4797e-01,  1.7735e-01,  1.4051e-01, -5.0534e-01,  1.2745e+00,\n",
            "          4.8082e-01, -8.2896e-01,  1.0241e-01],\n",
            "        [-1.5756e+00,  4.2584e-01,  7.2549e-01, -9.2447e-01,  3.7810e-01,\n",
            "          1.5237e+00, -6.2783e-01,  1.6104e-01],\n",
            "        [-2.3968e+00,  7.6429e-01, -1.1795e+00,  3.8950e-01,  2.1149e+00,\n",
            "         -6.4524e-01, -1.2746e+00,  1.3878e+00],\n",
            "        [-1.7245e+00,  6.4642e-01, -6.5693e-01, -1.0717e+00,  2.0665e+00,\n",
            "         -2.0430e-01, -1.2727e+00,  1.3665e+00],\n",
            "        [-1.7843e+00, -5.0786e-01, -1.7017e+00, -2.2189e+00,  6.4749e+00,\n",
            "         -3.5009e-01, -5.1635e-01, -2.0733e-01],\n",
            "        [-2.6773e+00,  7.9937e-01, -1.6056e+00, -1.9267e+00,  3.2533e+00,\n",
            "         -6.9257e-01, -9.1254e-01,  2.6370e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1399, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2521,  4.9533, -2.4280, -1.9455,  2.7433, -1.5391, -1.8699,  0.1887],\n",
            "        [-1.5046,  0.1391,  1.2697,  0.1196, -0.3440,  1.9899, -0.1153, -0.8295],\n",
            "        [-2.5896,  0.7451, -1.6648, -1.0436,  1.0733, -0.2888, -2.0127,  4.5945],\n",
            "        [-1.3129,  0.2652,  0.2856,  0.0561,  0.7526,  1.1854, -0.6781, -0.1554],\n",
            "        [-1.3393,  0.5835, -1.1337, -1.3752,  2.0628, -0.0763, -1.1631,  1.2390],\n",
            "        [-0.2111,  0.0560,  0.9872, -1.2087,  0.6295,  0.5502, -1.0220,  0.2379],\n",
            "        [-2.0248,  0.4104, -0.9036,  0.5520,  1.8581, -0.1715, -1.1946,  0.9726],\n",
            "        [ 0.0942, -0.6524,  1.3442, -1.0581,  0.4324,  1.3051, -0.2431, -0.6579],\n",
            "        [-1.2704, -1.1435, -0.9212, -1.6877,  6.7726, -0.1130, -0.9005, -1.1394],\n",
            "        [-1.9358,  1.2527, -1.2054, -0.2434,  1.7003, -0.4375, -1.1932,  1.1914],\n",
            "        [-1.7687, -0.8601, -0.9453, -2.1799,  6.3689, -0.2395, -0.5788, -0.8848],\n",
            "        [-2.0677,  0.1820, -0.5427, -1.3127,  2.5429,  0.5142, -0.9284,  0.8949],\n",
            "        [-1.6530, -0.4022, -0.3210, -0.7624, -0.5032,  6.8359, -0.6100, -1.0847],\n",
            "        [-1.5156,  0.5969, -0.5509, -0.2960,  1.7978,  0.2800, -1.0012,  0.4617],\n",
            "        [-1.2728,  1.1831, -0.1436, -0.7442,  0.6410,  1.2699, -1.3482,  0.2030],\n",
            "        [-0.9531,  1.2207, -0.1065, -0.1194,  0.4696,  0.7700, -1.2134,  0.0259],\n",
            "        [-0.0701, -0.2520,  0.3738, -0.6908,  0.8907,  1.3256, -1.1122, -0.1295],\n",
            "        [-1.6534,  0.0450,  0.4555, -0.2363,  1.0254,  1.2610, -0.5439, -0.0238],\n",
            "        [-1.7956,  0.1203,  0.1247,  0.0159,  1.0236,  1.2088, -0.8956,  0.2911],\n",
            "        [-1.4546,  0.4383, -0.0132, -0.0727,  1.3247,  0.4711, -0.9861,  0.3183],\n",
            "        [-0.6368,  0.8843, -0.2011,  0.2862,  0.6164,  0.1496, -0.9134, -0.1233],\n",
            "        [-2.2201,  6.5342, -1.7231, -1.7513, -0.0997, -1.6581, -1.0508,  0.0638],\n",
            "        [-0.6782, -0.0476,  1.8002, -0.3065, -0.5959,  1.9115, -0.1288, -1.0014],\n",
            "        [-2.3069,  0.7185, -1.4698, -1.5474,  2.5179, -0.8346, -1.5488,  2.6882],\n",
            "        [-2.5493,  5.4067, -1.5241, -0.8243,  0.3171, -2.0489, -0.2257, -0.3366],\n",
            "        [ 0.3298,  0.4206,  0.4599,  0.0577, -0.1223,  0.4366, -0.8360, -0.8086],\n",
            "        [-2.1104, -0.0768, -0.4289,  1.0284,  1.5220, -0.0282, -0.2168,  0.4573],\n",
            "        [-2.6134,  1.1772, -1.6640,  1.0530,  1.7629, -0.8245, -1.2521,  1.8311],\n",
            "        [-1.9693,  2.3183, -1.1386,  0.0325,  0.6654, -0.2884, -1.8091,  0.9266],\n",
            "        [-0.4924, -0.4065, -0.1185,  0.1348,  1.0099,  1.8020, -1.2697, -0.3664],\n",
            "        [-1.6279, -0.1086,  2.3832, -0.9329, -1.3919,  3.3984,  0.0419, -1.1562],\n",
            "        [-1.2333,  0.1247, -0.1127,  0.3866,  1.2368,  0.6733, -0.8515, -0.0400]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4273, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6652,  1.0758, -1.1995, -1.0270,  2.1746, -0.3287, -1.3226,  1.2703],\n",
            "        [-0.6882,  0.6359,  1.6528, -1.1082, -0.4438,  1.8032, -0.8694, -0.7178],\n",
            "        [-1.5317, -0.3742, -0.3851, -0.7958, -0.0448,  6.7795, -0.9514, -0.9191],\n",
            "        [-1.8158,  0.5726, -1.0586,  0.5997,  1.8416, -0.3667, -0.8040,  0.6366],\n",
            "        [-1.8524,  3.9524, -1.0659, -1.4779,  0.5725, -0.4528, -1.7798,  0.5044],\n",
            "        [-1.9098,  0.8570, -0.4959, -0.7565,  1.2916,  0.3237, -1.3223,  1.4193],\n",
            "        [-1.3129, -0.2864,  0.7422, -0.8276,  1.0175,  1.0235, -0.6359,  0.0872],\n",
            "        [-1.7184, -0.5097,  0.0255, -0.5750,  1.8093,  0.6504, -0.4773,  0.3011],\n",
            "        [-1.9420,  1.8505, -1.0776,  0.3236,  0.6113, -0.2410, -1.3736,  0.6565],\n",
            "        [-2.0217,  1.0851, -0.8998, -0.5291,  1.8040, -0.2327, -0.7987,  0.9520],\n",
            "        [-0.6926,  1.3924,  0.1872, -0.9926,  0.4074,  0.4608, -0.9547, -0.0079],\n",
            "        [-1.5810,  1.2929, -0.7933, -0.7754,  1.5443, -0.2172, -0.9800,  0.8167],\n",
            "        [-1.9200,  0.3067, -1.6059,  4.8500,  0.4527, -1.0462, -1.5297, -0.1435],\n",
            "        [-2.2987,  3.9392, -1.8727, -1.0086,  1.3243, -1.3089, -2.2416,  1.1657],\n",
            "        [-1.9058,  5.0536, -0.7787, -1.9434, -0.7628, -1.3513, -1.6092,  1.4983],\n",
            "        [-0.9774,  0.6980,  0.4613, -1.1222,  0.3919,  1.0017, -0.5528,  0.3862],\n",
            "        [-2.2938,  4.1460, -1.7569, -1.2416,  1.1776, -0.6487, -2.1389,  0.4631],\n",
            "        [-0.3828,  0.0203,  0.5068,  0.0890,  0.3486,  0.7445, -0.5128, -0.3947],\n",
            "        [-1.5964,  0.2850,  0.1302, -0.9455,  1.0120,  1.3430, -1.1121,  0.7841],\n",
            "        [-0.3038, -0.2309,  0.8774, -0.0688,  0.4188,  0.8390, -0.5570, -0.4539],\n",
            "        [-1.7967,  0.2640, -0.4004,  0.2721,  1.6330,  0.2592, -0.9284,  0.6700],\n",
            "        [-0.9722, -0.2718,  2.9450, -0.9277, -1.3870,  2.0505, -0.1689, -0.4653],\n",
            "        [-2.8863,  1.8972, -1.9697, -1.0920,  2.6557, -1.4183, -1.2940,  2.1447],\n",
            "        [-2.3776,  0.8068, -1.7112, -1.3024,  2.8805, -0.4076, -1.2349,  2.0858],\n",
            "        [-0.7011,  0.3658,  0.1629, -0.8044,  0.8297,  0.9977, -1.2033,  0.1010],\n",
            "        [-1.5479,  0.2716,  0.2732, -0.2629,  1.2030,  0.7757, -0.5902,  0.2178],\n",
            "        [-0.8189, -0.0208, -0.1830,  0.1495,  1.1627,  0.2113, -1.0006,  0.1386],\n",
            "        [-2.6310,  2.6297, -2.2566, -1.5495,  2.5103, -1.0390, -2.0729,  2.4371],\n",
            "        [-2.4203,  0.6983, -0.5628, -1.8286,  2.6945, -0.0382, -0.2312,  0.9661],\n",
            "        [-2.4085,  1.4676, -2.1156, -2.0755,  3.8188, -0.4792, -1.4366,  1.1453],\n",
            "        [-2.2550,  3.7409, -1.7378, -0.7149,  0.8950, -1.0528, -2.3430,  1.7940],\n",
            "        [-2.4646,  2.3132, -1.3628,  0.0825,  1.2407, -0.6415, -1.5955,  1.4714]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0607, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8465e-01,  1.4752e-02,  3.6600e-01, -8.5090e-02,  7.8668e-01,\n",
            "          3.6115e-01, -8.8824e-01, -8.2095e-02],\n",
            "        [-2.8310e+00,  5.8534e+00, -1.8111e+00, -9.4901e-01,  7.9928e-01,\n",
            "         -2.0612e+00, -1.3056e+00, -2.9478e-02],\n",
            "        [-1.9354e+00,  5.2973e+00, -1.1273e+00, -1.9625e+00, -3.4882e-01,\n",
            "         -1.2871e+00, -2.2942e+00,  8.7215e-01],\n",
            "        [-2.8917e-01, -1.4414e-01,  8.9272e-02,  4.0418e-01,  8.3831e-01,\n",
            "          5.1507e-01, -7.8182e-01, -4.7191e-01],\n",
            "        [-1.7841e+00,  2.0698e+00, -9.7674e-01,  1.3947e-02,  1.0778e+00,\n",
            "         -3.7745e-01, -1.5399e+00,  6.3999e-01],\n",
            "        [-1.6138e+00,  1.2519e-01, -6.2298e-01,  1.6390e-01,  1.7430e+00,\n",
            "         -5.1818e-02, -7.8410e-01,  5.4344e-01],\n",
            "        [-5.0943e-01, -3.3256e-01, -1.0517e-01,  1.4850e+00,  7.6296e-01,\n",
            "          3.2289e-01, -6.8677e-01, -5.5582e-01],\n",
            "        [-1.8776e+00, -1.7759e-01, -2.8937e-01, -1.2083e+00, -2.7488e-01,\n",
            "          6.5446e+00, -8.8433e-01, -4.6920e-01],\n",
            "        [-1.7519e+00,  5.2122e-01, -1.3306e+00, -1.4575e+00,  2.9998e+00,\n",
            "         -5.4673e-01, -9.7034e-01,  1.3888e+00],\n",
            "        [-2.3712e+00,  6.1999e+00, -1.8062e+00, -1.8257e+00,  5.8770e-01,\n",
            "         -1.3774e+00, -2.0896e+00,  1.3620e-01],\n",
            "        [-1.2753e+00,  1.3495e+00, -1.5520e-01, -2.1811e-01,  1.9916e-01,\n",
            "          4.7118e-01, -8.1004e-01,  3.2123e-01],\n",
            "        [-2.3152e+00, -3.9781e-01, -1.3952e+00,  5.0309e+00,  8.3895e-01,\n",
            "         -7.0884e-01, -9.1722e-01, -5.9030e-01],\n",
            "        [-2.4404e+00,  4.7521e+00, -1.5396e+00, -1.3514e+00,  8.6626e-01,\n",
            "         -1.0569e+00, -1.4560e+00, -1.7598e-01],\n",
            "        [-1.4244e+00,  1.2390e+00, -3.1633e-01, -7.1862e-02,  8.6466e-01,\n",
            "         -1.4135e-01, -8.2707e-01,  4.4136e-01],\n",
            "        [-6.7147e-01, -1.1689e-02,  9.2897e-02, -5.6299e-01,  1.6829e+00,\n",
            "          3.5861e-01, -1.0789e+00,  3.5607e-01],\n",
            "        [-2.8387e+00,  5.4747e+00, -2.0913e+00, -2.2396e+00,  1.2662e+00,\n",
            "         -1.5615e+00, -1.9509e+00,  4.3336e-01],\n",
            "        [-2.1467e+00,  2.2011e-01, -1.1797e+00, -1.1902e+00,  2.6363e+00,\n",
            "         -5.3366e-01, -1.1954e+00,  2.1667e+00],\n",
            "        [-2.6147e+00,  3.0180e+00, -2.4425e+00, -1.9779e+00,  2.5845e+00,\n",
            "         -1.1938e+00, -2.0866e+00,  2.1336e+00],\n",
            "        [-3.8897e-01, -6.3625e-01,  8.2398e-01, -7.8423e-01,  8.2632e-01,\n",
            "          1.5511e+00, -8.7047e-01, -1.6882e-01],\n",
            "        [-8.2016e-01,  1.3452e-01,  8.9368e-01, -7.1721e-01,  4.6485e-02,\n",
            "          1.2128e+00, -2.9626e-01,  5.7879e-02],\n",
            "        [-7.7300e-01, -3.5312e-01,  1.9336e+00, -1.2591e+00, -1.1970e-01,\n",
            "          1.4700e+00, -4.7432e-03, -6.3353e-01],\n",
            "        [-6.0742e-01,  1.8418e-01,  1.1253e+00, -3.1951e-01, -2.4572e-01,\n",
            "          1.4364e+00, -3.6957e-01, -4.9440e-01],\n",
            "        [-2.7252e+00,  4.3541e-01, -1.2455e+00, -7.9615e-01,  2.9941e+00,\n",
            "         -1.4088e-01, -5.1772e-01,  1.1871e+00],\n",
            "        [-1.9634e+00,  2.8398e+00, -1.6560e+00, -9.3050e-01,  1.5680e+00,\n",
            "         -6.2233e-01, -1.7313e+00,  1.2578e+00],\n",
            "        [-1.5413e+00,  1.3487e+00, -6.7553e-01,  1.8533e-01,  1.2308e+00,\n",
            "         -7.8141e-02, -1.2694e+00,  5.0276e-01],\n",
            "        [-1.6252e+00,  1.3872e+00, -5.2222e-01,  4.3280e-01,  8.1073e-01,\n",
            "          6.5869e-02, -1.2669e+00,  3.1207e-01],\n",
            "        [-1.3614e+00,  1.4810e-01, -1.0645e+00, -9.2305e-01,  2.4504e+00,\n",
            "         -6.9954e-02, -1.3248e+00,  1.0238e+00],\n",
            "        [-1.8782e+00,  2.2353e+00, -1.4316e+00, -8.8211e-01,  1.3457e+00,\n",
            "         -5.5062e-01, -1.8271e+00,  1.8302e+00],\n",
            "        [-5.8636e-01, -1.1269e+00,  3.0348e-01,  1.6568e+00, -6.6462e-01,\n",
            "          2.8826e+00,  4.5700e-02, -1.5815e+00],\n",
            "        [-1.2072e+00, -1.3586e+00, -4.1562e-01, -1.8413e+00,  6.4847e+00,\n",
            "         -3.0071e-01, -8.0780e-01, -1.1121e+00],\n",
            "        [-1.3505e+00,  8.7773e-01, -5.3491e-01, -7.6259e-01,  1.6069e+00,\n",
            "          1.4094e-01, -6.7169e-01,  1.0749e-01],\n",
            "        [-2.6806e+00,  1.8624e+00, -2.2199e+00, -1.2792e+00,  2.9249e+00,\n",
            "         -1.1785e+00, -1.6717e+00,  2.4013e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9496, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.7033e+00,  3.5682e+00, -2.1861e+00, -1.7245e+00,  2.1556e+00,\n",
            "         -1.0167e+00, -2.0953e+00,  1.5317e+00],\n",
            "        [-1.7952e+00, -8.4658e-01, -1.4175e+00, -2.3775e+00,  6.1066e+00,\n",
            "         -2.6197e-01, -2.8956e-01, -6.7396e-03],\n",
            "        [-2.4714e+00,  5.8163e-01, -1.6244e+00, -8.9576e-01,  2.6198e+00,\n",
            "         -5.9759e-01, -1.4972e+00,  2.7272e+00],\n",
            "        [-1.7827e+00,  1.4733e+00, -1.1611e+00, -1.3695e+00,  1.8420e+00,\n",
            "          9.0964e-01, -1.2643e+00,  5.1097e-01],\n",
            "        [-1.3563e+00,  7.4501e-02, -5.7176e-01,  1.5617e-01,  1.7156e+00,\n",
            "         -3.8366e-02, -9.8670e-01,  8.7480e-01],\n",
            "        [-2.6655e+00,  3.0215e+00, -2.0844e+00, -1.6337e+00,  1.4769e+00,\n",
            "         -6.5905e-01, -2.4128e+00,  2.5247e+00],\n",
            "        [-1.8832e-01, -5.2375e-01,  5.4173e-01, -7.1424e-02,  8.1354e-01,\n",
            "          1.1287e+00, -8.7173e-01, -3.7244e-01],\n",
            "        [-1.3606e+00, -2.1074e-01,  5.5027e-01,  1.8331e-01,  1.1586e+00,\n",
            "          1.4490e-01, -3.9049e-01, -3.0873e-02],\n",
            "        [-1.7556e+00,  6.3939e-01, -9.8285e-02, -6.2147e-01,  1.1793e+00,\n",
            "         -1.2043e-02, -8.7724e-01,  7.6187e-01],\n",
            "        [-3.0073e-02,  3.5013e-02,  3.6685e-01, -3.3596e-01,  5.8236e-01,\n",
            "          1.0424e+00, -9.9629e-01, -5.5515e-01],\n",
            "        [ 4.2817e-01, -8.2438e-01,  1.8360e+00, -4.5612e-01, -6.6152e-01,\n",
            "          2.4022e+00, -1.1021e+00, -1.1272e+00],\n",
            "        [-1.4871e-01, -9.2711e-01,  5.6049e+00, -1.5037e+00, -4.2589e-01,\n",
            "         -6.0262e-01, -6.7568e-01, -1.0574e+00],\n",
            "        [-2.0287e+00,  7.1787e-01, -1.1076e+00, -3.1342e-01,  1.3254e+00,\n",
            "         -4.9604e-01, -1.7876e+00,  2.8309e+00],\n",
            "        [-2.0068e+00,  5.0585e+00, -9.7161e-01, -2.0197e+00, -8.1838e-01,\n",
            "         -1.4388e+00, -1.9000e+00,  1.7877e+00],\n",
            "        [-1.2529e+00,  8.6218e-01, -6.9919e-01, -1.0479e+00,  1.6714e+00,\n",
            "         -9.5106e-02, -1.4234e+00,  1.3653e+00],\n",
            "        [-1.1173e+00, -1.1287e-01,  1.2605e+00,  2.0201e-01, -6.1351e-02,\n",
            "          1.5932e+00, -5.9024e-01, -4.2130e-01],\n",
            "        [-1.8540e+00, -1.9725e-01, -2.6679e-01, -9.3988e-01, -4.0474e-01,\n",
            "          6.3983e+00, -1.0246e+00, -5.4550e-01],\n",
            "        [-1.5455e+00,  1.4449e+00, -9.7757e-01, -2.3351e-01,  8.3078e-01,\n",
            "         -4.3959e-01, -2.1794e+00,  1.8310e+00],\n",
            "        [-2.3659e+00,  5.2149e-01, -5.5538e-01, -7.0015e-01,  1.3591e+00,\n",
            "          1.1354e-01, -7.7486e-01,  1.7491e+00],\n",
            "        [-2.8668e+00,  2.5143e+00, -2.7321e+00, -1.4734e+00,  2.9794e+00,\n",
            "         -1.2148e+00, -1.8083e+00,  2.2481e+00],\n",
            "        [-2.2380e+00,  1.3418e+00, -1.9414e+00, -2.2118e+00,  3.7742e+00,\n",
            "         -2.2549e-01, -1.1676e+00,  5.8240e-01],\n",
            "        [-1.3689e+00, -1.0451e+00, -4.4252e-01, -2.0855e+00,  5.9203e+00,\n",
            "          6.6137e-03, -5.4214e-01, -7.8414e-01],\n",
            "        [-2.7561e+00,  3.2369e-01, -2.0249e+00, -1.1412e+00,  2.1441e+00,\n",
            "         -1.6842e+00, -2.2627e+00,  5.4971e+00],\n",
            "        [ 6.9045e-01, -8.8894e-01,  2.1224e+00, -9.6019e-01,  3.6599e-02,\n",
            "          1.2842e+00, -1.1916e+00, -7.0384e-01],\n",
            "        [-2.2276e+00,  7.1960e-01, -1.7830e+00, -1.5443e+00,  2.6038e+00,\n",
            "         -9.9321e-01, -1.9218e+00,  3.3528e+00],\n",
            "        [-2.8311e+00,  2.6007e+00, -1.8850e+00, -1.7291e+00,  1.1940e+00,\n",
            "         -1.1579e+00, -2.2559e+00,  4.0047e+00],\n",
            "        [-2.0419e+00,  2.8269e-02, -4.2919e-01, -1.5491e+00,  2.6584e+00,\n",
            "          4.0340e-01, -2.7738e-01,  3.2344e-01],\n",
            "        [-2.2378e+00,  5.0219e-02, -9.9432e-01, -1.6261e+00,  2.6703e+00,\n",
            "         -2.5613e-01, -8.0626e-01,  2.2675e+00],\n",
            "        [-2.5285e+00,  6.8997e+00, -2.2004e+00, -1.7222e+00,  4.5210e-01,\n",
            "         -1.5393e+00, -2.1337e+00,  5.9128e-01],\n",
            "        [-1.7613e+00,  1.3546e+00, -1.2481e+00, -9.3733e-01,  2.3734e+00,\n",
            "         -4.4210e-01, -1.2356e+00,  1.0561e+00],\n",
            "        [-1.7799e+00,  5.3985e-01, -9.3252e-01,  5.3763e-01,  1.7263e+00,\n",
            "         -6.5119e-02, -7.3639e-01,  4.4269e-01],\n",
            "        [-1.1564e+00, -7.3229e-01,  2.0217e+00, -9.6986e-01, -2.9658e-01,\n",
            "          2.2508e+00, -5.1798e-01, -1.5447e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2957, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.1769e-01,  1.2432e-01,  4.8334e-02, -1.8766e-01,  1.1878e+00,\n",
            "          5.7334e-01, -9.0227e-01, -2.1135e-01],\n",
            "        [-1.2229e+00, -8.1861e-01, -3.6955e-01, -1.9170e+00,  4.8832e+00,\n",
            "          2.7399e-01, -1.8192e-01, -8.2876e-01],\n",
            "        [-8.1055e-01,  2.7969e-01,  1.0414e-01, -1.3799e+00,  1.4235e+00,\n",
            "          7.2166e-02, -1.2781e+00,  1.0913e+00],\n",
            "        [-2.0200e+00, -4.6521e-01, -5.2352e-01,  3.4433e+00,  8.0734e-01,\n",
            "         -1.3506e-01, -9.7905e-02, -1.9516e-01],\n",
            "        [-3.6993e-01, -7.5518e-02,  3.1237e-01, -8.3475e-01,  1.4398e+00,\n",
            "          6.4071e-01, -9.7634e-01,  1.2837e-02],\n",
            "        [-3.0214e+00, -1.2601e-01, -1.5572e+00,  5.6389e+00,  5.2066e-01,\n",
            "         -9.4637e-01, -5.0176e-01, -9.2103e-02],\n",
            "        [-2.1355e+00,  3.3454e-01, -1.7283e+00, -2.2423e+00,  4.7748e+00,\n",
            "         -5.5282e-01, -5.8979e-01,  5.9489e-01],\n",
            "        [-1.9191e+00,  4.8088e+00, -1.5259e+00, -1.4347e+00,  5.4082e-01,\n",
            "         -1.0681e+00, -1.4515e+00, -1.6648e-01],\n",
            "        [-6.9643e-01,  4.1057e-01, -4.0392e-01, -5.8909e-01,  1.2348e+00,\n",
            "          2.2022e-01, -1.2704e+00,  6.2368e-01],\n",
            "        [-2.1610e+00,  1.3316e+00, -1.1532e+00, -1.0514e+00,  2.2553e+00,\n",
            "         -5.5151e-01, -7.8172e-01,  1.2968e+00],\n",
            "        [-1.4864e+00,  1.1609e-01, -8.0425e-02, -8.4140e-02,  1.3494e+00,\n",
            "          3.6521e-01, -5.2541e-01,  3.1241e-01],\n",
            "        [-2.2413e+00,  6.0509e-01, -8.3871e-01, -1.1749e+00,  2.1678e+00,\n",
            "         -3.4974e-01, -9.4709e-01,  1.6519e+00],\n",
            "        [-1.5990e+00, -2.2400e-03,  2.3625e+00, -6.0048e-01, -1.1632e+00,\n",
            "          2.8928e+00,  1.6653e-01, -1.1825e+00],\n",
            "        [-4.0977e-01,  4.7277e-02, -2.7672e-01, -3.3865e-01,  1.7046e+00,\n",
            "          5.8751e-01, -6.2772e-01, -3.8383e-01],\n",
            "        [-2.0709e+00,  2.3874e+00, -1.4999e+00, -2.9495e-01,  1.2201e+00,\n",
            "         -9.2815e-01, -1.4824e+00,  1.3646e+00],\n",
            "        [-2.0205e+00,  1.3351e+00, -1.9141e+00, -1.4104e+00,  2.6879e+00,\n",
            "         -1.0436e+00, -1.8875e+00,  2.4020e+00],\n",
            "        [-1.9163e+00, -6.7487e-01,  5.5630e+00, -1.6157e+00, -6.6538e-01,\n",
            "         -4.5908e-02, -1.0245e+00,  2.0577e-02],\n",
            "        [-1.0588e+00,  1.0692e+00,  3.2138e-01, -9.8308e-01,  1.1145e-01,\n",
            "          5.6906e-01, -7.8198e-01,  4.7589e-01],\n",
            "        [-2.7725e-01, -2.0090e-01,  6.7076e-02, -9.2019e-01,  1.3793e+00,\n",
            "          8.9065e-01, -8.6987e-01, -1.4265e-01],\n",
            "        [-2.8030e-01,  1.3922e-01,  2.6009e-01, -8.7819e-01,  1.3359e+00,\n",
            "          4.5846e-01, -9.7639e-01, -7.7719e-02],\n",
            "        [-1.8178e+00,  2.6442e+00, -9.7868e-01, -1.0443e+00,  1.4737e+00,\n",
            "         -6.3132e-01, -9.8679e-01,  7.3011e-01],\n",
            "        [-1.0583e+00,  7.7523e-01, -4.4091e-02,  1.1192e-01,  5.8060e-01,\n",
            "          3.3746e-01, -8.3018e-01, -8.1180e-03],\n",
            "        [-4.5300e-01, -6.3829e-02,  2.1207e-01, -5.3283e-01,  1.2525e+00,\n",
            "          4.0290e-01, -1.0396e+00,  3.3378e-01],\n",
            "        [-9.1617e-01,  1.1851e-01, -1.0330e+00, -1.1367e+00,  2.4344e+00,\n",
            "         -9.3579e-02, -7.3954e-01,  5.8405e-01],\n",
            "        [-9.5757e-01,  5.9193e-01, -2.0084e-01, -8.4136e-01,  7.3338e-01,\n",
            "          5.8582e-01, -1.2096e+00,  6.2508e-01],\n",
            "        [-1.6636e+00,  1.4008e+00, -2.0996e+00, -1.8881e+00,  2.9606e+00,\n",
            "         -5.7840e-01, -1.5110e+00,  1.9773e+00],\n",
            "        [-1.8894e+00,  5.6243e-01, -8.2057e-01, -1.2054e+00,  2.5957e+00,\n",
            "         -3.3847e-01, -1.0297e+00,  1.3872e+00],\n",
            "        [-1.5934e+00,  7.0222e-01, -4.3228e-01, -8.3907e-01,  2.0432e+00,\n",
            "          5.9642e-02, -1.1328e+00,  4.3801e-01],\n",
            "        [-1.3875e+00,  1.7024e-01,  2.1631e-01, -1.5054e-01,  1.1635e+00,\n",
            "          6.3915e-01, -6.0725e-01,  8.6327e-02],\n",
            "        [-8.4717e-01,  2.8531e-01,  3.4099e-02,  4.6315e-01,  8.9652e-01,\n",
            "          6.9191e-01, -6.7833e-01, -3.5963e-01],\n",
            "        [-5.6600e-01,  3.4233e-01,  2.9539e-01, -5.8754e-01,  7.4090e-01,\n",
            "          1.0305e+00, -1.0140e+00,  1.8522e-01],\n",
            "        [-9.1395e-01, -3.3485e-01, -1.7129e-01,  2.0321e+00,  4.7905e-01,\n",
            "          3.8680e-01, -3.9647e-01, -4.9860e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3716e+00,  1.1516e-01,  4.8425e-01, -1.6417e-01,  7.3914e-01,\n",
            "          1.3450e+00, -7.4936e-01, -5.8435e-06],\n",
            "        [-5.1809e-01,  4.9866e-02, -3.8327e-01, -9.2226e-01,  1.9276e+00,\n",
            "          3.6515e-01, -8.0144e-01,  1.8428e-01],\n",
            "        [ 2.4171e-01, -5.4387e-01,  9.0982e-01, -7.0687e-01,  6.1330e-01,\n",
            "          1.2198e+00, -6.9301e-01, -6.3888e-01],\n",
            "        [-1.4239e+00,  1.0342e+00, -1.1301e+00, -7.9338e-01,  2.1299e+00,\n",
            "         -3.6922e-01, -1.2468e+00,  8.7845e-01],\n",
            "        [-1.8963e+00,  3.9383e-01, -1.3400e+00, -1.2842e+00,  2.8952e+00,\n",
            "         -1.8042e-01, -1.3248e+00,  1.5363e+00],\n",
            "        [-1.0666e+00,  1.7011e+00, -4.8222e-01, -4.4598e-01,  6.4998e-01,\n",
            "         -2.6178e-01, -1.8617e+00,  1.0878e+00],\n",
            "        [-2.5557e+00,  5.3134e-01, -9.7052e-01, -4.1123e-01,  1.6881e+00,\n",
            "         -2.1834e-02, -1.1216e+00,  2.4196e+00],\n",
            "        [-4.3689e-01, -5.7592e-01,  2.1064e+00, -4.0999e-01,  1.4666e-01,\n",
            "          1.1840e+00, -5.8184e-01, -7.0605e-01],\n",
            "        [-1.1744e+00, -1.6923e-01, -4.9778e-01,  2.9618e+00,  6.1924e-01,\n",
            "         -4.0006e-01, -9.0638e-01, -1.3937e-01],\n",
            "        [-1.9668e+00,  3.2675e+00, -5.4466e-01, -3.6007e-01,  1.0983e-01,\n",
            "         -1.0012e-01, -1.7668e+00,  2.3754e-02],\n",
            "        [-1.7911e+00, -3.8485e-01,  1.7556e+00, -4.8512e-01, -6.5998e-01,\n",
            "          3.5067e+00, -5.4536e-01, -9.0173e-01],\n",
            "        [-8.9908e-01, -4.0773e-01, -2.4884e-01,  9.1744e-01,  1.4448e+00,\n",
            "          8.6664e-02, -8.2504e-01,  8.6354e-02],\n",
            "        [-1.2893e+00,  7.9961e-01, -9.8989e-01, -1.5628e-01,  1.6031e+00,\n",
            "         -2.0959e-01, -1.1107e+00,  8.0027e-01],\n",
            "        [-1.0276e+00,  6.0898e-01, -2.9719e-01, -8.6207e-01,  1.1322e+00,\n",
            "         -2.4109e-02, -8.8785e-01,  9.4467e-01],\n",
            "        [-1.3107e+00,  1.0487e+00, -5.3000e-01, -1.4199e-01,  1.3687e+00,\n",
            "          9.2742e-03, -1.1039e+00,  4.5821e-01],\n",
            "        [-1.0788e-01, -2.1998e-01,  3.3988e-01, -8.9860e-01,  1.4075e+00,\n",
            "          6.7994e-01, -1.0399e+00, -1.2667e-01],\n",
            "        [ 3.0131e-01, -7.3281e-01,  1.1951e+00, -5.1551e-01,  3.3373e-01,\n",
            "          1.5119e+00, -2.1391e-01, -1.0513e+00],\n",
            "        [-1.2603e+00,  3.2194e+00, -1.4529e+00, -8.9232e-01,  7.5238e-01,\n",
            "         -7.4372e-01, -2.3727e+00,  9.1300e-01],\n",
            "        [-2.4971e+00,  7.3640e-01, -2.2079e+00, -1.5358e+00,  2.9536e+00,\n",
            "         -1.1903e+00, -1.8752e+00,  3.6311e+00],\n",
            "        [-1.7762e-01, -2.1652e-01,  5.7635e-01, -8.3859e-01,  9.7034e-01,\n",
            "          7.9861e-01, -1.0869e+00, -7.7050e-02],\n",
            "        [-5.1720e-01, -5.4323e-01,  6.4301e-01, -4.3830e-01,  1.1051e+00,\n",
            "          1.0362e+00, -8.1328e-01, -6.4656e-02],\n",
            "        [ 1.1719e-01, -1.0396e+00,  2.8562e+00, -6.7030e-01, -5.1695e-01,\n",
            "          1.4269e+00, -9.2080e-01, -9.5244e-01],\n",
            "        [-1.3505e+00,  1.5358e-01, -4.2962e-01, -9.5473e-01,  2.1006e+00,\n",
            "          1.2073e-01, -1.0919e+00,  9.0638e-01],\n",
            "        [-1.8519e+00,  3.5015e+00, -1.7991e+00, -1.5445e+00,  1.9957e+00,\n",
            "         -7.5019e-01, -2.0768e+00,  8.6909e-01],\n",
            "        [-8.8698e-02, -6.4109e-01,  5.3033e-01, -9.4814e-01,  1.1327e+00,\n",
            "          9.6909e-01, -1.0266e+00, -1.4500e-01],\n",
            "        [-2.1346e+00,  1.8254e+00, -1.8422e+00,  1.2305e-01,  1.6187e+00,\n",
            "         -6.6045e-01, -1.4523e+00,  1.4788e+00],\n",
            "        [-1.7841e+00,  1.7793e-01, -8.3639e-01, -4.7318e-01,  2.1869e+00,\n",
            "          2.0600e-01, -1.0129e+00,  7.2856e-01],\n",
            "        [-6.9479e-01, -5.6734e-01,  4.7565e-01, -1.0347e+00,  9.7476e-01,\n",
            "          4.1971e-01, -1.3851e+00,  1.4219e+00],\n",
            "        [-1.7119e+00, -4.0843e-01, -1.6633e-01, -8.3155e-01, -4.6803e-01,\n",
            "          6.7174e+00, -8.1830e-01, -9.1618e-01],\n",
            "        [-6.8805e-01,  1.2127e+00, -5.8835e-01,  3.0537e-01,  8.4524e-01,\n",
            "         -3.6812e-01, -9.3397e-01,  1.6206e-01],\n",
            "        [-7.5621e-01,  2.4656e-01,  1.5664e+00, -1.2346e+00,  6.4923e-02,\n",
            "          1.3378e+00, -9.2566e-01, -2.0086e-02],\n",
            "        [-8.2789e-01,  1.0781e-01,  1.2930e+00, -1.3029e+00,  4.0186e-01,\n",
            "         -2.9256e-01, -1.8212e+00,  1.8111e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.4962,  1.3731, -0.9946, -0.7061,  1.9872, -0.1142, -1.2675,  0.5454],\n",
            "        [-2.3567,  0.3603, -1.2304, -1.1117,  2.4600, -0.4548, -1.3494,  2.4503],\n",
            "        [-2.5829,  6.6044, -1.6475, -1.4961,  0.2171, -1.6078, -1.1216, -0.1242],\n",
            "        [-0.7103,  0.6977, -0.1133,  0.2377,  0.9016,  0.3127, -1.0405, -0.1877],\n",
            "        [-2.3494,  0.7202, -1.3719, -1.4418,  2.3225, -0.6970, -1.1731,  2.8271],\n",
            "        [-1.0231, -0.7246,  0.6137,  1.4584,  0.7409,  0.4321, -0.4757, -0.3668],\n",
            "        [-2.5150,  6.7091, -1.6389, -2.0609,  0.1962, -1.4344, -1.6395,  0.2388],\n",
            "        [-0.6599, -0.3586,  1.5019, -0.6850,  0.1473,  1.8469, -0.2910, -0.7321],\n",
            "        [-0.7946,  0.5924,  0.7294,  0.1058, -0.2622,  0.9920,  0.0679, -0.8027],\n",
            "        [-2.2823,  0.5521, -1.6001, -0.9100,  2.7523, -0.5424, -1.5527,  2.5038],\n",
            "        [-2.1032,  5.4353, -1.3965, -2.1723,  0.5573, -1.7768, -2.3297,  0.8884],\n",
            "        [ 1.1904, -0.3487,  0.4937, -0.4610,  0.6081,  0.8113, -1.4698, -0.8209],\n",
            "        [-1.9389, -0.3918, -0.6319,  3.5321,  0.8843, -0.4725, -0.8285,  0.1676],\n",
            "        [-0.9319,  0.9204, -0.5339,  0.4673,  1.1751,  0.1271, -1.2231,  0.1582],\n",
            "        [-2.3674,  1.4794, -1.5239, -0.7864,  1.7774, -0.7389, -1.4805,  2.4829],\n",
            "        [-0.4970, -0.1122,  0.3639, -0.0816,  0.3387,  1.7903, -0.3501, -0.7611],\n",
            "        [-0.1845, -0.4686,  1.1306,  0.2128,  0.0880,  1.3209, -0.2214, -0.9775],\n",
            "        [-1.3081,  0.3084, -0.2370, -0.7901,  1.6437,  0.4709, -0.7343,  0.5649],\n",
            "        [-0.8835,  0.0661,  0.8805, -1.1017,  0.9205,  0.3024,  0.1928, -0.1757],\n",
            "        [-1.3159,  0.9893, -0.6692,  0.1007,  1.1806, -0.8999, -0.3884,  0.3302],\n",
            "        [-0.3674,  1.2177,  0.6513, -1.1958, -0.0264,  0.0079, -1.6763,  0.6652],\n",
            "        [-2.0078,  0.3985, -1.1021, -1.2809,  2.7604, -0.1759, -1.2147,  1.4264],\n",
            "        [-0.7323, -0.5551,  0.9174,  0.3341,  0.7122,  1.1262, -0.4744, -0.6431],\n",
            "        [-1.4913,  0.7554, -0.3048, -0.2342,  0.7581,  0.3964, -1.3759,  0.8551],\n",
            "        [-2.0306,  1.8706, -1.6132, -1.8487,  2.6616, -0.1669, -1.2791,  0.8537],\n",
            "        [-0.4129, -0.8132,  2.5967, -0.7254, -0.6314,  2.6192, -0.6397, -1.3527],\n",
            "        [-0.7704,  0.4350, -0.3932, -0.0839,  1.3116,  0.3651, -0.8754, -0.0542],\n",
            "        [-1.1492,  0.6938, -0.3267, -1.4565,  1.6977,  0.1130, -0.9526,  0.8406],\n",
            "        [-0.8845,  0.5107, -1.2625, -0.9482,  2.9455, -0.6137, -1.6998,  0.7887],\n",
            "        [-0.7883,  0.3595, -0.8371, -0.5636,  1.9424, -0.3529, -1.0777,  0.6953],\n",
            "        [-1.4872, -0.4405,  0.5637, -0.4063,  0.7466,  1.1465, -0.6727,  0.5860],\n",
            "        [-1.5340,  1.0877, -0.5588, -1.6158,  2.0687, -0.5973, -1.1970,  1.2628]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0180, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.1460, -0.3179,  0.4496, -0.9411,  0.9546,  0.7686, -1.3785, -0.2507],\n",
            "        [-1.7220,  1.8555, -0.9981, -0.1543,  1.2349, -0.3852, -1.4703,  0.9509],\n",
            "        [-2.4991, -0.1968, -1.4655, -2.4000,  4.6199, -0.6484, -0.1736,  0.8166],\n",
            "        [-0.4448,  0.2374, -0.2913, -0.6648,  1.6718,  0.3037, -1.2655,  0.3835],\n",
            "        [-1.4091, -0.6023,  1.4118, -0.5827,  0.0899,  2.5614, -0.2381, -0.5125],\n",
            "        [-1.4952,  0.2964,  0.0179, -0.9194,  1.3238,  0.1108, -1.3290,  1.4538],\n",
            "        [-0.6359, -0.1681,  1.0874, -0.0097, -0.3371,  2.1786, -0.0272, -1.0356],\n",
            "        [-1.0789, -0.1189,  0.0467, -0.3555,  1.1934,  0.9016, -0.7743,  0.2765],\n",
            "        [-2.0766,  0.7754, -1.2046, -1.0102,  2.4641, -0.3730, -1.1303,  1.4539],\n",
            "        [-2.0245,  1.3607, -1.0966, -0.9897,  1.9976, -0.6268, -1.2631,  1.6441],\n",
            "        [-2.2438,  0.9606, -1.4043, -0.5369,  1.5791, -0.5414, -2.1191,  3.1283],\n",
            "        [-2.2526, -0.0381, -1.4683, -0.5418,  0.2515, -1.1795, -1.7041,  5.8577],\n",
            "        [-1.1857, -1.2516, -0.2223, -2.1537,  5.8209, -0.3958, -0.6513, -0.7712],\n",
            "        [-0.7662,  0.5046,  1.0144, -1.3497, -0.2551,  0.6803, -1.0546,  1.0655],\n",
            "        [-1.2424,  1.0182, -0.9927, -0.6578,  1.7513, -0.3766, -1.0646,  0.8285],\n",
            "        [-2.0429,  1.1531, -1.8854, -1.3534,  2.3494, -0.7208, -1.6827,  2.4638],\n",
            "        [-2.3384, -0.0931, -0.8381, -0.4363,  2.5880, -0.2784, -0.6232,  1.2245],\n",
            "        [-1.2844, -0.4753,  1.3274, -0.9739,  0.2883,  2.6827, -0.7154, -0.6976],\n",
            "        [-2.0830,  2.5165, -0.7542, -1.3885,  1.2079, -0.4901, -1.1202,  0.8954],\n",
            "        [-1.5088,  0.6404, -1.0024, -1.4472,  2.6415, -0.1325, -0.7919,  0.7879],\n",
            "        [-1.4202, -0.5607, -0.8012, -2.4096,  5.4062, -0.3859, -0.5901, -0.5693],\n",
            "        [-1.3531, -0.3022,  1.8682, -0.8209, -0.3989,  2.3809, -0.2269, -0.2732],\n",
            "        [-0.1993, -0.5323,  0.7504, -0.6227,  0.5451,  1.4012, -0.6449, -0.4647],\n",
            "        [-3.1936,  3.4243, -2.5813, -2.0250,  1.7068, -0.9175, -2.2888,  3.4728],\n",
            "        [-1.8938,  0.1629, -1.8557, -1.9764,  2.2979, -0.6725, -1.8098,  4.3925],\n",
            "        [-0.9083,  0.5608, -0.9196, -1.4634,  2.4949, -0.1695, -0.9758,  0.7758],\n",
            "        [-3.0336,  3.1047, -0.8609, -1.0434,  1.7446, -1.1497,  0.8017, -0.7655],\n",
            "        [-2.6300,  5.8110, -1.7105, -0.9024,  0.4705, -2.0911, -0.7993,  0.0333],\n",
            "        [-2.5732, -0.1905, -1.4540, -1.9935,  4.3465, -0.4332, -0.0794,  1.0708],\n",
            "        [-0.0413, -0.5119,  1.5165, -0.6245, -0.0060,  1.7066,  0.0668, -1.2583],\n",
            "        [-2.0153,  0.5044, -0.7977, -0.7366,  1.8073, -0.3962, -0.8489,  1.4453],\n",
            "        [-2.1526,  1.6465, -1.8830, -0.5700,  2.3156, -0.9525, -1.3884,  1.7831]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0524, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.4908e+00,  8.6688e-01, -4.1246e-01, -1.4890e+00,  1.6669e+00,\n",
            "         -5.1631e-01, -7.5497e-01,  1.0739e+00],\n",
            "        [-1.5440e+00,  1.9444e+00, -1.3315e+00, -6.5756e-01,  1.9123e+00,\n",
            "         -5.9921e-01, -1.5601e+00,  1.1530e+00],\n",
            "        [-1.8372e+00, -2.5416e-01, -1.1298e+00, -1.8048e+00,  3.6749e+00,\n",
            "         -4.2154e-01, -4.3792e-01,  1.3229e+00],\n",
            "        [-4.4385e-01, -7.2218e-01,  6.0709e-01,  2.6961e-01,  9.7400e-01,\n",
            "          7.8948e-01, -6.7606e-01, -3.1134e-01],\n",
            "        [-9.4101e-01, -2.1087e-01,  3.2083e-01, -8.7939e-02,  1.0395e+00,\n",
            "          7.9682e-01, -6.8205e-01, -5.5878e-02],\n",
            "        [-8.3139e-01,  2.8789e-01, -5.0384e-01, -8.2897e-01,  1.7920e+00,\n",
            "          1.8870e-02, -1.0676e+00,  6.0437e-01],\n",
            "        [-1.2095e+00, -5.8284e-01,  2.1734e+00, -2.4456e-01, -2.7272e-01,\n",
            "          1.7709e+00,  2.6460e-01, -1.1768e+00],\n",
            "        [-6.7766e-01,  1.7371e+00,  1.4320e-01, -8.2124e-01,  4.8739e-01,\n",
            "          3.7982e-01, -1.4356e+00, -4.6606e-02],\n",
            "        [-1.2362e+00,  1.1500e+00, -1.9250e-02,  5.8631e-02,  2.8110e-01,\n",
            "          8.4805e-01, -8.8039e-01, -4.7199e-02],\n",
            "        [-1.6353e+00,  5.2780e-01, -1.3270e+00, -1.2983e+00,  2.7430e+00,\n",
            "         -1.1532e-02, -5.1846e-01,  1.0956e+00],\n",
            "        [-9.8756e-01, -2.9068e-01, -1.6484e-01,  1.1486e-01,  1.5328e+00,\n",
            "          6.6923e-01, -8.7185e-01,  1.2794e-01],\n",
            "        [-6.3692e-01,  4.1178e-01, -4.7689e-01, -8.0559e-01,  1.9718e+00,\n",
            "         -1.0438e-01, -1.3938e+00,  5.5701e-01],\n",
            "        [-1.8145e+00, -3.1520e-01, -1.5554e-01, -1.6806e+00,  1.1560e+00,\n",
            "         -9.2305e-02, -1.5075e+00,  3.0448e+00],\n",
            "        [-6.9467e-01, -8.3271e-01, -2.5295e-01, -2.0656e+00,  5.0665e+00,\n",
            "         -4.0004e-01, -9.7208e-01, -5.3797e-01],\n",
            "        [-1.5154e+00,  2.1488e+00, -9.3540e-01, -7.4836e-01,  1.0587e+00,\n",
            "         -3.2493e-01, -1.6601e+00,  8.4099e-01],\n",
            "        [-2.0771e+00, -1.7615e-01, -2.5239e-01, -7.4370e-01,  1.6637e-02,\n",
            "          6.4896e+00, -1.0343e+00, -6.1254e-01],\n",
            "        [-1.2240e-01, -4.8759e-01,  1.9764e-01,  7.0264e-01,  7.5900e-01,\n",
            "          6.7768e-01, -7.1390e-01, -4.8303e-01],\n",
            "        [-1.4171e+00, -2.2962e-01, -1.5137e+00,  4.5580e+00,  8.6669e-01,\n",
            "         -1.0632e+00, -7.9117e-01, -4.4752e-01],\n",
            "        [-1.9237e-01,  3.3662e-01,  4.5926e-01,  3.1544e-02, -1.8809e-01,\n",
            "          1.1214e+00, -2.8936e-01, -7.5018e-01],\n",
            "        [-2.1604e+00,  3.0100e+00, -1.6321e+00, -8.7343e-01,  1.3199e+00,\n",
            "         -5.6340e-01, -1.5192e+00,  1.2903e+00],\n",
            "        [-1.4689e+00, -1.2682e+00, -1.7947e-01, -2.1239e+00,  5.9182e+00,\n",
            "         -2.7506e-01, -4.3614e-01, -9.0366e-01],\n",
            "        [-1.2764e+00,  1.0410e+00, -1.2129e+00, -1.0552e+00,  2.2482e+00,\n",
            "         -3.8622e-01, -1.1166e+00,  1.0875e+00],\n",
            "        [-1.2453e+00,  2.0570e-01, -8.0760e-01, -1.1962e+00,  2.5343e+00,\n",
            "         -1.7599e-01, -8.9023e-01,  8.1109e-01],\n",
            "        [-2.5298e+00,  6.5524e+00, -1.5967e+00, -1.2936e+00, -2.1122e-01,\n",
            "         -1.3642e+00, -1.5332e+00, -1.5680e-01],\n",
            "        [-4.1136e-01, -5.6805e-02,  1.1531e+00, -1.4009e+00,  1.8284e-01,\n",
            "          1.4377e+00, -1.3709e+00,  6.5202e-01],\n",
            "        [-7.0437e-01, -6.9080e-01,  6.3906e-01, -3.4962e-02,  9.3924e-01,\n",
            "          6.2233e-01, -6.8291e-01,  1.8970e-01],\n",
            "        [ 9.3308e-01,  3.1359e-01,  1.2134e+00, -1.3728e+00,  2.9484e-01,\n",
            "          6.1975e-01, -1.5719e+00, -4.5468e-01],\n",
            "        [-4.7525e-01, -4.3383e-02, -5.7197e-01, -3.7772e-01,  1.7851e+00,\n",
            "          2.7146e-02, -1.0227e+00,  3.7647e-01],\n",
            "        [-1.3802e+00,  6.3531e-01, -1.3421e+00, -1.2360e+00,  2.6417e+00,\n",
            "         -6.2214e-01, -1.7494e+00,  2.3320e+00],\n",
            "        [-4.7216e-01, -4.9584e-01,  2.9385e+00, -1.1092e+00, -5.9823e-01,\n",
            "          1.9600e+00, -9.3162e-01, -8.5493e-01],\n",
            "        [-1.3538e+00,  4.0605e-01, -1.1184e+00, -1.9445e+00,  2.7077e+00,\n",
            "          1.5433e-01, -8.9210e-01,  9.1235e-01],\n",
            "        [-1.1590e+00, -6.4481e-01,  3.2481e-03, -7.1001e-01,  1.5162e+00,\n",
            "          4.1093e-01, -1.3664e-01,  5.0938e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1526e+00, -8.2606e-01,  3.0585e+00, -7.1721e-01, -1.4990e+00,\n",
            "          3.4231e+00, -3.0197e-01, -1.3030e+00],\n",
            "        [-9.9805e-01, -6.1457e-02,  3.4097e-01, -6.3350e-02,  1.2112e+00,\n",
            "          3.8315e-01, -6.8803e-01,  8.1731e-02],\n",
            "        [-8.1877e-01, -4.5654e-01,  3.5506e-01, -1.0127e-01,  1.2864e+00,\n",
            "          9.1578e-01, -5.6879e-01, -6.8298e-02],\n",
            "        [-2.0804e+00,  1.6556e-01, -8.0173e-01, -1.0772e+00,  2.3864e+00,\n",
            "         -6.3460e-01, -1.1436e+00,  2.0433e+00],\n",
            "        [-1.8969e+00,  1.9143e+00, -1.6053e+00, -5.6262e-01,  1.7105e+00,\n",
            "         -5.5725e-01, -1.5853e+00,  1.4417e+00],\n",
            "        [-2.2963e+00,  2.1460e+00, -2.1421e+00, -2.1594e+00,  2.6723e+00,\n",
            "         -1.1325e+00, -2.1043e+00,  2.4633e+00],\n",
            "        [-5.8345e-01, -1.2508e-01,  5.1636e-01, -5.5436e-01,  8.7769e-01,\n",
            "          1.1215e+00, -1.5644e-01, -5.4996e-01],\n",
            "        [-2.0886e+00,  1.2760e+00, -1.4622e+00, -1.1494e+00,  2.2761e+00,\n",
            "         -7.5680e-01, -9.5136e-01,  1.6219e+00],\n",
            "        [-2.1168e+00,  1.0053e+00, -6.8058e-01, -1.4086e+00,  2.1745e+00,\n",
            "         -4.4852e-01, -6.0710e-01,  1.1728e+00],\n",
            "        [-1.2229e+00,  1.1392e+00, -3.6515e-01, -3.1694e-01,  1.0668e+00,\n",
            "          3.7648e-01, -1.0517e+00,  3.0669e-01],\n",
            "        [-1.9695e+00,  3.1759e-02, -1.2904e+00, -1.5519e+00,  2.7848e+00,\n",
            "         -6.9474e-01, -1.6177e+00,  2.8783e+00],\n",
            "        [-2.3063e+00,  1.5131e-01, -1.1105e+00, -6.8572e-01,  2.3032e+00,\n",
            "          3.7514e-02, -6.3288e-01,  1.2493e+00],\n",
            "        [-1.2175e+00, -4.9212e-01,  5.8533e-02,  2.5341e+00,  4.1899e-01,\n",
            "          2.2681e-01, -5.2709e-03, -8.6935e-01],\n",
            "        [-2.7886e+00,  1.2701e+00, -2.3902e+00, -2.1359e+00,  3.6774e+00,\n",
            "         -1.3026e+00, -1.6378e+00,  3.4297e+00],\n",
            "        [-1.0187e+00, -8.7918e-02,  2.9595e-01, -5.5437e-01,  1.4850e+00,\n",
            "          6.7913e-01, -8.0568e-01,  2.7268e-01],\n",
            "        [-1.1194e+00, -1.3842e+00, -2.5159e-01, -1.9815e+00,  5.6541e+00,\n",
            "          9.5871e-02, -5.8775e-01, -1.0701e+00],\n",
            "        [-8.4755e-01, -7.5009e-03, -5.3267e-01, -5.6094e-01,  2.1594e+00,\n",
            "         -1.2948e-01, -9.2804e-01,  5.3758e-01],\n",
            "        [-2.0838e+00,  3.1474e+00, -1.6022e+00, -1.6250e+00,  1.5065e+00,\n",
            "         -1.1219e+00, -2.1931e+00,  2.2601e+00],\n",
            "        [-1.5312e+00,  3.4074e+00, -1.8632e+00, -8.9099e-01,  1.3546e+00,\n",
            "         -1.1511e+00, -1.6459e+00,  1.3419e+00],\n",
            "        [-1.1201e+00, -1.0688e+00, -1.6964e-01, -1.8656e+00,  5.0162e+00,\n",
            "         -1.2528e-01, -4.6070e-01, -1.0192e+00],\n",
            "        [ 1.5122e+00, -1.0858e+00,  1.0242e+00, -1.3056e-01,  1.6823e-02,\n",
            "          1.5791e+00, -1.3731e+00, -1.0456e+00],\n",
            "        [-1.3903e+00,  3.4209e+00, -9.6252e-01, -1.0442e+00,  8.0552e-01,\n",
            "         -6.0022e-01, -1.9947e+00,  5.5331e-01],\n",
            "        [-1.8610e+00, -2.5389e-01, -1.0139e+00, -9.8847e-01,  2.9731e+00,\n",
            "         -3.0254e-01, -6.5232e-01,  1.4818e+00],\n",
            "        [-2.6886e-01, -3.7516e-01, -2.6573e-01, -7.0873e-01,  1.5251e+00,\n",
            "          6.4865e-01, -8.5472e-01,  1.9279e-01],\n",
            "        [-4.1848e-01, -1.1235e+00,  1.5328e+00, -2.3763e-01,  1.9511e-01,\n",
            "          2.1700e+00, -3.5008e-01, -1.0814e+00],\n",
            "        [-7.5199e-01, -3.7577e-01, -3.3476e-01, -7.8072e-01,  1.9265e+00,\n",
            "         -7.6109e-02, -1.1159e+00,  1.1650e+00],\n",
            "        [-8.7144e-01,  2.6728e-01, -9.4963e-01, -1.9121e+00,  3.0347e+00,\n",
            "         -1.1106e-01, -1.1144e+00,  8.9278e-01],\n",
            "        [-1.0026e+00,  1.3668e+00, -5.2208e-01, -5.9956e-01,  5.8169e-01,\n",
            "          3.3821e-01, -6.2397e-01,  3.0636e-01],\n",
            "        [-9.9236e-01,  8.2130e-01, -7.8819e-01,  1.5002e-01,  1.4487e+00,\n",
            "          1.6125e-01, -1.4972e+00,  3.0835e-01],\n",
            "        [ 5.2333e-01, -5.2956e-01,  8.9971e-01, -6.1214e-01,  3.2277e-01,\n",
            "          1.6926e+00, -8.1080e-01, -9.6267e-01],\n",
            "        [-1.1217e+00,  2.8762e-01,  8.7287e-01, -4.8482e-02,  1.1662e-01,\n",
            "          1.4949e+00, -2.6555e-01, -5.5027e-01],\n",
            "        [-1.7431e+00,  1.3144e+00, -1.4318e+00, -8.8353e-01,  2.3205e+00,\n",
            "         -7.4429e-01, -1.1106e+00,  1.5162e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0899, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.3175, -0.2507,  0.1347, -0.2596,  1.3560,  0.3408, -0.7791, -0.2101],\n",
            "        [-1.5687,  0.0540, -0.9609, -0.6542,  2.3832, -0.4768, -1.0832,  1.2828],\n",
            "        [-2.9917,  1.1423, -3.0291, -1.8663,  2.4414, -1.4960, -2.0253,  5.1454],\n",
            "        [-1.8597,  1.7776, -1.1718, -0.0612,  1.4636, -0.5702, -1.6147,  1.1861],\n",
            "        [-1.5046,  0.3037, -1.3726, -1.8919,  2.2059, -0.8668, -1.5520,  3.0646],\n",
            "        [-1.9226,  4.7464, -1.8335, -1.1620,  0.9043, -1.4989, -2.6042,  0.8929],\n",
            "        [-0.2059, -1.0826,  1.3449, -0.2049,  0.8181,  1.3551, -0.7385, -0.7577],\n",
            "        [-1.0559, -1.2444,  0.4928, -1.8877,  5.2918, -0.0202, -0.2606, -1.0729],\n",
            "        [-2.0852,  1.6105, -1.7434, -2.1215,  2.6511, -0.5458, -1.0164,  2.0708],\n",
            "        [-0.8420,  1.5598,  0.0628, -0.7718,  0.2496,  0.1382, -1.5815,  0.7055],\n",
            "        [-0.3056, -0.7804,  0.7078, -0.5520,  0.9390,  1.3900, -0.2377, -0.3676],\n",
            "        [-1.8989,  0.7445, -0.8259, -0.3763,  1.8805, -0.6576, -1.0027,  1.2033],\n",
            "        [-0.4130, -1.0011,  2.5591, -0.7232, -1.1579,  3.5252, -0.2451, -1.5006],\n",
            "        [-0.9144,  0.0121,  0.4284, -1.3544,  1.7053, -0.0581, -0.9295,  0.6243],\n",
            "        [-1.4298,  0.7211, -0.4136, -1.3710,  1.1951, -0.7700, -1.6403,  2.9694],\n",
            "        [-2.2753,  2.4014, -1.5849, -0.7827,  1.6268, -0.7066, -1.9523,  1.8641],\n",
            "        [-1.5108,  0.4712, -0.9483, -1.0520,  1.9277, -0.3041, -1.4827,  1.1564],\n",
            "        [-1.8033, -0.2677, -0.7648, -1.2180,  2.9687, -0.0189, -0.3417,  0.7848],\n",
            "        [-0.2608, -0.7406,  0.5926, -0.2145,  1.0936,  1.1822, -0.8307, -0.5493],\n",
            "        [-0.9271, -0.3140,  0.8451, -0.4618,  0.6470,  0.4036,  0.5158, -0.2605],\n",
            "        [-1.9560,  0.0986, -1.8406,  5.5687,  0.2406, -1.3704, -0.4631, -0.5325],\n",
            "        [-0.2291, -0.2670,  0.9052, -0.6394,  0.3816,  1.5611, -0.8483, -0.2564],\n",
            "        [-1.9853,  2.6758, -0.8711, -0.9021,  1.0245, -0.7082, -1.3566,  1.1657],\n",
            "        [ 0.3031, -0.0755,  0.5174, -0.8070,  1.1127,  0.5394, -1.3634, -0.3060],\n",
            "        [-1.9907,  2.2159, -1.1289, -0.5476,  1.4101, -0.6367, -1.4658,  1.2763],\n",
            "        [-1.4250, -1.2172, -0.0944, -2.1706,  5.7309, -0.1237, -0.4870, -0.6691],\n",
            "        [-1.8688,  0.4364, -1.4642, -1.1112,  0.3686, -1.9532, -1.5705,  5.3686],\n",
            "        [-0.4162, -0.4787,  0.6777, -1.2610,  1.0145,  0.6445, -0.6874,  0.6752],\n",
            "        [ 0.8907, -0.3981,  1.2982, -0.9676,  0.2811,  1.0597, -1.4449, -0.5442],\n",
            "        [-1.7333,  0.0769, -1.1131, -1.0928,  2.5861, -0.2130, -1.3805,  1.6394],\n",
            "        [-0.0996, -1.1012,  1.9114, -1.3134,  0.3001,  2.0993, -0.4007, -0.9501],\n",
            "        [-0.2657, -0.8311,  1.8806, -1.7145,  0.2971,  1.4070, -0.6604, -0.1586]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.7536e+00,  2.1885e+00, -1.5129e+00, -1.5296e+00,  1.9116e+00,\n",
            "         -5.1357e-01, -1.6502e+00,  1.7099e+00],\n",
            "        [ 1.4819e+00, -3.9542e-01,  6.8361e-01, -8.6704e-01,  5.0763e-01,\n",
            "          5.0743e-01, -8.3518e-01, -1.0867e+00],\n",
            "        [-1.3363e+00, -1.0938e+00, -5.9582e-02, -2.0528e+00,  5.3741e+00,\n",
            "         -1.8109e-01, -3.5147e-01, -8.5794e-01],\n",
            "        [-1.5489e+00,  3.0715e-01, -1.0043e+00, -1.3571e+00,  2.7114e+00,\n",
            "         -3.8951e-01, -1.3246e+00,  1.5357e+00],\n",
            "        [-1.0663e+00, -4.3620e-01,  1.2696e-01, -1.4473e-01,  1.6042e+00,\n",
            "          7.3634e-01, -6.7639e-01,  3.4871e-01],\n",
            "        [-2.4132e+00,  8.4925e-01, -2.1798e+00, -2.2433e+00,  3.8751e+00,\n",
            "         -1.0993e+00, -1.4494e+00,  2.7695e+00],\n",
            "        [-5.0563e-02, -4.8451e-01,  8.7093e-01, -3.6198e-01,  1.0718e+00,\n",
            "          1.5673e-01, -1.0619e+00, -1.5660e-01],\n",
            "        [-1.5444e+00,  9.7478e-01, -1.9285e+00, -2.6829e+00,  4.1828e+00,\n",
            "          2.6403e-01, -1.5206e+00,  6.0446e-01],\n",
            "        [-2.7003e+00,  4.8172e+00, -2.3192e+00, -2.3105e+00,  1.7269e+00,\n",
            "         -1.5800e+00, -2.5319e+00,  1.9748e+00],\n",
            "        [-8.5898e-01, -7.0163e-01,  4.7127e-01, -1.6945e+00, -3.7351e-01,\n",
            "          6.5699e+00, -7.8025e-01, -8.2677e-01],\n",
            "        [ 8.5078e-01, -2.7165e-01,  4.8762e-01, -1.3322e+00,  1.2120e+00,\n",
            "          6.9964e-01, -1.4805e+00, -5.9260e-01],\n",
            "        [-1.1005e+00,  2.3576e-01, -3.7721e-01, -1.4554e+00,  2.1257e+00,\n",
            "          3.5528e-01, -9.4972e-01,  5.8951e-01],\n",
            "        [-1.3905e+00, -1.0004e+00, -1.2656e+00,  4.7972e+00,  6.7822e-01,\n",
            "         -7.2772e-01, -5.9105e-01, -7.9025e-01],\n",
            "        [-1.0184e+00, -1.0418e+00,  1.0441e+00,  2.0915e-01,  1.0722e+00,\n",
            "          6.5377e-01, -5.3998e-01, -4.5505e-02],\n",
            "        [-7.7283e-01,  1.6669e-01, -2.9929e-01, -1.0251e-01,  1.4025e+00,\n",
            "          2.2083e-01, -8.8230e-01,  1.7972e-01],\n",
            "        [-8.7756e-01, -3.9113e-01, -5.6570e-02, -1.5659e+00,  2.1869e+00,\n",
            "          2.6813e-01, -1.0619e+00,  1.0586e+00],\n",
            "        [-9.7277e-01, -8.1841e-01, -8.5016e-01,  4.2902e+00,  6.7691e-01,\n",
            "         -5.2571e-01, -6.1695e-01, -6.5497e-01],\n",
            "        [-9.8160e-01,  4.9829e-01, -4.6872e-01, -1.4431e+00,  2.3567e+00,\n",
            "         -5.2142e-01, -1.0165e+00,  1.1553e+00],\n",
            "        [-5.2642e-01, -5.2086e-01,  1.4625e+00, -7.3683e-01,  5.3950e-01,\n",
            "          8.5786e-01, -7.1846e-01, -6.4710e-01],\n",
            "        [-1.5437e+00,  8.0236e-01, -8.1528e-01, -7.5531e-01,  1.8742e+00,\n",
            "          4.3443e-02, -1.3627e+00,  1.0421e+00],\n",
            "        [-1.9541e+00,  1.2318e+00, -7.0287e-01, -1.9008e+00,  2.2341e+00,\n",
            "         -7.2118e-01, -9.8637e-01,  1.6468e+00],\n",
            "        [-1.6033e+00, -4.5371e-01,  2.3876e-01, -1.1142e+00,  1.1022e-01,\n",
            "          6.9682e+00, -9.0352e-01, -1.0612e+00],\n",
            "        [ 5.9853e-01,  5.8387e-01,  1.3955e-01, -1.0204e+00,  8.3957e-01,\n",
            "          7.6113e-01, -1.4334e+00, -5.0991e-01],\n",
            "        [-2.7806e-01, -3.4908e-01,  3.5658e-01, -1.6655e+00,  9.6266e-01,\n",
            "          3.6038e-02, -7.3228e-01,  7.9586e-01],\n",
            "        [-2.3629e+00,  2.6986e+00, -2.3591e+00, -1.9202e+00,  2.5112e+00,\n",
            "         -1.3894e+00, -2.0785e+00,  2.7422e+00],\n",
            "        [ 7.8240e-01, -4.9739e-01,  1.0750e+00, -1.2670e+00,  9.5249e-01,\n",
            "          1.0851e+00, -1.1823e+00, -6.0936e-01],\n",
            "        [-4.9847e-01,  1.5947e-01, -3.9415e-01, -5.5903e-01,  1.5884e+00,\n",
            "         -1.6102e-01, -9.8210e-01,  3.0606e-01],\n",
            "        [-9.1346e-01,  4.5889e-03,  8.3362e-01, -1.4630e+00,  1.2758e+00,\n",
            "          4.1738e-01, -4.3227e-01,  5.1297e-02],\n",
            "        [-2.6777e+00,  1.0996e+00, -1.4359e+00, -7.6908e-01,  2.1048e+00,\n",
            "         -7.2119e-01, -1.2486e+00,  2.7780e+00],\n",
            "        [-1.2858e+00, -4.8693e-01, -3.8367e-02, -1.2239e+00,  2.1710e+00,\n",
            "          2.5087e-01, -3.8442e-01,  4.0746e-01],\n",
            "        [-8.4437e-02, -8.9543e-01,  8.7690e-01, -3.7169e-01,  8.1347e-01,\n",
            "          1.4743e+00, -6.6070e-01, -5.6243e-01],\n",
            "        [-9.0209e-01,  7.8105e-01, -5.7969e-01, -2.6962e-01,  1.5858e+00,\n",
            "         -5.9863e-01, -1.2154e+00,  5.0405e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0454, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5723e+00, -1.3944e-01, -1.9018e+00, -2.4607e+00,  4.6732e+00,\n",
            "         -7.2764e-01, -1.7110e-01,  1.8297e+00],\n",
            "        [-2.3604e+00,  1.4910e+00, -2.3953e+00, -2.0739e+00,  4.0541e+00,\n",
            "         -1.2584e+00, -1.5488e+00,  2.3946e+00],\n",
            "        [-4.5491e-01, -9.7156e-01,  1.5406e+00, -4.3557e-02,  5.2483e-01,\n",
            "          9.3422e-01, -5.9218e-01, -7.5197e-01],\n",
            "        [-1.1120e+00,  6.6342e-01,  2.6418e-01, -1.5380e+00,  1.4766e+00,\n",
            "         -6.2705e-01, -1.8847e+00,  1.6462e+00],\n",
            "        [-1.7966e+00, -1.5039e-01, -1.5296e+00, -9.4993e-01,  4.2702e-01,\n",
            "         -1.2706e+00, -1.5435e+00,  5.9524e+00],\n",
            "        [ 2.8268e-01, -8.0311e-01,  1.1735e+00, -1.4234e+00,  9.7897e-01,\n",
            "          8.1018e-01, -8.2527e-01, -1.3314e-01],\n",
            "        [-1.8417e+00,  3.2516e+00, -1.5763e+00, -1.2011e+00,  7.5304e-01,\n",
            "         -8.4977e-01, -2.1345e+00,  1.9480e+00],\n",
            "        [-1.5618e+00, -3.4426e-02, -7.4327e-01, -8.0428e-01,  2.1824e+00,\n",
            "         -1.6703e-01, -5.9478e-01,  1.3333e+00],\n",
            "        [-8.8561e-01,  5.9181e-01, -6.5859e-01, -2.2127e-01,  1.2747e+00,\n",
            "          6.6571e-02, -1.2865e+00,  8.0542e-01],\n",
            "        [-7.9193e-01, -1.3706e+00,  4.1044e-01, -1.9914e+00,  5.3423e+00,\n",
            "         -2.3925e-01, -5.7194e-01, -1.2243e+00],\n",
            "        [-7.1573e-01,  9.3264e-02, -9.0462e-02, -1.1563e+00,  1.6460e+00,\n",
            "          2.3274e-01, -9.1769e-01,  8.0748e-01],\n",
            "        [-7.6869e-01, -3.3457e-01,  1.1892e+00, -9.3850e-01,  4.2997e-01,\n",
            "          1.3103e+00, -3.7410e-01, -2.1094e-01],\n",
            "        [-1.5713e+00,  1.5610e+00, -1.2274e+00, -9.5227e-01,  1.5831e+00,\n",
            "         -8.5588e-01, -1.4660e+00,  1.7578e+00],\n",
            "        [-1.1191e+00, -1.1210e+00, -2.0219e-01, -2.2217e+00,  5.4639e+00,\n",
            "          3.4079e-03, -2.2018e-01, -8.3884e-01],\n",
            "        [-1.5886e+00,  6.5208e-01, -1.4967e+00, -1.8112e+00,  3.3862e+00,\n",
            "         -2.0510e-01, -1.1846e+00,  1.0277e+00],\n",
            "        [-7.5489e-01, -3.7396e-01, -2.6305e-01, -1.7404e+00,  2.3545e+00,\n",
            "          3.0892e-01, -9.5938e-01,  5.4151e-01],\n",
            "        [-3.0406e-01, -8.5549e-01,  2.5283e-01, -5.7883e-01,  1.6271e+00,\n",
            "          1.4872e+00, -7.7730e-01, -2.7771e-01],\n",
            "        [-1.3593e+00, -7.5166e-01,  4.6966e-01,  1.5081e+00,  9.9270e-01,\n",
            "          3.4049e-01, -5.2018e-02, -3.2122e-01],\n",
            "        [ 9.1172e-01, -2.0149e-01,  4.0178e-01, -6.4566e-01,  6.8426e-01,\n",
            "          9.9482e-01, -1.5155e+00, -6.0716e-01],\n",
            "        [-3.8872e-01, -3.0609e-01,  2.2563e+00, -1.2408e+00, -5.3910e-01,\n",
            "          1.7727e+00, -1.0097e-03, -9.2056e-01],\n",
            "        [-1.0631e+00, -1.5393e-01, -2.7516e-01, -1.2264e+00,  1.5331e+00,\n",
            "          1.5819e-01, -9.6492e-01,  1.4612e+00],\n",
            "        [-2.4040e+00,  4.6999e-01, -1.9555e+00, -2.0238e+00,  2.7370e+00,\n",
            "         -1.4483e+00, -1.9242e+00,  4.6238e+00],\n",
            "        [-1.7145e+00,  8.7190e-01, -1.5229e+00, -2.3506e+00,  3.6080e+00,\n",
            "         -1.1379e-01, -1.3144e+00,  9.4003e-01],\n",
            "        [-7.2873e-01, -1.0767e+00,  1.4828e+00,  3.6282e-01,  1.7881e-01,\n",
            "          5.3056e-01,  1.2661e+00, -9.3854e-01],\n",
            "        [-3.7745e-01,  5.2464e-01, -3.6216e-01, -1.8514e+00,  2.0760e+00,\n",
            "         -3.1936e-01, -1.6929e+00,  9.1129e-01],\n",
            "        [-1.5155e+00, -2.7711e-01, -5.1005e-01,  3.0115e+00,  2.7514e-01,\n",
            "         -2.1580e-01, -2.5102e-01, -7.4243e-01],\n",
            "        [-2.7133e+00,  1.9108e+00, -1.8220e+00, -2.0807e+00,  2.1092e+00,\n",
            "         -1.1406e+00, -1.9530e+00,  3.1330e+00],\n",
            "        [-1.4951e+00,  7.9985e-01, -1.0702e+00, -1.1110e+00,  2.2098e+00,\n",
            "         -5.8463e-01, -1.4179e+00,  1.5633e+00],\n",
            "        [-1.7077e+00, -3.9182e-01,  1.2966e-02, -9.7548e-01, -2.5042e-01,\n",
            "          6.7875e+00, -8.5828e-01, -1.1169e+00],\n",
            "        [-2.4528e+00, -1.0488e-01, -1.1082e+00, -1.1388e+00,  2.8787e+00,\n",
            "         -7.2107e-01, -9.3007e-01,  2.2207e+00],\n",
            "        [-2.2591e+00,  1.1516e+00, -2.0476e+00, -2.4408e+00,  4.1649e+00,\n",
            "         -1.0372e+00, -1.1647e+00,  1.6471e+00],\n",
            "        [-1.4666e+00, -4.9237e-01,  4.7909e-01, -1.6877e+00,  1.4236e+00,\n",
            "          2.4935e-01, -1.0017e+00,  1.8206e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3356,  0.7462, -0.5360, -1.7491,  2.5544, -0.1330, -0.8312,  0.5721],\n",
            "        [-1.8110,  0.0421, -1.7501,  5.9828,  0.1238, -1.5533, -0.1282, -0.4805],\n",
            "        [-0.1667,  0.5157, -0.2014, -1.1654,  1.4087,  0.1975, -1.3519,  0.1860],\n",
            "        [-1.4010,  1.4731,  0.7243, -1.9134, -0.2662,  0.1493, -1.4149,  2.0255],\n",
            "        [ 0.5086,  0.1590,  0.8448, -0.4493, -0.1760,  0.9406, -0.4676, -0.7887],\n",
            "        [-1.7855, -0.0349, -0.6345,  2.4206,  0.7731, -0.7902, -0.2839,  0.5290],\n",
            "        [-1.5805,  0.0229, -1.0860,  0.0132, -0.6811, -1.4563, -1.3925,  4.9458],\n",
            "        [ 1.8249, -1.2641,  0.6386, -0.5001,  0.7486,  1.1632, -1.1796, -1.1778],\n",
            "        [ 0.1921, -0.5817,  0.3926, -0.4945,  0.9946,  0.9953, -0.9652, -0.3976],\n",
            "        [-0.7115,  1.1718, -0.0772, -0.9577,  0.7466, -0.2972, -1.6880,  1.0303],\n",
            "        [-1.2638,  0.2299, -0.9009, -1.3286,  2.6902, -0.0544, -1.1800,  0.8661],\n",
            "        [-2.7007,  0.9441, -2.4010, -2.0257,  3.5039, -1.3711, -1.6391,  3.7030],\n",
            "        [-0.9035,  0.0541, -0.4232, -1.1691,  1.7031,  0.3384, -1.1502,  0.8779],\n",
            "        [-0.8567,  0.3297,  0.0851, -0.9749,  1.4703,  0.2609, -0.8908,  0.2938],\n",
            "        [-2.1288,  1.9532, -1.6656, -1.9161,  2.9953, -0.4634, -1.0589,  0.8275],\n",
            "        [-0.7707, -0.1383, -0.2807, -1.1260,  2.1363, -0.2613, -1.1054,  1.1609],\n",
            "        [-1.6217, -0.4311, -0.4046, -2.1267,  5.1171, -0.6361, -0.3856, -0.3385],\n",
            "        [-0.5100,  0.5829, -0.2975, -0.4535,  0.4413,  0.3288, -0.9899,  0.7082],\n",
            "        [-0.5239, -0.0612, -1.1515, -1.8216,  3.0438,  0.2904, -1.4257,  0.7871],\n",
            "        [ 0.9025, -0.6531,  1.5526, -0.9179, -0.1233,  1.6810, -0.7508, -1.3331],\n",
            "        [-2.0488,  0.9269, -1.7116, -1.7105,  1.8782, -0.1305, -1.4523,  3.3193],\n",
            "        [ 0.4064,  0.5815,  0.1759, -0.3809,  0.4931,  0.7156, -0.9840, -0.8022],\n",
            "        [-0.8062, -0.7910,  0.3161, -0.6461, -0.0461,  5.8599, -1.2263, -1.6832],\n",
            "        [-1.3743,  4.0747, -0.8516, -1.5706,  0.2617, -0.6825, -2.7413,  1.2507],\n",
            "        [-1.2414, -0.7864,  5.7010, -1.9135, -0.9248,  0.7941, -0.6714, -0.9210],\n",
            "        [-1.2795, -0.3681, -0.2413, -0.5620,  2.4513, -0.1658, -0.3439,  0.2912],\n",
            "        [-1.2107, -1.0703,  0.1246, -2.2240,  5.3977, -0.0227, -0.4352, -1.1845],\n",
            "        [-0.7464, -0.2546,  0.5678, -0.6747,  1.2210,  0.5525,  0.0463, -0.2100],\n",
            "        [-0.3052,  0.0167, -0.6527, -1.0784,  1.3860,  0.8367, -1.3712,  0.7245],\n",
            "        [-0.3902,  0.8202,  0.3348, -1.9156,  1.1351,  0.1439, -1.5187,  0.7561],\n",
            "        [-0.8675, -1.2595,  0.3657,  0.6926,  1.0337,  0.7504,  0.2267, -0.4611],\n",
            "        [-0.4035, -0.5025,  0.9756, -0.9498,  1.0914,  0.7636, -0.4980, -0.3108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2025, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.6304e-01, -1.0399e+00,  1.9378e-01,  5.9658e-01,  1.1415e+00,\n",
            "          9.2136e-01, -3.0809e-01, -6.1503e-01],\n",
            "        [-1.0012e+00,  3.3868e-01,  2.3455e+00, -7.5661e-01, -7.3383e-01,\n",
            "          1.6366e+00,  8.5718e-02, -1.1347e+00],\n",
            "        [-9.9028e-01, -3.7514e-01, -4.0054e-01, -2.0006e+00,  2.8213e+00,\n",
            "          4.1854e-01, -7.7355e-01,  4.5462e-01],\n",
            "        [-5.2632e-01,  7.2153e-01, -2.1312e-01, -1.2942e+00,  1.3295e+00,\n",
            "         -8.0237e-02, -1.3934e+00,  7.0158e-01],\n",
            "        [-1.4944e+00,  6.4582e+00, -1.6426e+00, -2.2794e+00,  3.7083e-01,\n",
            "         -1.1936e+00, -2.6899e+00, -1.4914e-01],\n",
            "        [-1.7340e-01, -1.0396e+00,  1.3079e+00, -1.2295e+00,  9.9760e-01,\n",
            "          1.3028e+00, -4.5225e-01, -6.0711e-01],\n",
            "        [-1.3216e+00, -3.1824e-01,  1.3069e+00, -9.5636e-01,  5.8600e-01,\n",
            "          1.0736e+00, -1.3197e-01, -9.1523e-04],\n",
            "        [-2.5142e+00,  1.7461e+00, -2.3481e+00, -1.9529e+00,  2.8576e+00,\n",
            "         -1.3387e+00, -1.7236e+00,  2.6098e+00],\n",
            "        [-2.1928e+00,  2.5266e-01, -1.4519e+00, -1.7263e+00,  1.1117e+00,\n",
            "         -1.4518e+00, -1.6018e+00,  5.5474e+00],\n",
            "        [-2.2051e+00,  4.9145e+00, -1.6828e+00, -1.7456e+00,  8.6226e-01,\n",
            "         -1.1414e+00, -1.9855e+00,  1.2554e+00],\n",
            "        [-1.0281e+00, -9.7444e-04,  2.7079e-01, -1.7582e+00,  1.6654e+00,\n",
            "          2.3041e-01, -1.2325e+00,  1.2845e+00],\n",
            "        [ 5.3506e-02, -4.5376e-01,  6.0630e-01, -5.7507e-01,  8.1399e-01,\n",
            "          8.2105e-01, -7.4316e-01, -3.0444e-01],\n",
            "        [-2.1112e+00,  2.5060e-01, -8.5159e-01, -1.5552e+00,  2.5848e+00,\n",
            "         -3.1991e-01, -1.0909e+00,  2.1619e+00],\n",
            "        [-1.4748e+00,  2.8481e+00, -1.0451e+00, -1.1128e-01,  3.1594e-01,\n",
            "         -4.7652e-01, -1.3697e+00,  2.2702e-01],\n",
            "        [-8.8418e-01, -2.3528e-01,  2.7618e-01, -1.6394e+00,  1.9086e+00,\n",
            "          9.7059e-02, -6.7028e-01,  6.5567e-01],\n",
            "        [-7.6826e-01, -2.1259e-01,  5.8205e-01, -1.6097e+00,  1.6323e+00,\n",
            "         -1.9112e-01, -9.5367e-01,  9.5173e-01],\n",
            "        [ 5.5790e+00, -1.2948e-01, -1.2341e+00, -7.9937e-01, -5.8780e-01,\n",
            "         -1.2493e+00, -8.0926e-01, -9.2933e-01],\n",
            "        [-4.7152e-01, -8.7699e-01,  1.5107e+00,  3.8250e-01,  1.0716e-01,\n",
            "          4.9730e-01, -1.4235e-01, -6.5515e-01],\n",
            "        [-1.0507e+00, -1.7585e-01,  2.5162e-01, -7.7922e-01,  1.5228e+00,\n",
            "          3.9084e-01, -2.9124e-01,  1.9278e-01],\n",
            "        [-1.0243e+00, -4.4459e-01,  2.1737e+00, -2.0926e-01, -1.7859e-01,\n",
            "          1.3987e+00, -2.0410e-02, -9.6192e-01],\n",
            "        [-1.9112e+00,  1.4836e+00, -1.7675e+00, -1.5501e+00,  2.7473e+00,\n",
            "         -8.1057e-01, -1.1943e+00,  1.3788e+00],\n",
            "        [-2.3049e+00,  7.0156e+00, -1.4974e+00, -1.6249e+00, -3.5524e-01,\n",
            "         -1.2725e+00, -1.6695e+00,  3.3733e-02],\n",
            "        [-2.7980e+00,  3.7560e-01, -2.0258e+00, -1.9485e+00,  2.9801e+00,\n",
            "         -1.7678e+00, -1.6287e+00,  4.9130e+00],\n",
            "        [-4.4956e-01, -5.3558e-01,  1.0674e+00, -1.1867e+00,  1.4421e+00,\n",
            "          3.8125e-01, -5.5813e-01, -9.4686e-02],\n",
            "        [-9.1984e-01, -1.0724e+00,  2.3147e+00, -8.1179e-01, -3.8380e-01,\n",
            "          3.0614e+00, -3.7049e-01, -1.0060e+00],\n",
            "        [-5.7978e-01, -1.0313e+00,  2.5263e+00, -1.6100e-01,  1.8291e-02,\n",
            "          7.4954e-01, -1.4641e-01, -8.9374e-01],\n",
            "        [-1.5156e+00, -1.5385e+00, -2.0664e-01, -1.9279e+00,  6.0952e+00,\n",
            "         -4.8339e-01, -4.1390e-01, -6.1143e-01],\n",
            "        [-2.3860e+00,  1.9961e+00, -2.4243e+00, -1.6472e+00,  3.2361e+00,\n",
            "         -1.4459e+00, -2.0105e+00,  2.5466e+00],\n",
            "        [-1.7260e+00,  1.0767e+00, -6.7940e-02, -1.4288e+00,  1.1210e+00,\n",
            "         -3.8817e-01, -1.3142e+00,  1.7688e+00],\n",
            "        [-1.7731e+00, -3.5032e-01, -1.2362e+00, -8.6514e-01,  2.9898e+00,\n",
            "         -4.2548e-01, -1.0130e+00,  1.3478e+00],\n",
            "        [-3.8946e-01, -6.1351e-01,  3.7304e-01, -1.8023e+00,  1.9321e+00,\n",
            "          5.8175e-01, -1.1394e+00,  2.9470e-01],\n",
            "        [-8.2203e-01, -7.2590e-01,  8.0981e-01, -5.8352e-01,  1.4581e+00,\n",
            "          7.9476e-01, -4.9509e-01, -5.1967e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5375, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.2325,  2.0398, -2.3834, -1.8825,  2.7263, -1.5456, -1.7445,  2.8928],\n",
            "        [ 5.7160, -0.6477, -1.0096, -1.1722, -0.7426, -1.1659, -0.4849, -1.2219],\n",
            "        [-0.1226,  0.4312,  1.2774, -0.6853, -0.4954,  2.2327, -0.7628, -1.1331],\n",
            "        [-0.6654, -1.1379,  2.3985, -0.7114, -0.1602,  2.9859, -0.4463, -1.1968],\n",
            "        [-2.6947,  1.6137, -1.9232, -2.1426,  3.1161, -1.0614, -1.2379,  2.2533],\n",
            "        [-1.8036, -0.4129,  0.1633,  2.6091,  0.2989, -0.2024, -0.0794, -0.5961],\n",
            "        [-2.8372,  0.0796, -1.8339, -0.6003,  3.2568, -0.5467, -0.9969,  2.2212],\n",
            "        [-0.7318, -0.3904,  0.6762, -1.1242,  1.6681,  0.0559, -1.1246,  0.9021],\n",
            "        [-0.2805, -0.9351,  1.5780, -0.8775,  0.6134,  1.5681, -0.5635, -0.3567],\n",
            "        [-1.6923,  0.3733, -0.3810, -1.4538,  2.0869, -0.1453, -0.9557,  1.3566],\n",
            "        [-0.6822, -0.7123,  0.8273, -0.6775,  1.3135,  1.5470, -0.7497, -0.3265],\n",
            "        [-2.1636,  4.1489, -1.6844, -1.7723,  1.2663, -0.8619, -2.1371,  1.2391],\n",
            "        [ 1.7098, -0.5910,  2.1982, -1.2106, -0.8507,  1.7988, -0.6166, -1.4010],\n",
            "        [-0.7657,  0.3835,  0.1315, -0.7180,  0.7258,  0.2579, -1.2412,  0.6964],\n",
            "        [-1.4415, -0.1522,  0.1044, -0.9975,  1.5993,  0.6576, -0.7975,  0.4752],\n",
            "        [ 1.0494, -0.9408,  2.1164, -1.1837,  0.0146,  1.4642, -0.3284, -1.4768],\n",
            "        [-2.6308,  3.7445, -2.4655, -1.9154,  2.6202, -1.3621, -1.8437,  1.9117],\n",
            "        [-1.4742, -0.2130, -1.0014,  3.4638,  0.5585, -0.3622,  0.2352, -0.8522],\n",
            "        [-1.3633, -0.4275, -0.0103, -0.6009,  1.7821,  0.6178, -0.7165,  0.4702],\n",
            "        [-0.5403, -0.9735,  2.0958, -0.8716,  0.2057,  1.8137,  0.0660, -1.0691],\n",
            "        [-1.8749, -0.6219,  4.8616, -1.5905, -1.6589,  2.5489,  0.2487, -1.4646],\n",
            "        [-0.7445, -0.5316,  1.6926,  0.4318,  0.1171,  0.7728,  0.1419, -1.1518],\n",
            "        [-0.7202, -1.7320,  0.4843, -2.0044,  5.5483, -0.1216, -0.6351, -1.1279],\n",
            "        [ 0.2814, -0.4086, -0.1290, -0.5601,  0.8854,  0.6826, -0.9712, -0.1089],\n",
            "        [-0.9272,  1.1540,  1.9447, -2.0794, -0.2507,  0.3352, -0.9521,  0.3922],\n",
            "        [-1.6187,  2.7381, -1.0293, -1.8731,  1.2605, -0.4790, -1.2883,  0.6176],\n",
            "        [-0.4394, -0.4209,  0.2162, -1.3694,  1.5320,  0.4827, -1.1919,  0.5948],\n",
            "        [-1.0503, -0.2861, -0.0148, -1.1493,  1.6790,  0.4298, -0.8574,  0.7285],\n",
            "        [-0.0128, -0.4222,  1.2049, -0.5898,  0.5076,  1.1932, -0.2521, -0.8880],\n",
            "        [-1.4674, -0.2770,  0.7847, -1.4893, -0.2524,  6.6358, -1.1005, -1.2569],\n",
            "        [-1.5509,  2.7847, -1.1206, -0.6292,  1.0203, -0.8432, -1.1662,  0.6705],\n",
            "        [ 0.7734, -0.8172,  2.0433, -1.3971,  0.5489,  1.6286, -1.2011, -0.9980]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5437e+00,  2.2870e+00, -2.4591e+00, -2.3506e+00,  3.3852e+00,\n",
            "         -1.5014e+00, -1.6626e+00,  2.6127e+00],\n",
            "        [-1.4816e+00, -1.0697e+00, -4.2883e-01, -2.2944e+00,  5.6008e+00,\n",
            "         -5.0714e-01, -2.0405e-01, -6.1430e-01],\n",
            "        [-1.0472e+00, -4.2405e-01, -6.8582e-01,  2.7726e+00,  1.0431e+00,\n",
            "         -1.3151e-01, -5.6836e-01, -3.1743e-01],\n",
            "        [ 4.4837e-01, -6.1620e-01,  3.3337e-01, -1.9806e-01,  1.0709e+00,\n",
            "         -6.2635e-02, -2.7737e-01, -5.1406e-01],\n",
            "        [-2.0256e+00,  3.1910e-01, -1.4800e+00, -1.6841e+00,  8.7872e-01,\n",
            "         -1.3446e+00, -1.5899e+00,  5.7295e+00],\n",
            "        [-2.6500e+00,  9.1050e-01, -2.5287e+00, -2.4355e+00,  4.7450e+00,\n",
            "         -1.2810e+00, -1.0800e+00,  1.8760e+00],\n",
            "        [-1.5544e+00,  2.1306e+00, -1.8183e+00, -1.7003e+00,  2.4221e+00,\n",
            "         -6.1106e-01, -1.5023e+00,  1.2442e+00],\n",
            "        [ 9.2689e-01, -8.8384e-01,  2.0779e+00, -1.5020e+00,  2.5495e-03,\n",
            "          1.6394e+00, -8.5037e-01, -1.3928e+00],\n",
            "        [ 2.4377e+00, -1.0966e+00,  2.9657e+00, -1.9523e+00, -7.8288e-01,\n",
            "          1.8738e+00, -1.1941e+00, -1.6744e+00],\n",
            "        [-1.9660e+00,  2.2851e+00, -7.8553e-01,  6.8528e-01,  9.8295e-01,\n",
            "         -6.0171e-01, -1.3037e+00,  2.6743e-01],\n",
            "        [-1.0780e+00, -1.5298e+00,  3.0851e-01, -2.1814e+00,  5.7937e+00,\n",
            "         -1.6735e-01, -5.3831e-01, -7.7533e-01],\n",
            "        [-1.5348e-01, -8.0860e-01,  4.7610e-01, -9.6297e-01,  1.6958e+00,\n",
            "          1.0143e+00, -8.2404e-01, -3.3764e-01],\n",
            "        [-4.6889e-01, -3.6361e-01, -7.5735e-03, -1.5131e+00,  2.0593e+00,\n",
            "          2.7569e-01, -4.8930e-01,  3.6121e-01],\n",
            "        [-1.6845e+00,  5.6586e-01, -1.5784e+00, -2.4112e+00,  3.9703e+00,\n",
            "         -6.4286e-01, -1.0553e+00,  1.0631e+00],\n",
            "        [ 2.2437e-02, -7.6749e-01,  9.5758e-01, -3.6496e-01,  9.8651e-01,\n",
            "          4.6850e-01, -5.7840e-01, -4.9976e-01],\n",
            "        [-4.0828e-01,  1.4758e-02, -2.6280e-01, -1.0716e+00,  1.8988e+00,\n",
            "          4.1093e-01, -1.3042e+00,  4.6188e-01],\n",
            "        [-1.3470e+00,  9.3124e-02, -3.8088e-01, -1.2769e+00,  2.4039e+00,\n",
            "         -3.0398e-01, -7.4885e-01,  8.1886e-01],\n",
            "        [-1.9446e+00,  1.7776e-01, -3.7196e-01, -1.5610e+00,  2.5436e+00,\n",
            "         -2.3155e-01, -2.7889e-01,  7.9586e-01],\n",
            "        [-8.0890e-01, -2.4235e-01,  3.8034e-01, -2.4851e+00,  2.1679e+00,\n",
            "          1.5307e-01, -2.1506e-01,  4.0841e-01],\n",
            "        [ 1.0146e-01, -6.9557e-01,  7.0541e-01, -3.4428e-01,  1.0742e+00,\n",
            "          9.1551e-01, -7.0386e-01, -6.3417e-01],\n",
            "        [-1.1060e-01, -1.3571e+00,  2.1816e+00, -8.6632e-01,  4.5989e-02,\n",
            "          2.4309e+00, -5.8319e-01, -1.2967e+00],\n",
            "        [-1.5258e+00,  1.6930e+00, -5.6878e-01, -1.4416e+00,  9.0465e-01,\n",
            "         -7.1712e-01, -1.7274e+00,  2.3204e+00],\n",
            "        [-1.5494e+00,  3.1370e-02, -3.0444e-01,  3.7389e-01,  1.8102e+00,\n",
            "         -2.1714e-02, -1.3562e-01, -2.2847e-01],\n",
            "        [-1.5890e+00,  5.9276e-01, -7.8047e-01,  1.7117e-01,  1.5919e+00,\n",
            "          1.8492e-01, -1.5349e-01, -2.3199e-01],\n",
            "        [-1.5222e+00,  4.3008e-01, -1.6548e-01, -8.3542e-01,  1.9985e+00,\n",
            "          2.0572e-01, -5.0627e-01, -2.4017e-02],\n",
            "        [-1.2502e+00, -1.1870e+00,  2.4628e+00, -6.3098e-01, -8.0616e-01,\n",
            "          3.8091e+00, -3.0776e-01, -1.2900e+00],\n",
            "        [-6.7677e-01, -3.8171e-01,  2.5450e-01, -1.5014e+00,  1.9414e+00,\n",
            "          6.3696e-01, -9.0202e-01,  3.8471e-01],\n",
            "        [-3.1604e-01, -2.2157e-01, -1.8342e-01, -5.4447e-01,  1.6021e+00,\n",
            "          6.4676e-01, -9.2413e-01, -5.7055e-02],\n",
            "        [-3.1051e-01,  5.9730e-01,  9.8859e-02, -1.3781e-01,  7.0217e-02,\n",
            "         -8.7954e-02, -1.4828e+00,  7.2565e-01],\n",
            "        [-3.9511e-01, -2.0885e+00,  6.7609e-01,  9.7121e-02, -5.2437e-01,\n",
            "         -1.6039e+00,  6.2418e+00, -7.4459e-01],\n",
            "        [-2.1565e+00, -1.5764e+00,  3.0929e-01,  3.0709e-01, -9.7450e-02,\n",
            "         -9.5254e-01,  5.9375e+00, -4.8374e-01],\n",
            "        [-5.0569e-01, -8.8136e-01,  3.8705e-01, -7.1821e-01,  1.7027e+00,\n",
            "          9.0598e-01, -8.9607e-01,  3.8710e-03]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9707, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.3044e-01, -1.0864e+00,  1.6609e+00, -6.9559e-01,  6.7754e-01,\n",
            "          1.1677e+00, -6.4207e-01, -8.5098e-01],\n",
            "        [-1.5540e+00, -7.3233e-02, -1.1443e+00, -8.4924e-01,  2.9839e+00,\n",
            "         -7.7519e-01, -1.2107e+00,  1.7133e+00],\n",
            "        [ 1.2728e-01, -1.2124e+00,  2.2016e+00, -1.2842e+00, -1.4081e-01,\n",
            "          2.5309e+00, -7.6453e-01, -1.2695e+00],\n",
            "        [-1.7155e+00, -3.6400e-01, -3.9799e-01, -1.2630e+00,  2.8231e+00,\n",
            "         -2.0348e-01, -2.7572e-01,  7.3670e-01],\n",
            "        [-1.6366e+00,  6.0854e-01, -1.3236e+00, -1.7584e+00,  1.9667e+00,\n",
            "         -4.1813e-01, -1.8831e+00,  3.1193e+00],\n",
            "        [ 2.9345e-01, -1.6874e-01,  1.2805e+00, -8.1457e-01, -9.6573e-02,\n",
            "          1.2542e+00, -3.8086e-01, -6.4469e-01],\n",
            "        [-5.0019e-01, -3.8703e-01,  5.5894e-01, -1.1392e+00,  1.4510e+00,\n",
            "          4.6654e-01, -6.7176e-01,  3.2693e-01],\n",
            "        [-1.1251e+00,  2.6791e-01,  3.8671e-01,  5.5758e-01,  7.8207e-01,\n",
            "          1.3397e-01, -7.9467e-01, -4.3111e-01],\n",
            "        [-2.1394e+00,  5.5360e+00, -1.7296e+00, -1.4199e+00,  5.3311e-01,\n",
            "         -1.3003e+00, -2.6626e+00,  1.5904e-01],\n",
            "        [-1.2225e+00,  4.5026e-02, -2.8386e-01,  2.0432e+00,  6.2590e-01,\n",
            "         -4.0319e-02, -4.8225e-01, -6.9245e-01],\n",
            "        [-1.0049e+00,  1.3819e+00, -2.9268e-01, -7.8983e-01,  1.0691e+00,\n",
            "          2.4039e-01, -1.0476e+00,  1.3040e-01],\n",
            "        [ 6.0894e-01, -1.0394e+00,  1.1115e+00, -5.6334e-01,  8.8005e-01,\n",
            "          1.1941e+00, -9.7229e-01, -6.2734e-01],\n",
            "        [-7.5534e-01, -1.6930e+00,  4.5306e-01, -1.8052e+00,  5.8230e+00,\n",
            "         -4.0418e-03, -7.7600e-01, -1.4913e+00],\n",
            "        [ 2.5250e-01, -5.4892e-01,  2.5068e-01, -1.2588e+00,  1.3132e+00,\n",
            "          8.4901e-01, -1.1111e+00,  1.6322e-01],\n",
            "        [-1.2582e+00, -1.2525e-01,  3.9401e-01, -1.3902e+00, -7.8801e-01,\n",
            "          6.6435e+00, -1.1049e+00, -9.9465e-01],\n",
            "        [-1.1654e+00, -4.0757e-01, -1.1302e+00, -1.7096e+00,  3.0252e+00,\n",
            "         -3.0669e-01, -1.2352e+00,  1.6060e+00],\n",
            "        [-1.6570e+00, -7.7767e-01,  5.6255e+00, -1.6099e+00, -3.3297e-01,\n",
            "         -3.0102e-01, -1.2501e+00, -5.0719e-01],\n",
            "        [-1.7617e+00, -7.7538e-01,  1.0604e+00, -1.2045e+00,  1.4937e+00,\n",
            "          1.6163e+00, -2.9775e-01,  1.5521e-01],\n",
            "        [-1.2182e+00, -1.5012e+00,  3.6012e-01, -1.9735e+00,  5.8304e+00,\n",
            "         -7.0417e-02, -4.5039e-01, -1.1966e+00],\n",
            "        [-1.0977e+00,  2.0927e-01, -8.8130e-01, -1.6215e+00,  2.6564e+00,\n",
            "         -1.7867e-01, -9.3784e-01,  9.2203e-01],\n",
            "        [-1.7109e+00,  3.3721e-01, -1.6556e+00, -2.2868e+00,  3.8113e+00,\n",
            "         -4.0597e-01, -9.2072e-01,  1.4167e+00],\n",
            "        [ 9.9664e-02, -8.2713e-01,  1.0694e+00, -5.3157e-01,  4.3586e-01,\n",
            "          1.8209e+00, -5.3058e-01, -8.5472e-01],\n",
            "        [-9.0111e-02,  5.7515e-01,  1.3501e-01, -1.1132e+00,  1.1465e+00,\n",
            "          1.6914e-01, -1.5121e+00,  2.0184e-01],\n",
            "        [-1.4058e+00, -3.6567e-02, -6.6900e-01, -1.8377e+00,  2.7471e+00,\n",
            "          2.8898e-01, -5.9942e-01,  6.9218e-01],\n",
            "        [-1.4815e+00, -7.4856e-01,  6.7629e-01,  7.2377e-01,  7.1004e-01,\n",
            "         -4.6431e-02,  1.0376e+00, -6.8722e-01],\n",
            "        [-1.7662e+00,  4.0938e+00, -1.6048e+00, -2.4634e+00,  1.7417e+00,\n",
            "         -4.9903e-01, -2.2251e+00,  6.4072e-01],\n",
            "        [-8.1456e-01, -1.6025e-01, -5.9485e-01, -1.7568e+00,  2.1759e+00,\n",
            "          1.1192e+00, -1.4569e+00,  4.9430e-01],\n",
            "        [-1.1622e+00, -8.9524e-01,  1.4181e+00, -9.4790e-01,  9.7244e-01,\n",
            "          1.7407e+00, -2.3647e-01, -1.0218e+00],\n",
            "        [-2.6939e+00, -1.0800e-01, -2.0155e+00, -3.0898e+00,  4.9202e+00,\n",
            "         -9.4284e-01, -5.7748e-01,  1.8589e+00],\n",
            "        [ 5.7660e-01, -5.3813e-01,  1.7260e+00,  3.9441e-02, -9.3593e-01,\n",
            "          7.1036e-02, -1.3535e+00,  3.6111e-01],\n",
            "        [-6.7596e-01,  4.3123e-01,  8.6404e-01, -1.6154e-01, -7.8448e-02,\n",
            "          2.4627e-01,  6.7051e-01, -8.7119e-01],\n",
            "        [ 4.5127e-01,  8.9348e-02,  1.1722e+00, -7.3142e-01, -2.3806e-01,\n",
            "          1.4928e+00, -1.1042e+00, -9.3598e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1109,  0.2934, -1.7120, -1.9259,  3.4938, -0.6116, -1.0359,  2.1963],\n",
            "        [-0.7644, -0.9631,  1.2296, -0.8877,  0.9705,  1.8213, -0.6571, -0.1566],\n",
            "        [-2.0863,  0.1539, -1.9363, -2.1327,  3.6994, -0.7781, -1.3439,  2.5201],\n",
            "        [-1.6226,  5.1535, -0.2771, -1.7373, -0.2813, -0.7950, -2.5589, -0.1108],\n",
            "        [-2.2653,  0.4534, -1.6854, -2.2176,  4.1546, -0.7609, -0.9419,  1.9042],\n",
            "        [-1.4025,  1.3450, -0.9349, -0.6270,  1.9449, -0.4755, -1.5826,  0.5967],\n",
            "        [ 0.5451, -0.5965,  1.0474, -1.5958,  1.0637,  0.5536, -1.5489,  0.3445],\n",
            "        [-1.2046,  0.2969, -0.5750, -1.8698,  2.2670, -0.3072, -1.0127,  1.6225],\n",
            "        [-2.0059,  1.1626, -1.7945, -1.5222,  2.6962, -1.1169, -1.5120,  2.2296],\n",
            "        [-1.9632,  0.5503, -1.2799, -1.6353,  3.0492, -0.5779, -1.0820,  1.7358],\n",
            "        [-0.0144, -0.3617,  1.2923, -1.0061,  0.2211,  1.5130, -0.4836, -0.5666],\n",
            "        [-1.3288, -1.1339, -0.2217, -2.0936,  6.0419, -0.6359, -0.6335, -0.5246],\n",
            "        [-1.3201, -0.2767, -0.5429, -1.7298,  2.4598, -0.1937, -0.9474,  1.7506],\n",
            "        [-1.1770, -0.1701, -0.2884, -1.8295,  2.6274, -0.0348, -0.8759,  1.0537],\n",
            "        [-1.5176, -0.3048,  0.1720, -1.1202,  1.9664,  0.5013, -0.2657,  0.2255],\n",
            "        [-1.0468,  1.0289,  0.0115, -0.7563,  1.5584,  0.2312, -1.0097, -0.3889],\n",
            "        [-0.2052, -0.6936,  0.7353, -0.9489,  0.9849,  1.5513, -0.5435, -0.6694],\n",
            "        [-0.6549, -1.0441,  1.3911, -0.6795,  0.5184,  2.3011, -0.3296, -0.7600],\n",
            "        [-1.7926,  3.7288, -2.1429, -1.8239,  2.3938, -1.4342, -2.0900,  1.2067],\n",
            "        [-2.9600,  0.9379, -2.5032, -2.1667,  2.8158, -1.6646, -2.1787,  5.6219],\n",
            "        [-0.3850, -0.0846,  0.4367, -1.0952,  1.1633, -0.0137, -1.5428,  0.9980],\n",
            "        [-1.1517, -1.0951, -0.1046, -2.3680,  5.6038, -0.1998, -0.6135, -1.0642],\n",
            "        [-1.6029,  0.2093, -1.2825, -1.6340,  3.1821, -0.4520, -0.6224,  0.8759],\n",
            "        [-2.6238,  0.9154, -2.2495, -2.1254,  3.8388, -1.0284, -1.7395,  3.1406],\n",
            "        [-0.7129, -0.3250, -0.5769, -1.8650,  2.7421,  0.4369, -1.1167,  0.6002],\n",
            "        [-1.9011,  0.2105, -0.7542,  1.5767,  1.5370, -0.8143,  0.3833,  0.0153],\n",
            "        [-1.7918,  1.6057, -1.0329, -1.2253,  1.9247, -0.3529, -1.3728,  1.2191],\n",
            "        [-2.3717,  2.1693, -2.1385, -1.6026,  2.9906, -1.4590, -1.0364,  1.5746],\n",
            "        [-2.2529,  2.4743, -2.0607, -1.9920,  2.9847, -0.5050, -1.7784,  1.6385],\n",
            "        [-2.9642,  2.6454, -2.5610, -2.4018,  3.1332, -1.4851, -1.6069,  2.6400],\n",
            "        [-0.5711,  0.3364, -0.7499, -1.6552,  2.1427,  0.7102, -1.0974,  0.4211],\n",
            "        [-0.6339, -0.3935,  0.1305, -1.1838,  1.7897,  0.7991, -0.7088,  0.0137]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.3845, -1.3324,  2.0328, -0.6191,  0.4000,  1.0706, -0.6953, -1.1570],\n",
            "        [-2.3499, -1.2232,  0.8126, -0.7099,  4.3829, -0.4126,  0.1491, -1.2006],\n",
            "        [-0.9560, -1.4529,  2.3501, -1.1993, -0.0540,  2.7831, -0.4193, -0.4396],\n",
            "        [-1.3484, -0.7746,  1.9136, -0.9689,  0.1314,  2.5743, -0.4269, -0.6166],\n",
            "        [-2.2150,  5.5877, -1.8665, -2.0479,  1.0310, -1.4162, -2.3120,  0.7718],\n",
            "        [-1.7318, -0.7503,  1.3766, -1.2940,  0.3781,  2.1355, -1.2680,  1.3094],\n",
            "        [-1.3362,  1.5607, -0.9259, -1.3607,  0.9641, -0.7543, -2.0412,  2.3070],\n",
            "        [-1.3316,  0.6122,  0.3771,  0.7854,  0.7167, -0.2577, -0.6739, -0.3028],\n",
            "        [-1.7949,  6.9283, -1.5426, -2.1408,  0.0621, -1.3056, -1.7279, -0.0528],\n",
            "        [-1.4984,  1.3851, -0.6676, -2.1108,  1.8087, -0.4499, -1.8911,  2.0582],\n",
            "        [-1.3223, -1.3803, -0.3278, -2.2645,  5.9008, -0.1957, -0.1862, -0.7861],\n",
            "        [-2.2971, -0.0589, -1.2727, -2.7074,  4.9548, -0.3315, -0.6500,  0.8448],\n",
            "        [-2.1625,  3.3348, -2.2865, -1.1947,  1.2488, -1.0918, -1.5106,  1.8185],\n",
            "        [-2.2144,  5.5798, -2.1223, -2.2241,  1.3003, -1.1286, -2.4575,  0.7622],\n",
            "        [-1.8893, -0.3392, -0.2224, -1.3588, -0.0083,  6.2730, -0.9900, -0.6295],\n",
            "        [-2.0712, -0.7018, -1.7332, -1.4189,  1.3868, -1.3981, -1.5962,  5.7139],\n",
            "        [-0.5655, -1.0796,  2.3969, -0.8979, -0.6394,  2.7870, -0.4283, -1.1701],\n",
            "        [-0.5139, -0.2529, -0.1994, -0.4138,  1.4970,  0.2023, -1.2038,  0.3171],\n",
            "        [-0.4014,  0.0575,  0.2911, -0.3781,  0.8335,  0.5323, -0.8266, -0.2137],\n",
            "        [-1.8939,  1.8991, -1.2738, -1.2435,  2.3451, -0.7996, -1.3668,  0.8492],\n",
            "        [ 0.7057, -1.5997,  2.4283, -0.8691, -0.0377,  1.3979, -0.5934, -1.0507],\n",
            "        [-1.5723, -1.1211, -0.5906, -2.3569,  5.8867, -0.0343, -0.6147, -0.6265],\n",
            "        [-1.3111, -0.5355, -0.1173, -1.7662,  2.3758,  0.6414, -0.7271,  0.7782],\n",
            "        [-2.0482,  1.7327, -2.2323, -1.4497,  2.0216, -1.5700, -1.9485,  4.4818],\n",
            "        [-0.3578, -0.8892, -0.4067, -1.3181,  2.4965, -0.1029, -0.9483,  0.6659],\n",
            "        [-2.0750, -0.1237, -0.9593, -1.3313,  3.1003, -0.6374,  0.4748,  0.7726],\n",
            "        [-0.4458, -1.0864,  1.0836, -0.5476,  1.2834,  1.1199, -0.6308, -0.4075],\n",
            "        [-0.6574, -0.0957,  0.3041, -0.0765,  1.1258,  0.3533, -0.9302, -0.1279],\n",
            "        [ 0.0337,  0.0131,  0.6183, -0.7082,  0.8856,  0.6489, -0.6765, -0.4271],\n",
            "        [-1.2764,  0.3020, -1.0909, -1.9986,  2.9957,  0.0496, -0.9587,  1.0033],\n",
            "        [-0.0852, -0.5492, -0.1084, -0.9191,  1.4875,  0.9916, -0.7112,  0.0194],\n",
            "        [-0.8210, -1.1537,  2.9564, -1.3334, -0.8515,  3.1476, -0.4009, -1.3069]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1982,  0.1032, -1.1069, -1.8484,  3.0899, -0.0755, -1.2652,  1.6802],\n",
            "        [ 0.2809, -1.1027,  1.5517, -1.1688,  0.5447,  0.6361,  0.0667, -0.8200],\n",
            "        [-2.4742,  0.3978, -1.6849, -2.0818,  3.7078, -1.0163, -1.1401,  2.2655],\n",
            "        [-0.5843, -0.9798,  1.7282, -1.1710, -0.0873,  0.3905,  1.3335, -0.0866],\n",
            "        [-1.7200, -0.0341,  1.0352, -0.6551,  0.7597,  1.5505, -0.1205, -0.5930],\n",
            "        [-0.0669, -0.6681,  0.2340, -0.7636,  1.5565,  0.6972, -0.8787, -0.0772],\n",
            "        [-0.7921, -0.4353, -0.4468, -1.1863,  2.4689,  0.4999, -1.0579,  0.5859],\n",
            "        [-1.0870, -0.8565,  0.8343, -0.0508,  0.6426,  1.4510, -0.2855, -0.2801],\n",
            "        [-1.7226,  0.5642, -0.4634, -1.8844,  2.4883, -0.0626, -0.8580,  0.8719],\n",
            "        [ 0.4890, -0.5758,  1.6536, -1.7995,  0.8699,  0.7268, -1.3364, -0.3546],\n",
            "        [ 0.1520,  0.6202,  0.8244, -1.6149,  0.6142,  0.2635, -1.6580,  0.3674],\n",
            "        [-1.6860,  1.3879, -0.7578, -0.9073,  1.7390, -0.2999, -1.4339,  1.1552],\n",
            "        [-1.0797, -0.1195, -0.2610, -1.7673,  2.4093, -0.0945, -1.0791,  0.9083],\n",
            "        [-1.2073,  0.2320, -1.2801, -2.3513,  3.0183, -0.5443, -1.1191,  1.1284],\n",
            "        [-0.1971, -0.1700,  0.3689, -1.7667,  1.2697,  0.6342, -1.0304,  0.1351],\n",
            "        [-0.1249, -0.8076,  0.9871, -1.1223,  1.0353,  0.7679, -0.7035, -0.2842],\n",
            "        [-0.8671, -1.3971,  1.6777, -0.6493,  0.3459,  2.7313, -0.1627, -0.7129],\n",
            "        [-1.2218, -1.0497,  0.5113, -1.4661,  2.3306,  0.5030, -0.2593,  0.3638],\n",
            "        [-2.4632,  0.2757, -1.7873, -1.8598,  3.3928, -0.7179, -1.5491,  3.0414],\n",
            "        [-2.0464,  0.6053, -1.8582, -2.0164,  3.8627, -1.0072, -1.3996,  2.1639],\n",
            "        [-1.3529, -1.4546,  0.3267, -2.0481,  5.7319, -0.1997, -0.6458, -1.0502],\n",
            "        [-1.9559, -0.7509, -0.1529,  0.8590,  2.0466, -0.0257,  0.6008, -0.5642],\n",
            "        [-1.1790,  1.0303, -0.3212, -1.3027,  1.6350,  0.0731, -1.0635,  0.4243],\n",
            "        [-2.4588,  3.0570, -2.6246, -2.0963,  2.9358, -1.1934, -2.0841,  1.7177],\n",
            "        [-0.3195,  0.1397, -0.1936, -0.5896,  1.5830,  0.1148, -1.0585, -0.1763],\n",
            "        [-2.6912,  1.4858, -2.2062,  0.7257,  1.9372, -1.5803, -1.2917,  1.8835],\n",
            "        [-1.5802, -0.4114, -0.5433, -2.2890,  3.7005,  0.3532, -0.6223,  0.5786],\n",
            "        [-0.5524, -0.0780,  1.4199, -0.9907,  0.4654,  0.7664, -0.9436, -0.2569],\n",
            "        [-2.0442, -0.2065, -1.3158, -2.1175,  4.2433, -0.4157, -0.3017,  0.7442],\n",
            "        [-0.9992, -1.4059,  0.6596, -2.2465,  5.5844, -0.1970, -0.5642, -1.2867],\n",
            "        [-1.0801, -0.3691, -1.1275, -2.0707,  2.9888,  0.2868, -0.9208,  1.1646],\n",
            "        [-0.9830, -0.0151, -0.2803, -1.9154,  2.6300,  0.0554, -1.4079,  0.9933]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.4819,  2.4009, -0.7951, -0.8850,  1.3647, -0.0987, -1.5427, -0.0501],\n",
            "        [-1.7123,  0.4498, -0.9810, -1.7558,  2.7772, -0.2740, -1.0016,  1.2115],\n",
            "        [-0.6992, -0.4820,  0.5306, -1.6867,  2.3920, -0.2776, -0.8071,  0.3485],\n",
            "        [-0.7684, -0.1739, -0.4890, -1.7204,  2.0546, -0.1556, -1.3015,  1.6494],\n",
            "        [ 0.0807, -0.5010,  1.0710, -1.4525,  1.6042,  0.3934, -0.9266, -0.1077],\n",
            "        [-1.5244,  1.1630, -1.1999, -1.6505,  2.5152, -0.4923, -1.4736,  1.1597],\n",
            "        [-0.4559,  0.7350, -0.3898, -0.5512,  1.3898,  0.2562, -1.9247,  0.4109],\n",
            "        [ 0.1395,  0.2550,  1.2187, -1.7654,  0.4164,  0.5919, -1.3412,  0.3326],\n",
            "        [-1.8490,  6.9159, -1.8896, -1.5498, -0.2112, -1.7563, -1.8208,  0.3435],\n",
            "        [-2.1371,  1.3520, -1.5353, -1.7979,  1.9533, -0.3569, -1.3399,  2.2013],\n",
            "        [-2.2373, -0.0744, -2.1816, -2.0277,  3.4729, -1.2796, -1.9472,  4.3174],\n",
            "        [-0.6682, -0.5436,  1.4777, -0.2356,  0.2330,  1.0738, -0.2866, -0.5266],\n",
            "        [-1.9931,  0.4146,  0.6905, -1.3335,  0.6980,  1.6253, -0.9738,  0.5388],\n",
            "        [-1.5417, -1.1170,  0.4599, -0.4810, -0.2174, -1.0255,  5.2159, -0.1636],\n",
            "        [-2.2514,  2.1500, -2.1020, -2.6101,  3.4902, -0.7627, -2.1403,  1.5990],\n",
            "        [-2.1780,  2.5625, -2.3918, -2.1464,  2.5326, -1.2442, -1.9548,  2.3200],\n",
            "        [-0.7398, -0.6338,  0.9850, -0.4401,  0.9053,  1.7922, -0.7186, -0.3802],\n",
            "        [-0.1013, -0.9361,  0.8157, -1.5393,  2.1586,  0.5097, -0.9699, -0.0866],\n",
            "        [-2.4932, -0.1487, -0.8142, -0.8889,  0.5469, -1.3211, -1.0667,  5.1506],\n",
            "        [-1.5462, -0.5855, -0.1797, -1.4874,  2.7055,  0.1651, -0.6985,  0.8858],\n",
            "        [ 6.3623, -0.2604, -1.1655, -0.8361, -0.6431, -1.0546, -0.7405, -1.4253],\n",
            "        [-1.7534,  1.9128, -1.7381, -2.4661,  2.8935, -0.3869, -1.9171,  1.5279],\n",
            "        [-2.4377,  0.4931, -2.1403, -2.1577,  3.6995, -1.3977, -1.7481,  4.1326],\n",
            "        [-0.9081, -0.5727, -0.4013, -2.0051,  2.5843,  0.1845, -1.1961,  1.3318],\n",
            "        [-1.5801,  1.0001, -1.2772, -1.5294,  2.4972, -0.5069, -1.1096,  1.0921],\n",
            "        [-0.7516, -0.6400,  0.9782, -1.1700,  1.0874,  1.0248, -0.4103, -0.1419],\n",
            "        [-1.5959, -0.6966,  0.4527, -0.5790,  1.6913,  0.9282, -0.8235,  0.4202],\n",
            "        [-1.6969,  0.3354, -1.0978, -1.6403,  3.0736, -0.4171, -0.8364,  1.3104],\n",
            "        [-2.2969,  3.9248, -2.4337, -2.5244,  3.2436, -1.0581, -2.2691,  0.8465],\n",
            "        [-1.0015,  0.7569, -0.4811, -1.5912,  1.7848, -0.4081, -1.5001,  1.3257],\n",
            "        [-2.6466,  5.5737, -2.3809, -2.2377,  1.4301, -1.3925, -2.8063,  0.6304],\n",
            "        [-1.9646,  0.2829, -1.3649, -2.4869,  5.1315, -0.7610, -0.4140,  0.1836]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3086, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.4773e-02, -1.5882e-01,  1.1724e+00, -1.4335e+00,  3.7928e-01,\n",
            "          8.4267e-01, -1.0144e+00,  3.2337e-02],\n",
            "        [-2.1754e+00,  1.1931e+00, -1.9925e+00, -2.7335e+00,  4.6531e+00,\n",
            "         -3.7220e-01, -9.5760e-01,  6.0964e-01],\n",
            "        [-1.4359e+00, -7.4921e-01, -3.7385e-01, -2.3860e+00,  5.7037e+00,\n",
            "          3.2724e-02, -5.8384e-01, -1.0941e+00],\n",
            "        [-1.3598e+00,  3.0802e-01, -1.4356e+00, -2.2249e+00,  2.4759e+00,\n",
            "         -1.2116e+00, -1.3297e+00,  3.9196e+00],\n",
            "        [-1.5224e+00,  2.4461e+00, -1.7675e+00, -1.5334e+00,  2.7041e+00,\n",
            "         -6.5155e-01, -1.6736e+00,  4.2376e-01],\n",
            "        [-1.9878e+00,  5.6230e-01, -1.6377e+00, -1.8824e+00,  2.9064e+00,\n",
            "         -9.0159e-01, -1.2836e+00,  2.4061e+00],\n",
            "        [-1.4293e+00,  3.7125e-02, -7.2193e-01, -1.4364e+00,  2.6030e+00,\n",
            "         -6.2320e-01, -1.2327e-01,  2.6042e-01],\n",
            "        [-1.9011e+00,  1.0954e-01, -1.5264e+00, -2.1453e+00,  3.6715e+00,\n",
            "         -6.1246e-01, -1.3267e+00,  2.1628e+00],\n",
            "        [-2.2316e+00,  5.9094e-01, -2.4542e+00, -2.7394e+00,  4.1042e+00,\n",
            "         -1.3738e+00, -1.5936e+00,  3.6164e+00],\n",
            "        [-1.6385e+00,  6.1193e-01, -6.5205e-01, -1.0294e+00,  2.2861e+00,\n",
            "          1.0849e-01, -8.0214e-01,  8.2594e-01],\n",
            "        [-1.7216e+00, -6.1503e-03, -1.1226e-01, -7.7215e-01,  2.0781e+00,\n",
            "          2.5260e-01, -6.0509e-01,  4.3689e-01],\n",
            "        [-4.4287e-01,  3.5720e-03,  1.0218e+00, -2.2883e-01,  7.0808e-01,\n",
            "          4.2036e-01, -8.4762e-01, -5.2741e-01],\n",
            "        [-1.7584e+00,  1.5222e+00, -2.2264e+00, -2.2196e+00,  3.4577e+00,\n",
            "         -8.3600e-01, -1.7340e+00,  1.8578e+00],\n",
            "        [-7.7221e-01, -1.6133e-01,  1.7515e-01, -4.6567e-01,  1.5597e+00,\n",
            "          4.3569e-01, -2.9524e-01, -2.7791e-01],\n",
            "        [-1.7489e+00,  1.4619e+00, -1.7851e+00, -1.5419e+00,  2.8292e+00,\n",
            "         -6.8719e-01, -1.6118e+00,  1.7805e+00],\n",
            "        [-6.2627e-01, -1.9157e-01,  1.7680e-01, -1.6511e+00,  1.9889e+00,\n",
            "          3.4409e-01, -7.5999e-01,  2.1299e-01],\n",
            "        [-7.2006e-01, -6.3228e-01,  5.1668e-01, -9.7339e-01,  1.8848e+00,\n",
            "          1.8173e-01, -5.6011e-01,  1.5920e-01],\n",
            "        [-2.0020e+00,  6.3297e+00, -2.0036e+00, -2.0886e+00,  1.1873e+00,\n",
            "         -1.6511e+00, -2.5616e+00, -5.1641e-02],\n",
            "        [-1.7847e+00, -7.1772e-01,  1.9500e-01, -1.1295e+00, -5.4057e-02,\n",
            "          6.5651e+00, -6.3742e-01, -1.3948e+00],\n",
            "        [-8.3995e-01, -1.2351e+00, -5.8967e-02, -2.3022e+00,  5.8303e+00,\n",
            "          2.3492e-01, -5.6576e-01, -1.2352e+00],\n",
            "        [-2.1441e+00,  4.6641e+00, -1.7700e+00, -1.9599e+00,  1.0794e+00,\n",
            "         -1.0030e+00, -1.9411e+00,  7.3434e-01],\n",
            "        [-1.2160e+00, -9.2604e-01,  6.2690e-02,  8.4883e-02,  1.7347e+00,\n",
            "          2.1427e-01, -2.3333e-01,  1.7554e-02],\n",
            "        [-2.0298e+00,  2.0697e+00, -2.7693e-01, -2.2261e+00,  1.3810e+00,\n",
            "         -3.6508e-01, -1.4405e+00,  1.5904e+00],\n",
            "        [-1.4563e+00,  7.6616e-01, -9.8167e-01, -1.1982e+00,  2.1017e+00,\n",
            "         -7.0890e-02, -5.1946e-01,  5.3951e-01],\n",
            "        [-1.7280e+00, -6.2241e-01, -1.0208e+00, -2.7632e+00,  5.8088e+00,\n",
            "         -8.1313e-01, -5.6037e-01,  4.7506e-01],\n",
            "        [-2.8187e-01, -8.7718e-01,  6.9918e-01, -5.2349e-01,  1.2537e+00,\n",
            "          9.9343e-01, -4.3498e-01, -6.2541e-01],\n",
            "        [-9.6435e-01, -6.3519e-01,  1.3712e+00, -7.5813e-01,  9.6743e-01,\n",
            "          1.0269e+00, -6.4097e-01, -4.5629e-01],\n",
            "        [-1.7136e+00,  1.5337e+00, -7.4823e-01, -1.2756e+00,  1.8487e+00,\n",
            "          3.0952e-01, -1.2152e+00,  6.1012e-01],\n",
            "        [-2.0504e+00,  1.8524e+00, -5.2517e-01, -2.1689e+00,  1.8506e+00,\n",
            "         -6.1635e-01, -1.0664e+00,  1.0639e+00],\n",
            "        [-1.6003e-01, -1.1643e-01,  2.3546e+00, -1.5181e+00,  4.8041e-01,\n",
            "          7.5681e-01, -1.4802e+00, -4.1261e-01],\n",
            "        [-1.9974e+00, -5.9320e-01,  2.0043e+00, -6.4311e-01, -6.1869e-01,\n",
            "          2.8303e+00,  1.2463e-01, -1.1718e+00],\n",
            "        [-3.3133e-01, -7.5470e-01,  2.6511e-01, -1.1493e+00,  1.7901e+00,\n",
            "          9.2934e-01, -9.0500e-01, -1.9283e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.8528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3419e+00,  1.7501e+00, -1.4089e+00, -1.0123e+00,  1.7697e+00,\n",
            "         -5.7834e-01, -1.4059e+00,  7.2748e-01],\n",
            "        [-4.1059e-01, -5.9192e-01,  5.5308e+00, -1.8746e+00, -8.4394e-01,\n",
            "          5.1600e-01, -1.4107e+00, -9.3024e-01],\n",
            "        [-3.2107e-01,  2.6500e-01,  3.2004e-01, -6.4460e-01,  1.2242e+00,\n",
            "         -1.4209e-02, -9.2647e-01, -8.2631e-02],\n",
            "        [-2.2444e+00,  1.2806e+00, -2.3587e+00, -2.7380e+00,  4.6492e+00,\n",
            "         -9.1557e-01, -1.2210e+00,  1.3488e+00],\n",
            "        [-1.0122e+00, -1.3922e+00,  7.2329e-02, -2.1709e+00,  5.7355e+00,\n",
            "         -1.4009e-01, -4.8759e-01, -1.0251e+00],\n",
            "        [-1.5670e+00, -3.3913e-01, -9.1207e-01, -1.4325e+00,  3.0663e+00,\n",
            "         -2.1400e-01, -1.1076e+00,  1.3669e+00],\n",
            "        [ 7.8324e-01, -3.3499e-01,  1.0206e+00, -8.2556e-01, -2.0789e-01,\n",
            "          1.9600e+00, -5.2075e-01, -1.0967e+00],\n",
            "        [-8.5127e-01, -6.5380e-01, -3.0968e-01, -1.5673e+00,  2.4270e+00,\n",
            "          6.3144e-01, -1.1747e+00,  6.5820e-01],\n",
            "        [-2.7122e+00,  1.4294e-01, -1.8070e+00, -1.9593e+00,  3.2409e+00,\n",
            "         -7.6698e-01, -1.2281e+00,  2.8645e+00],\n",
            "        [-2.2193e+00,  2.0322e+00, -2.0438e+00, -2.0485e+00,  2.6599e+00,\n",
            "         -8.3960e-01, -1.8055e+00,  1.9537e+00],\n",
            "        [-1.9579e+00,  7.1196e+00, -2.0102e+00, -1.5975e+00, -1.5667e-01,\n",
            "         -1.3715e+00, -1.7603e+00,  9.2038e-02],\n",
            "        [-2.3374e+00,  6.7039e-01, -2.6556e+00, -2.3785e+00,  2.9096e+00,\n",
            "         -7.3720e-01, -1.5592e+00,  4.1804e+00],\n",
            "        [-1.3440e+00, -1.2777e+00, -3.4086e-03, -2.2848e+00,  5.6732e+00,\n",
            "         -3.1530e-02, -5.5482e-01, -9.1570e-01],\n",
            "        [-1.9911e+00,  1.0988e+00, -2.0307e+00, -2.2050e+00,  3.5335e+00,\n",
            "         -6.2123e-01, -1.5388e+00,  1.7427e+00],\n",
            "        [-1.8672e+00,  1.5284e-01, -1.9348e+00, -2.4079e+00,  4.3322e+00,\n",
            "         -7.8890e-01, -6.7361e-01,  1.4880e+00],\n",
            "        [-1.7512e+00,  2.9238e+00, -1.4780e+00, -1.6100e+00,  1.6531e+00,\n",
            "         -4.8022e-01, -1.6897e+00,  8.6643e-01],\n",
            "        [-1.3478e+00,  4.5665e-01, -4.6073e-01, -2.0174e+00,  2.5645e+00,\n",
            "         -2.3869e-01, -1.0207e+00,  1.1247e+00],\n",
            "        [-1.2180e+00,  2.0493e+00, -1.2881e+00, -1.5830e+00,  1.9546e+00,\n",
            "          1.1016e-01, -1.5740e+00,  5.2029e-01],\n",
            "        [-9.5554e-01, -1.4705e+00,  2.3712e+00, -7.4837e-01, -2.1620e-01,\n",
            "          2.7391e+00, -2.9549e-01, -9.3771e-01],\n",
            "        [-1.8633e+00,  8.1088e-01, -1.3294e+00, -1.8085e+00,  3.2715e+00,\n",
            "         -3.8841e-01, -4.2084e-01,  7.8735e-01],\n",
            "        [-9.2338e-01,  5.7312e-01,  2.3842e-01, -1.2533e+00,  1.2731e+00,\n",
            "          2.0185e-01, -6.6595e-01,  4.2017e-01],\n",
            "        [-1.4952e+00, -1.2132e+00,  5.9823e+00, -1.7363e+00, -6.2503e-01,\n",
            "         -1.2766e-01, -3.7254e-01, -4.3711e-01],\n",
            "        [-1.3256e+00,  5.9677e-01, -8.1602e-01, -1.5423e+00,  2.2635e+00,\n",
            "         -3.1503e-02, -7.6442e-01,  4.7889e-01],\n",
            "        [-1.3482e+00, -1.7372e+00,  3.3829e-01,  2.6762e-01, -1.7624e-01,\n",
            "         -1.2088e+00,  6.3980e+00, -7.7576e-01],\n",
            "        [-2.0501e+00,  2.3112e+00, -1.8227e+00, -7.1079e-01,  1.7880e+00,\n",
            "         -1.1899e+00, -1.4393e+00,  1.4923e+00],\n",
            "        [ 2.7660e-01,  1.2945e+00, -2.8276e-01, -1.0922e+00,  6.2654e-01,\n",
            "          6.8313e-01, -1.5266e+00, -2.9202e-01],\n",
            "        [-1.9438e+00,  6.9607e+00, -1.9764e+00, -2.0265e+00,  2.0720e-01,\n",
            "         -1.6430e+00, -2.0973e+00, -7.1071e-02],\n",
            "        [-2.2445e+00,  1.6245e+00, -2.3314e+00, -2.2202e+00,  4.3024e+00,\n",
            "         -9.0349e-01, -1.3150e+00,  7.7040e-01],\n",
            "        [-2.0890e+00,  2.6212e+00, -2.2412e+00, -2.0935e+00,  2.8138e+00,\n",
            "         -1.6392e+00, -1.9302e+00,  2.2850e+00],\n",
            "        [-1.8066e+00,  6.2811e-01, -7.8667e-01, -2.3821e+00,  2.1717e+00,\n",
            "         -1.5375e-01, -1.4264e+00,  2.7133e+00],\n",
            "        [-2.4103e+00, -1.3591e+00,  6.0423e-02,  7.3833e-01, -2.6535e-01,\n",
            "         -5.4737e-01,  6.2109e+00, -1.0232e+00],\n",
            "        [-8.8019e-01,  5.1925e-01, -8.1255e-02, -1.2440e+00,  1.4156e+00,\n",
            "          2.8796e-01, -8.9187e-01,  2.2161e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.3574, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.0440, -0.1542, -1.1743, -2.4145,  4.1896, -0.0250, -0.6288,  0.6142],\n",
            "        [-0.2303, -0.5560,  1.1517, -0.8938,  0.3745,  1.3223, -0.7299, -0.3356],\n",
            "        [-1.2270,  0.9081, -0.7861,  1.5362,  1.1651, -0.5510, -0.8486, -0.3778],\n",
            "        [-1.2668, -0.0953, -0.2187, -1.8004,  2.2165,  0.1334, -0.6236,  0.9481],\n",
            "        [-2.0848,  0.6278, -1.9481, -2.0540,  1.3700, -1.0616, -2.0110,  5.5066],\n",
            "        [-2.3152,  4.7512, -2.7711, -2.4096,  2.4718, -1.4089, -2.1564,  0.8753],\n",
            "        [-1.5100,  0.2128, -1.1207, -1.2673,  2.9855, -0.2096, -0.5105,  0.3794],\n",
            "        [-1.2495, -0.4115, -0.4346, -1.5217,  2.2202,  0.2853, -1.1952,  1.4732],\n",
            "        [ 0.7114, -1.0884,  1.5723, -1.4953,  0.5038,  1.3774, -0.6978, -0.5117],\n",
            "        [-0.8770, -0.3210,  0.1516, -1.3664,  2.0699,  0.2300, -0.8522,  0.4165],\n",
            "        [-1.7308,  3.1101, -0.8164, -1.4401,  0.8103, -0.3456, -1.5625,  0.5015],\n",
            "        [-2.3389,  2.9792, -2.7154, -2.4290,  3.6014, -1.3669, -1.7094,  1.6315],\n",
            "        [-1.1681, -1.4152,  0.1874, -1.8820,  5.8091, -0.1777, -0.6645, -1.2824],\n",
            "        [-1.5916, -0.0979, -1.3790, -2.6814,  5.0935,  0.1071, -0.6620, -0.2611],\n",
            "        [-2.2714,  1.4823, -2.4822, -2.3253,  3.9686, -0.7262, -1.3408,  1.5743],\n",
            "        [-1.1416, -0.5296, -1.4085,  4.9372,  0.2787, -1.3511, -0.4290, -0.8055],\n",
            "        [-1.5766,  0.7474, -1.5154, -1.8563,  3.2015, -0.7351, -1.1536,  1.5563],\n",
            "        [ 0.6507, -0.8781,  0.3644, -1.5718,  1.5282,  1.3427, -1.1239, -0.4578],\n",
            "        [-2.1544,  6.7640, -1.9955, -2.1289,  0.3836, -1.6203, -2.1559,  0.3999],\n",
            "        [-1.2161,  1.4007, -1.6271, -1.5199,  1.0205, -0.7728, -1.7777,  3.1851],\n",
            "        [-1.3265, -0.4787,  1.3743, -1.4549,  1.9294,  0.0999, -0.4214,  0.1663],\n",
            "        [-1.8660,  6.3970, -1.8287, -1.8270,  0.2959, -1.1344, -1.7432, -0.0244],\n",
            "        [-1.7257, -0.2848,  0.1379, -0.9768,  2.2342,  0.6223, -0.6717,  0.6391],\n",
            "        [-2.4164,  3.0651, -1.2812,  0.1374,  1.1947, -0.6896, -0.5364, -0.3797],\n",
            "        [-0.9031, -0.7809,  1.3136, -1.4134,  0.7159,  1.9728, -0.3927,  0.0174],\n",
            "        [-1.2696,  1.2236, -1.0821, -1.9058,  2.4133, -0.2128, -1.4137,  1.0538],\n",
            "        [-1.8412,  1.0228, -1.8319, -2.0715,  3.1937, -0.8917, -1.7072,  2.1110],\n",
            "        [-2.1573,  1.4400, -2.2762,  0.8092,  2.0743, -1.7575, -1.4551,  2.0713],\n",
            "        [-1.8401,  6.5198, -1.5575, -2.1169,  0.3481, -1.1903, -1.8895,  0.2443],\n",
            "        [-1.1419,  1.9495, -1.4215, -1.5318,  1.5724, -0.5896, -1.9017,  1.6307],\n",
            "        [-0.8755, -1.0513,  1.8818, -0.6997,  0.1971,  2.6019, -0.7871, -0.4287],\n",
            "        [-1.8675,  0.3501,  0.3491, -0.9794,  1.5168,  0.2175, -0.1569, -0.0086]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.0515,  3.0811, -2.2847, -2.6751,  3.3719, -0.7882, -2.0243,  0.8504],\n",
            "        [ 0.7293,  0.8888, -0.6098, -0.8205,  0.9766,  0.2350, -1.4226, -0.7497],\n",
            "        [-0.8915, -1.4875,  0.4143, -1.8044,  5.8828, -0.0578, -0.7815, -1.0275],\n",
            "        [ 0.0186, -1.6564,  2.4392, -1.4745, -0.1711,  2.3466, -0.6151, -0.3972],\n",
            "        [-1.8698,  2.6039, -1.8866, -2.4545,  3.4592, -0.0285, -1.7835,  0.1408],\n",
            "        [-1.6572,  0.4371, -1.5583, -2.3527,  3.8740, -0.2204, -1.2801,  1.4482],\n",
            "        [-0.4228,  1.1565, -0.1533, -1.4421,  1.1483,  0.6036, -1.3658,  0.0806],\n",
            "        [-1.2885,  1.6865, -1.5489, -1.4375,  2.1400, -0.1997, -1.6343,  0.9424],\n",
            "        [-1.4841, -0.9475,  2.3021, -0.5807, -0.9834,  3.7269, -0.1326, -1.1376],\n",
            "        [-1.9511,  5.2306, -1.5028, -1.9917,  0.5429, -0.5716, -2.3361,  0.8096],\n",
            "        [-1.3285,  1.2924, -2.3017, -2.3315,  3.7060,  0.3016, -1.4203,  0.2851],\n",
            "        [-1.9187,  0.3752, -1.7763, -1.7304,  3.2500, -0.9478, -1.0485,  2.2825],\n",
            "        [-2.3387,  3.2940, -1.9035, -1.8651,  1.7101, -1.2459, -1.7946,  1.5524],\n",
            "        [-1.2286,  0.8213, -0.5465, -1.1514,  1.6075,  0.4204, -1.0279,  0.5101],\n",
            "        [-1.1627, -1.2880,  0.8863, -1.5476,  1.2142,  2.2731, -0.8181,  0.6333],\n",
            "        [-1.8631, -0.2734,  0.0718, -0.7044, -0.5764,  6.7180, -1.0139, -1.0605],\n",
            "        [-0.4336, -0.7877,  1.0179, -1.0680,  0.8641,  1.3616, -0.5074, -0.1561],\n",
            "        [-0.3327, -0.5930,  0.5016, -0.9340,  0.9497,  0.6860, -0.8369,  0.3188],\n",
            "        [-1.4449, -0.4791, -0.0423, -0.6603, -0.6058,  6.5197, -1.2154, -0.9568],\n",
            "        [-1.8073, -0.5857,  5.4123, -2.1114, -0.5209, -0.2959, -0.7538,  0.0580],\n",
            "        [-1.2470, -0.4846,  0.6313, -0.9625,  1.0862,  1.4798, -0.6015,  0.1669],\n",
            "        [-1.2079,  0.0557, -0.0109, -0.9924,  1.4633,  1.2296, -0.3532, -0.3973],\n",
            "        [-1.1844, -0.5041,  0.2310, -0.9804, -0.0954,  5.4179, -1.4086, -1.0307],\n",
            "        [-1.7602,  6.7481, -1.7696, -2.3240,  0.4772, -1.5280, -2.1100, -0.2685],\n",
            "        [-1.4538,  2.9650, -2.6492, -2.1364,  1.2531, -0.7091, -2.4944,  3.1931],\n",
            "        [-0.2190, -0.7980,  0.3519, -1.1845,  2.1357,  0.2790, -0.6258,  0.0684],\n",
            "        [ 0.4320,  0.3879,  0.1156, -1.4767,  1.3185,  0.5716, -1.2752, -0.3087],\n",
            "        [-1.7100,  0.1038, -1.2509, -1.7834,  3.3019, -0.1343, -1.0846,  1.7363],\n",
            "        [ 0.2628,  0.3060, -0.6327, -0.7388,  1.0116,  0.5589, -1.3276,  0.2498],\n",
            "        [-0.4023,  0.3497, -0.0768, -1.4435,  1.3622,  0.4525, -1.2692,  0.3100],\n",
            "        [-1.6929, -0.6746, -0.6195, -1.6676,  3.1230,  0.1822, -0.3253,  0.9260],\n",
            "        [-1.1695,  0.2274, -0.7306, -1.6600,  2.2239,  0.0245, -1.1206,  1.0946]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.7349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.3144, -0.9505,  3.0054, -1.4198, -1.2013,  2.1988, -0.7145, -0.7194],\n",
            "        [ 6.0241, -0.0465, -1.6348, -0.1727, -0.7349, -1.1029, -1.4943, -1.2213],\n",
            "        [-1.0072, -1.4061,  0.0545, -2.0186,  5.7372, -0.1239, -0.1444, -1.1034],\n",
            "        [-2.2420,  3.8171, -2.5758, -2.5300,  3.3351, -1.1370, -2.4018,  1.2072],\n",
            "        [-0.9603,  0.3617,  1.4386, -0.9565, -0.3100,  1.8921, -0.4555, -0.8521],\n",
            "        [-0.9483,  1.2017, -1.0198, -1.3421,  1.8101, -0.2020, -0.9344,  0.5982],\n",
            "        [-1.2122, -0.2624, -1.0299, -1.7658,  0.5257, -0.6747, -2.3116,  5.3711],\n",
            "        [-2.5766,  3.2844, -2.1238, -1.7474,  2.1222, -0.9356, -2.0455,  1.8111],\n",
            "        [-1.7997,  0.3958, -1.0973, -1.9386,  3.4210, -0.5363,  0.0247,  0.5400],\n",
            "        [-0.8826,  1.6918, -1.8932, -1.4469,  1.4246, -1.1657, -2.1767,  2.5942],\n",
            "        [-1.2075, -0.4860, -1.3566,  4.7280,  0.6256, -1.2631, -0.5020, -0.7824],\n",
            "        [-1.3102, -0.0312, -0.7625, -1.8008,  2.4188,  0.0959, -1.1414,  1.2467],\n",
            "        [-2.0611,  2.1063, -1.7011, -0.6498,  1.8384, -0.6582, -1.5142,  1.2251],\n",
            "        [-2.1292,  0.3059, -1.6214, -1.9252,  4.0003, -0.9398, -0.7671,  1.8250],\n",
            "        [-1.0847,  0.7716, -1.0497, -1.6460,  2.5021, -0.3348, -1.4884,  1.3574],\n",
            "        [-0.7080, -0.3647,  0.0300,  0.1216,  1.3345,  0.2476, -0.5770, -0.1408],\n",
            "        [-0.4180,  0.5512, -0.2894, -1.1953,  1.3031,  0.1941, -0.8371,  0.2663],\n",
            "        [-1.3632, -0.3818, -0.3217, -0.6583,  1.1461,  2.8338, -0.7685, -0.6043],\n",
            "        [-1.1843, -0.5383,  0.1044, -0.5905,  1.9729,  0.3519, -0.2784,  0.1634],\n",
            "        [-1.0467, -1.5325,  0.2455, -2.0373,  5.6564,  0.2482, -0.6631, -1.1566],\n",
            "        [-1.5543, -0.2597, -1.6372, -0.7318,  1.6401, -0.4609,  0.1476,  2.1679],\n",
            "        [-1.3242, -0.9234, -0.1539, -2.5758,  5.8084,  0.3620, -0.5843, -1.1758],\n",
            "        [ 0.5363, -1.2810,  1.7497, -0.8279, -0.6683,  1.9538, -0.7629, -0.6613],\n",
            "        [-1.2524,  0.4116, -1.5745, -2.7970,  4.9802, -0.0380, -0.6422, -0.6067],\n",
            "        [-2.4423,  1.7086, -2.4335, -2.0952,  3.5049, -0.9085, -1.5130,  1.9298],\n",
            "        [-2.3194, -0.6308, -1.3328, -2.3558,  4.3398, -0.1582,  0.1843,  0.7483],\n",
            "        [-1.1881, -1.3635, -0.0458, -2.0413,  5.4977, -0.3052, -0.3091, -0.8827],\n",
            "        [-1.4360, -1.2130, -0.3204, -1.9969,  5.4929,  0.2512, -0.1032, -0.7289],\n",
            "        [-0.7291,  1.1197, -1.1194,  1.0134,  0.7449, -0.4769, -0.3174, -0.8607],\n",
            "        [ 2.2145, -1.3474,  2.3431, -2.2018,  0.3314,  0.6849, -0.9387, -1.0519],\n",
            "        [-2.4573,  5.6415, -2.4449, -1.8544,  1.4335, -1.4513, -2.2389,  0.2034],\n",
            "        [-1.2096,  2.5007, -0.9813, -1.3661,  1.5187, -0.5071, -1.6648,  0.8014]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2862, -0.2699,  0.2391, -1.2817,  1.6026,  0.6954, -0.2826,  0.3346],\n",
            "        [ 0.7401, -1.2321,  1.3366, -1.2046,  0.7200,  0.8730, -0.8475, -0.4808],\n",
            "        [-0.4019, -1.2273,  0.8130, -0.3627,  1.2104,  1.0112, -0.4039, -0.2468],\n",
            "        [-0.6059,  0.6695,  0.3364, -0.9238,  0.7106, -0.2912, -0.6501,  0.2809],\n",
            "        [-0.4677,  0.6830, -0.6531, -1.5982,  2.0916,  0.1166, -1.1531,  0.1919],\n",
            "        [-2.2855,  1.3552, -2.0686, -2.4825,  4.2490, -0.4489, -1.0915,  0.4943],\n",
            "        [-2.0947,  0.0679, -1.4626, -1.4224,  2.8522, -0.4664, -1.2674,  2.0499],\n",
            "        [-0.4878, -1.0661,  1.0603, -0.5669,  0.8791,  0.6304, -0.3756, -0.0752],\n",
            "        [-0.9661, -1.3108, -0.1317, -2.2789,  5.9742, -0.1491, -0.7694, -1.1084],\n",
            "        [-0.7858, -0.9268,  1.8060, -1.1478, -0.2222,  1.5805, -0.5307,  0.4889],\n",
            "        [-1.2833, -1.1068, -0.2357, -2.4678,  5.8093,  0.2423, -0.5316, -1.2760],\n",
            "        [-0.4678, -0.3910,  0.4140, -0.8814,  0.3004,  1.7688, -1.0831,  0.5215],\n",
            "        [-0.5840,  1.3806, -1.4569, -1.9899,  2.1328,  0.0574, -1.6525,  1.3518],\n",
            "        [ 0.0431, -0.1989,  0.3565, -1.5609,  1.1043,  0.3739, -0.9799,  0.6110],\n",
            "        [-1.7478,  1.7439, -1.8510, -2.3825,  3.2153, -0.0299, -1.2729,  0.8412],\n",
            "        [-1.9506,  2.2875, -2.0560, -1.8033,  2.8282, -1.0125, -1.6833,  1.5225],\n",
            "        [-1.0098, -0.3805,  0.1571, -1.4715,  1.7494,  0.7465, -0.5817,  0.4614],\n",
            "        [-1.8237,  2.0739, -1.8638, -2.0189,  2.7325, -1.3090, -1.9904,  2.1826],\n",
            "        [-2.1948,  0.6729, -0.9665, -1.5006,  2.5837, -0.1125, -0.8400,  1.4496],\n",
            "        [-1.6100,  0.6035,  0.0742, -0.9195,  0.6242,  0.2603,  0.7939,  0.0812],\n",
            "        [-1.4400,  1.3141, -1.1963, -1.9608,  2.5331, -0.4400, -0.8126,  0.4383],\n",
            "        [-2.0705,  0.4268, -1.8189, -2.1692,  3.7928, -0.6219, -1.2015,  1.8998],\n",
            "        [ 0.2454, -0.7170,  0.2776, -1.3370,  1.6935,  0.7560, -0.9458,  0.0612],\n",
            "        [-0.8085, -1.2960,  0.6130, -0.0780, -0.8736,  6.3092, -1.1532, -1.0653],\n",
            "        [-0.9070, -0.8774, -1.0215,  3.7408,  0.6416, -0.5597, -0.3119, -0.9751],\n",
            "        [-1.4805,  0.2954, -0.1393, -1.5635,  2.3987,  0.6215, -0.3449,  0.0715],\n",
            "        [-0.3398,  0.6792, -1.0837, -0.7835,  1.8278,  0.1915, -1.0519,  0.0369],\n",
            "        [-0.2995, -0.2994,  4.1138, -2.6677, -1.0047,  0.5700, -0.3141, -0.3508],\n",
            "        [-1.8288,  5.4936, -2.0071, -1.5745,  0.9886, -0.8480, -2.1522,  0.2407],\n",
            "        [-1.8930,  1.5314, -1.9236, -2.4677,  3.8703, -0.4364, -1.3108,  0.9375],\n",
            "        [-1.4008, -0.2195, -0.6107, -1.8387,  1.4704, -0.2335, -1.5846,  2.9658],\n",
            "        [-2.2420,  3.6659, -2.1369, -1.7352,  2.0694, -1.0180, -1.7449,  1.3434]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.8796, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6179e+00,  1.8989e+00, -1.8417e+00, -2.5753e+00,  3.7312e+00,\n",
            "          4.9565e-01, -1.3175e+00, -1.1638e-01],\n",
            "        [-2.3116e+00,  4.1267e+00, -2.3807e+00, -1.8466e+00,  1.6867e+00,\n",
            "         -1.3404e+00, -2.0508e+00,  1.4542e+00],\n",
            "        [-1.7299e+00,  4.9677e-01, -2.1174e+00, -2.4884e+00,  4.0660e+00,\n",
            "         -2.3120e-01, -1.0058e+00,  1.1869e+00],\n",
            "        [-2.2336e+00,  3.3123e+00, -1.9310e+00, -2.0873e+00,  1.8634e+00,\n",
            "         -9.4910e-01, -2.1855e+00,  1.9563e+00],\n",
            "        [-1.6445e+00,  6.7122e-01, -1.2600e+00, -1.4349e+00,  2.7625e+00,\n",
            "         -5.8486e-01, -7.2426e-01,  9.1461e-01],\n",
            "        [-1.6632e+00,  2.6054e-01, -7.3647e-01, -1.9728e+00,  2.2802e+00,\n",
            "         -5.2043e-01, -8.4191e-01,  1.8307e+00],\n",
            "        [-1.3972e+00, -2.2546e-01, -1.0794e+00, -1.8530e+00,  3.1409e+00,\n",
            "         -4.7044e-01, -1.0574e+00,  1.5984e+00],\n",
            "        [-7.2721e-01,  6.2608e-01, -3.5813e-01, -1.2743e+00,  1.2134e+00,\n",
            "          1.8875e-01, -1.2279e+00,  5.2421e-01],\n",
            "        [-9.2437e-01,  2.3237e+00, -9.4313e-01, -1.2379e+00,  1.1944e+00,\n",
            "         -1.8272e-01, -1.9366e+00,  7.5972e-01],\n",
            "        [-8.9445e-01, -8.1448e-01,  5.3815e-01, -8.0741e-01,  1.0011e+00,\n",
            "          6.2252e-01,  1.5744e+00, -3.7067e-01],\n",
            "        [ 3.1790e-01, -1.0967e+00,  6.2237e-01, -1.2312e+00,  1.1657e+00,\n",
            "          8.2065e-01, -1.4403e+00,  6.3293e-02],\n",
            "        [-6.9888e-01,  2.6235e+00, -5.7626e-01, -1.1727e+00,  8.6357e-01,\n",
            "         -1.1437e-01, -1.5788e+00,  1.9147e-01],\n",
            "        [-3.6450e-01,  2.5864e-01, -3.3761e-01, -1.3594e+00,  2.2204e+00,\n",
            "         -6.5752e-03, -1.3266e+00,  2.9130e-01],\n",
            "        [-2.0076e+00,  6.8843e+00, -1.6477e+00, -1.1889e+00, -8.0318e-01,\n",
            "         -2.0320e+00, -1.2737e+00,  1.8514e-01],\n",
            "        [-1.4969e+00, -5.0768e-01, -1.5880e+00, -1.1976e+00,  6.0961e-01,\n",
            "         -1.3980e+00, -1.5168e+00,  5.5715e+00],\n",
            "        [-1.6046e+00,  6.7590e+00, -1.4599e+00, -1.3755e+00, -5.2023e-01,\n",
            "         -1.3538e+00, -1.6899e+00,  4.3578e-01],\n",
            "        [-1.2251e+00, -1.5084e+00,  1.9374e-01, -1.9519e+00,  5.7963e+00,\n",
            "          5.2228e-01, -4.7872e-01, -1.4816e+00],\n",
            "        [-1.1280e+00,  9.5605e-01, -1.6212e+00, -2.0603e+00,  2.7345e+00,\n",
            "         -3.3431e-02, -1.4333e+00,  1.0668e+00],\n",
            "        [-1.5683e+00,  1.9658e+00, -1.2099e+00, -1.1717e+00,  1.7636e+00,\n",
            "         -5.0079e-01, -1.0680e+00,  6.6644e-01],\n",
            "        [-1.3141e+00, -6.8923e-01,  1.2577e+00,  3.2871e-01,  7.9431e-01,\n",
            "          8.0426e-01, -2.5319e-01, -6.3163e-01],\n",
            "        [-6.4699e-01, -1.1097e+00,  1.0977e+00, -6.2897e-01,  5.1243e-01,\n",
            "          2.2926e+00, -7.9878e-01, -3.3478e-01],\n",
            "        [-1.9273e+00, -4.4304e-01, -3.3183e-01, -1.6278e+00,  2.5708e+00,\n",
            "         -2.6342e-02,  8.3484e-01,  5.3027e-01],\n",
            "        [-1.4632e+00, -1.8348e-01, -1.9035e-01, -8.6927e-01,  2.1606e+00,\n",
            "          4.6170e-01, -7.3774e-01,  3.9882e-01],\n",
            "        [-8.9379e-01,  8.3368e-01, -4.5359e-01, -1.6923e+00,  2.0172e+00,\n",
            "          4.4125e-01, -1.0312e+00,  2.3364e-01],\n",
            "        [-1.7198e+00, -4.7693e-01,  1.9471e-01, -1.0911e+00, -6.5622e-01,\n",
            "          6.5863e+00, -1.2565e+00, -8.2914e-01],\n",
            "        [-9.6733e-01, -1.3072e+00, -1.3353e-02, -2.0338e+00,  5.9915e+00,\n",
            "         -9.5985e-02, -8.8745e-01, -1.1976e+00],\n",
            "        [-1.0668e+00, -1.3032e+00,  8.4745e-01, -1.0265e+00,  7.4216e-01,\n",
            "          7.5130e-01, -3.4893e-01,  7.4419e-01],\n",
            "        [ 1.5298e-03,  9.5958e-01, -4.3306e-01, -1.0989e+00,  1.2722e+00,\n",
            "         -9.9936e-02, -1.4971e+00, -1.7611e-01],\n",
            "        [ 3.2229e-01, -7.7679e-01,  7.7740e-01, -5.1253e-01,  1.2171e-01,\n",
            "          1.2776e+00, -8.0748e-01, -1.3713e-01],\n",
            "        [-8.9540e-01,  5.4509e-01, -1.3043e+00, -7.9015e-01, -9.1400e-01,\n",
            "         -9.7861e-01, -1.3505e+00,  4.6994e+00],\n",
            "        [-1.5902e+00,  2.6464e+00, -1.5360e-01, -2.0813e+00,  3.4123e-02,\n",
            "          7.6270e-01, -2.0461e+00,  6.0486e-01],\n",
            "        [-9.9058e-01,  5.4066e-01, -1.1017e-01, -8.4286e-01,  1.3669e+00,\n",
            "          2.8932e-01, -5.8541e-01,  3.5310e-02]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.9881e+00,  1.3108e+00, -1.6647e+00, -1.3794e+00,  2.7420e+00,\n",
            "         -6.6877e-01, -1.1115e+00,  1.2804e+00],\n",
            "        [-2.0622e+00,  1.3902e+00, -2.5033e+00, -2.5653e+00,  4.0231e+00,\n",
            "         -8.3372e-01, -1.9535e+00,  1.9844e+00],\n",
            "        [-8.7133e-01,  3.1511e-01, -7.4891e-01, -1.1785e+00,  2.0660e+00,\n",
            "          1.9001e-01, -3.6454e-01,  1.6866e-02],\n",
            "        [-9.5384e-01, -2.5057e-01, -1.7542e-01, -1.9066e+00,  2.4944e+00,\n",
            "          1.5919e-01, -1.0625e+00,  8.7087e-01],\n",
            "        [-1.1848e+00, -1.1722e+00, -2.7597e-01, -2.2841e+00,  5.7967e+00,\n",
            "          3.7802e-01, -8.0355e-01, -1.3083e+00],\n",
            "        [-1.6909e+00, -6.5776e-01, -1.3803e-01,  1.5648e+00,  1.3286e+00,\n",
            "          4.4710e-01,  4.6337e-01, -5.9550e-01],\n",
            "        [-1.1650e+00,  1.9132e-01, -4.0537e-02, -1.2614e+00,  1.6274e+00,\n",
            "          1.9439e-01, -6.8318e-01,  6.2248e-01],\n",
            "        [-1.3270e+00, -2.6054e-01, -5.1600e-01,  3.1616e+00,  3.4417e-01,\n",
            "         -2.9942e-01,  8.7926e-01, -9.2866e-01],\n",
            "        [-1.8090e+00, -5.0993e-01, -1.4578e+00, -7.2398e-01,  4.2312e-01,\n",
            "         -1.0911e+00, -1.6441e+00,  5.2824e+00],\n",
            "        [-9.9284e-01,  5.5463e-01, -1.8645e-01, -1.4386e+00,  1.6326e+00,\n",
            "          1.1018e-01, -1.1771e+00,  7.6262e-01],\n",
            "        [-2.1471e+00,  8.0768e-01, -2.0975e+00, -2.2829e+00,  2.5775e+00,\n",
            "         -1.0724e+00, -1.8819e+00,  4.0779e+00],\n",
            "        [-2.1324e+00, -2.4114e-01, -3.4550e-01, -1.3253e+00,  2.1682e+00,\n",
            "          4.8663e-01, -9.0230e-01,  1.6232e+00],\n",
            "        [ 2.5226e-01, -1.5197e+00,  1.7136e+00, -4.9620e-01, -2.7928e-01,\n",
            "          1.6370e+00, -4.5746e-01, -3.1539e-01],\n",
            "        [-8.7422e-01,  2.4623e-01, -4.3664e-01, -7.7727e-01,  1.3447e-01,\n",
            "          4.1768e-01, -9.2806e-01,  1.4488e+00],\n",
            "        [-1.9130e+00, -5.6688e-03, -1.1771e+00, -2.4437e+00,  4.5066e+00,\n",
            "          2.5598e-01, -6.0549e-01,  2.6538e-01],\n",
            "        [-1.3505e+00,  2.0423e+00, -1.6787e+00, -1.2947e+00,  2.2387e+00,\n",
            "         -8.7411e-01, -1.7374e+00,  1.2398e+00],\n",
            "        [-1.3478e+00,  2.3360e-01, -1.0572e+00, -2.0360e+00,  2.3825e+00,\n",
            "         -9.2010e-02, -1.7329e+00,  2.2584e+00],\n",
            "        [ 2.0558e-01, -1.0164e+00,  1.3023e+00, -1.7988e+00,  4.7973e-01,\n",
            "          1.7597e+00, -9.3641e-01, -3.4572e-02],\n",
            "        [-1.4362e+00,  4.5285e-01, -1.5404e+00, -2.3573e+00,  3.3726e+00,\n",
            "          8.6181e-02, -3.8000e-01,  6.2222e-01],\n",
            "        [-1.9858e+00,  1.1545e+00, -1.3381e+00, -2.2385e+00,  2.5251e+00,\n",
            "         -5.0327e-01, -1.1841e+00,  1.9985e+00],\n",
            "        [-7.6815e-01,  2.2855e-01, -6.1501e-01, -1.2308e+00,  1.9718e+00,\n",
            "          4.1372e-01, -9.5341e-01,  3.0013e-01],\n",
            "        [-2.1295e+00,  1.7219e+00, -1.6711e+00, -2.2742e+00,  3.0161e+00,\n",
            "         -8.2141e-01, -1.1295e+00,  1.3718e+00],\n",
            "        [-1.4695e+00,  6.8068e+00, -1.8161e+00, -2.1963e+00,  1.9126e-01,\n",
            "         -1.5470e+00, -2.2968e+00, -7.8076e-02],\n",
            "        [-1.7736e+00,  1.8104e+00, -1.8033e+00, -2.4630e+00,  3.8092e+00,\n",
            "          2.5225e-01, -1.3385e+00,  1.3005e-01],\n",
            "        [-9.9156e-01,  1.3089e+00, -4.6169e-01, -1.9031e+00,  8.2114e-01,\n",
            "         -1.9204e-01, -1.6202e+00,  2.0162e+00],\n",
            "        [-1.1496e+00,  2.2041e-02, -8.1791e-01,  2.5395e+00,  4.2204e-01,\n",
            "         -5.2329e-01,  5.2354e-01, -8.2943e-01],\n",
            "        [-1.3657e+00, -6.8386e-01,  4.5039e-01, -1.2453e+00,  1.8975e+00,\n",
            "          9.3157e-01, -1.3958e-01, -1.4643e-01],\n",
            "        [-1.2995e+00, -9.8939e-02, -1.0967e+00,  1.4650e+00,  1.3567e+00,\n",
            "         -3.5531e-01, -6.7464e-01, -1.4057e-01],\n",
            "        [-7.7919e-01,  1.2251e+00,  3.2199e-01, -7.2523e-01,  3.4099e-01,\n",
            "         -1.0397e-01, -9.5633e-01, -1.6204e-01],\n",
            "        [-1.6672e+00,  2.5995e+00, -1.9059e+00, -1.5218e+00,  1.9842e+00,\n",
            "         -5.8870e-01, -1.4298e+00,  1.1390e+00],\n",
            "        [-1.5476e+00,  2.4081e+00, -1.0106e+00, -1.7643e+00,  1.5115e+00,\n",
            "         -7.0160e-01, -8.7953e-01,  4.5471e-01],\n",
            "        [ 2.7927e-01,  8.2119e-01, -1.8903e-01, -5.4703e-01,  2.7461e-01,\n",
            "          1.0277e+00, -1.1733e+00, -5.4061e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6458e+00,  6.4556e+00, -1.4952e+00, -1.7377e+00, -2.3401e-01,\n",
            "         -1.2400e+00, -2.1611e+00,  2.4789e-01],\n",
            "        [-5.1838e-01, -1.4137e+00,  1.5983e+00, -6.2834e-01,  4.3138e-01,\n",
            "          2.0482e+00, -4.0553e-01, -6.9989e-01],\n",
            "        [-1.0661e+00,  1.0905e+00, -1.2835e+00, -1.6418e+00,  1.8397e+00,\n",
            "         -4.0080e-01, -1.5371e+00,  2.0586e+00],\n",
            "        [-2.8198e-01, -3.9917e-01,  3.6930e-01, -1.4716e+00,  1.6059e+00,\n",
            "          5.8287e-01, -6.0056e-01, -2.5232e-01],\n",
            "        [-1.9482e+00,  4.4361e+00, -1.7383e+00, -1.8333e+00,  1.3315e+00,\n",
            "         -1.0695e+00, -1.8444e+00,  1.1010e-01],\n",
            "        [-2.4273e+00,  3.1373e-01, -1.8942e+00, -2.1763e+00,  4.3115e+00,\n",
            "         -3.0205e-01, -9.3291e-01,  1.6785e+00],\n",
            "        [-8.7133e-01,  3.2573e-03,  1.8085e-01, -9.6703e-01,  1.2624e+00,\n",
            "          7.8167e-01, -6.9031e-01,  1.8030e-01],\n",
            "        [-9.5319e-01, -5.5937e-01,  8.2910e-01, -1.5142e+00,  8.9099e-01,\n",
            "          1.1555e+00, -6.4230e-01,  5.7385e-01],\n",
            "        [-8.7831e-01, -1.2465e+00, -6.2090e-02, -2.1851e+00,  5.7369e+00,\n",
            "          3.8171e-01, -6.7785e-01, -1.2142e+00],\n",
            "        [-2.8105e+00,  3.2666e+00, -2.3565e+00, -1.4011e+00,  2.7862e-01,\n",
            "         -4.7441e-01, -2.0729e+00,  3.9936e+00],\n",
            "        [-5.4286e-01,  7.6376e-01, -4.4254e-01, -9.7129e-01,  1.6096e+00,\n",
            "          1.1644e-01, -1.4448e+00,  3.9798e-01],\n",
            "        [ 6.4544e-02, -1.5129e-02,  5.2400e-01, -1.9109e+00,  1.2571e+00,\n",
            "         -5.3122e-01, -1.3650e+00,  9.2701e-01],\n",
            "        [-1.0371e+00, -7.0340e-01, -6.0101e-01, -2.4648e+00,  6.0439e+00,\n",
            "          1.5685e-01, -1.0771e+00, -1.3301e+00],\n",
            "        [ 1.1967e+00, -6.8675e-01,  6.5122e-01, -7.0603e-01,  1.9439e-01,\n",
            "          1.7703e+00, -1.3291e+00, -7.6919e-01],\n",
            "        [-4.7677e-01, -9.0906e-01,  7.0771e-01, -1.6193e+00,  1.4233e+00,\n",
            "          1.4125e+00, -1.0869e+00,  3.6529e-01],\n",
            "        [-1.0979e+00, -1.0418e+00,  1.1567e+00, -1.2429e+00,  1.1005e+00,\n",
            "          1.7332e+00, -4.2462e-01, -2.6474e-01],\n",
            "        [-1.4699e+00,  2.3980e+00, -1.0669e+00, -8.6242e-01,  1.3808e+00,\n",
            "         -3.1378e-01, -1.6132e+00,  6.0355e-01],\n",
            "        [-2.9741e-01, -4.6801e-02,  8.8574e-02, -6.0059e-01,  1.1862e+00,\n",
            "          6.4564e-01, -7.5985e-01, -5.9350e-02],\n",
            "        [-5.6615e-01,  7.9460e-02,  6.5914e-01, -8.8936e-01,  1.2111e+00,\n",
            "         -2.9974e-01, -4.4555e-01,  6.9739e-02],\n",
            "        [-1.7784e+00,  4.2070e+00, -2.0916e+00, -8.5925e-01,  7.1206e-01,\n",
            "         -8.3749e-01, -2.1071e+00,  9.8855e-01],\n",
            "        [ 1.0312e-02, -3.3264e-01, -3.4428e-01, -1.4595e+00,  1.5140e+00,\n",
            "          8.2365e-01, -1.3853e+00,  6.9702e-01],\n",
            "        [-2.1415e+00,  5.1795e-01, -1.4147e+00, -1.4473e+00,  2.5935e+00,\n",
            "         -2.9376e-01, -1.0222e+00,  2.4227e+00],\n",
            "        [ 6.1537e-01,  8.7168e-01, -3.2688e-01, -5.1491e-01,  9.3902e-02,\n",
            "          1.0215e+00, -1.4479e+00, -5.2974e-01],\n",
            "        [-1.4181e+00, -1.2922e+00,  1.8500e+00, -5.6068e-01, -3.5174e-01,\n",
            "          3.4285e+00, -3.0376e-01, -7.8413e-01],\n",
            "        [-8.9079e-01, -1.8733e-01, -8.4915e-01, -2.0257e+00,  2.8954e+00,\n",
            "          4.2123e-01, -1.3433e+00,  1.2100e+00],\n",
            "        [-2.0874e+00,  1.8570e+00, -2.5689e+00, -2.6256e+00,  3.8217e+00,\n",
            "         -8.0261e-01, -1.2601e+00,  1.3080e+00],\n",
            "        [-1.1939e+00,  2.7728e+00, -1.0253e+00, -6.8032e-01,  6.9022e-01,\n",
            "         -9.4324e-01, -1.5182e+00,  8.6073e-01],\n",
            "        [-1.5938e+00,  3.3376e-01,  3.2388e-01, -1.0176e+00,  1.0749e+00,\n",
            "          7.1786e-01, -4.3008e-01,  1.2614e-01],\n",
            "        [-5.7055e-01,  3.9831e+00, -1.0851e+00, -1.5071e+00,  5.8846e-01,\n",
            "         -4.3384e-01, -2.3930e+00,  2.6130e-01],\n",
            "        [-1.9514e+00,  7.0867e+00, -1.9637e+00, -1.7698e+00, -3.6624e-01,\n",
            "         -1.4582e+00, -1.6110e+00, -7.7968e-02],\n",
            "        [-1.5870e+00,  3.8562e-02, -1.5546e+00,  4.9088e+00,  8.9637e-02,\n",
            "         -1.2342e+00, -5.4678e-01, -8.9606e-01],\n",
            "        [-1.1839e+00,  7.8411e-01, -1.6620e+00, -2.0209e+00,  2.6019e+00,\n",
            "         -4.8039e-01, -1.2705e+00,  2.0111e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(0.9300, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6109e+00, -9.0151e-01,  5.1080e+00, -1.5884e+00, -6.5595e-01,\n",
            "          5.4156e-01, -9.1789e-01, -1.8965e-01],\n",
            "        [-1.1250e+00,  4.0701e+00, -1.9761e+00, -9.3666e-01,  1.4613e+00,\n",
            "         -5.8986e-01, -2.5905e+00,  4.1906e-01],\n",
            "        [-1.9027e+00, -5.7530e-01,  5.9067e+00, -1.4523e+00, -8.2821e-01,\n",
            "         -1.1694e-01, -5.3698e-01, -2.3057e-01],\n",
            "        [-1.6867e+00,  2.0992e-01, -5.2870e-01, -1.7414e+00,  2.5395e+00,\n",
            "          2.6772e-01, -3.3027e-01,  9.3612e-01],\n",
            "        [-7.4921e-01, -4.6466e-01,  4.4008e-01, -5.6984e-01,  1.0537e+00,\n",
            "          1.4213e+00, -7.5081e-01, -1.6662e-01],\n",
            "        [-9.9199e-01, -5.9082e-02, -2.5863e-01, -1.4192e+00,  2.3129e+00,\n",
            "          6.1803e-01, -9.3560e-01,  4.6984e-01],\n",
            "        [-1.1203e+00, -4.6533e-01, -4.5911e-01, -2.1519e+00,  5.3858e+00,\n",
            "          5.7004e-01, -7.2102e-01, -1.2161e+00],\n",
            "        [-9.2965e-01,  1.6260e+00, -9.6667e-01, -1.6565e+00,  1.3592e+00,\n",
            "          3.1453e-01, -1.7324e+00,  1.0077e+00],\n",
            "        [-1.1382e+00, -2.3640e-01, -1.0751e+00, -2.7843e+00,  5.8459e+00,\n",
            "          7.3617e-01, -1.4145e+00, -1.0542e+00],\n",
            "        [-1.6677e+00,  1.7752e+00, -1.7258e+00, -1.5335e+00,  2.1977e+00,\n",
            "         -7.1995e-01, -8.2265e-01,  1.1541e+00],\n",
            "        [-1.8090e+00, -2.4865e-01, -5.6228e-01, -9.8914e-01,  2.4200e+00,\n",
            "          3.1889e-01, -1.0178e+00,  1.2242e+00],\n",
            "        [-6.5721e-01, -5.9868e-01,  1.5878e+00, -6.5558e-01, -1.0192e+00,\n",
            "          2.1098e+00, -2.1565e-01, -5.4004e-01],\n",
            "        [-8.8504e-01, -4.8747e-01, -1.8580e+00, -1.4322e+00,  9.3197e-01,\n",
            "         -1.4935e+00, -1.8330e+00,  5.5270e+00],\n",
            "        [-1.0798e+00, -3.0290e-01,  9.1147e-02, -1.5537e+00,  1.0017e+00,\n",
            "          2.0164e-01, -9.9742e-01,  2.0596e+00],\n",
            "        [-1.4501e-01, -9.2670e-01,  2.8322e-01, -1.0962e+00,  1.0155e+00,\n",
            "          1.1955e+00, -9.4668e-01,  2.8776e-01],\n",
            "        [-6.7125e-01,  1.0080e-01, -3.3708e-01, -1.0829e+00,  1.6881e+00,\n",
            "          4.0408e-01, -9.3425e-01,  3.5055e-01],\n",
            "        [-6.7483e-01, -1.1587e+00,  2.5832e+00, -6.6898e-01, -9.4384e-01,\n",
            "          2.0613e+00, -3.6148e-01, -3.2326e-01],\n",
            "        [-1.3745e+00, -5.8599e-01, -7.8801e-01, -2.4044e+00,  5.5886e+00,\n",
            "         -1.0788e-02, -6.6554e-01, -6.4182e-01],\n",
            "        [-1.4590e+00, -5.2402e-03, -1.7622e-01, -1.2525e+00,  2.3400e+00,\n",
            "          3.4747e-01, -8.9568e-01,  6.9087e-01],\n",
            "        [-1.3024e+00,  6.7521e-01, -9.2236e-01, -1.6426e+00,  2.2424e+00,\n",
            "          6.3935e-01, -8.5327e-01,  6.9573e-01],\n",
            "        [-1.3669e+00,  1.4511e+00, -7.1947e-01, -7.0638e-01,  1.8941e+00,\n",
            "         -3.6860e-01, -1.1524e+00,  1.8827e-01],\n",
            "        [-2.2580e+00,  3.9744e+00, -2.3010e+00, -2.1128e+00,  2.4155e+00,\n",
            "         -9.3171e-01, -2.0435e+00,  8.2543e-01],\n",
            "        [-2.2473e+00, -1.0085e+00,  1.5566e+00, -5.8369e-01,  2.1097e-01,\n",
            "          3.2496e+00, -4.5989e-01, -3.6240e-01],\n",
            "        [-1.8848e+00,  4.1591e-01,  2.6204e-01, -9.5362e-01,  1.5771e+00,\n",
            "          1.1474e-01, -1.9752e-01,  1.3189e-01],\n",
            "        [-2.4747e-01, -1.6458e+00,  2.8928e+00, -3.8865e-01, -4.9358e-01,\n",
            "          1.6541e+00, -5.9833e-01, -8.9000e-01],\n",
            "        [-9.7003e-01, -9.4387e-01, -9.2703e-02, -1.3535e+00,  2.0685e+00,\n",
            "         -5.4609e-02, -7.5802e-01,  1.3453e+00],\n",
            "        [-2.0763e+00,  7.0284e+00, -1.9682e+00, -1.4989e+00, -6.0340e-01,\n",
            "         -1.6416e+00, -1.6839e+00,  5.8812e-02],\n",
            "        [-1.3000e+00,  4.1475e-01,  1.3251e-01, -2.2145e+00,  1.1995e+00,\n",
            "         -6.6557e-03, -7.6676e-01,  1.4468e+00],\n",
            "        [-1.0904e+00,  1.1974e-02, -1.0410e+00, -2.1495e+00,  3.0764e+00,\n",
            "          1.6576e+00, -1.1351e+00,  4.3494e-02],\n",
            "        [-1.0014e+00, -1.6726e+00,  2.7849e-01, -1.9412e+00,  5.9944e+00,\n",
            "          1.7626e-03, -7.1486e-01, -1.3819e+00],\n",
            "        [-1.1169e+00,  1.0364e+00, -1.8616e-01, -9.4799e-01,  1.1651e+00,\n",
            "         -2.6198e-01, -1.6621e+00,  1.3399e+00],\n",
            "        [-6.6050e-01, -1.1087e+00,  1.2187e+00, -6.5142e-01,  7.9775e-01,\n",
            "          1.9016e+00, -4.3196e-01, -5.7707e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2853, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1029,  1.5836, -1.1920, -1.8078,  2.1086,  0.0360, -1.4394,  0.8819],\n",
            "        [-1.9691,  1.8240, -2.0358, -2.4161,  3.0313, -0.5615, -1.8522,  2.2506],\n",
            "        [-1.2688, -0.3707, -0.6478, -1.9580,  2.4118, -0.2691, -1.0417,  1.8546],\n",
            "        [-2.1949, -0.0890, -1.1101, -1.8644,  3.8415, -0.1858, -0.0245, -0.1382],\n",
            "        [-1.1098, -0.0618,  1.7851, -1.6061,  0.7601,  0.3781, -0.6698,  0.5598],\n",
            "        [-1.7050, -0.3117, -1.1921, -0.9082,  0.0718, -1.1472, -1.6191,  5.3364],\n",
            "        [-1.7653,  0.5621, -0.8333,  1.8198,  1.4171, -0.2778, -0.1947, -0.2228],\n",
            "        [-1.7250,  1.2647, -1.3050, -1.1794,  2.4801, -0.0890, -0.7627,  0.3287],\n",
            "        [-1.0103,  1.2521, -0.2196, -1.0843,  0.1763, -0.4236, -0.9032,  1.7318],\n",
            "        [-2.1838,  3.5156, -1.8416,  0.3919,  0.6547, -0.9027, -1.6617,  1.0236],\n",
            "        [-1.1886, -0.3644,  0.5442, -1.5466,  1.3971,  0.4714, -0.2609,  0.6893],\n",
            "        [-0.1141, -0.5661,  0.3033, -0.1644,  1.4662,  0.3868, -0.5689, -0.5333],\n",
            "        [-1.7352,  3.5801, -1.9653, -2.4405,  2.8292, -0.2051, -2.1801,  0.2846],\n",
            "        [-1.0428, -0.2305,  0.8379, -1.6297,  0.8773,  0.1955, -0.9405,  1.6191],\n",
            "        [-2.1763,  4.8226, -2.1080, -2.0560,  1.3757, -0.9343, -2.2266,  0.7244],\n",
            "        [-2.6284,  3.0161, -2.8383, -2.3446,  3.6218, -1.1244, -1.9819,  1.5902],\n",
            "        [-1.4310,  0.2711, -0.2055, -1.2457,  1.8160,  1.1832, -0.7492,  0.0771],\n",
            "        [-0.9314,  1.5106, -0.8616, -1.3801,  1.4971, -0.2982, -0.7307,  0.7707],\n",
            "        [-0.8020, -1.0530, -0.4090, -1.4853,  2.6551,  0.7086, -0.7321,  0.5691],\n",
            "        [-1.6886,  1.0814, -1.2505, -1.7676,  2.6114, -0.3823, -0.8321,  0.9362],\n",
            "        [-1.0148, -0.7560,  1.9280, -0.3675, -0.6916,  2.6055, -0.1754, -1.1234],\n",
            "        [-1.5275,  1.2781, -1.2791,  2.3762,  0.5815, -0.9880, -0.7394, -0.0463],\n",
            "        [-1.9541,  1.2440, -1.1971, -1.6946,  2.1293, -0.1658, -1.4431,  1.6934],\n",
            "        [-0.8227,  1.0225,  0.2182, -0.5715, -0.3545,  1.5145, -0.2463, -0.2733],\n",
            "        [-1.3155, -0.3450,  0.1642, -1.3199,  1.7459,  1.0693, -0.3480,  0.2249],\n",
            "        [-1.9043,  0.2471, -0.9782, -1.0819,  3.2249, -0.1158, -0.4267,  0.4105],\n",
            "        [-1.9247, -0.2297, -0.5172, -1.2098,  2.8166,  0.0215, -0.3527,  0.6624],\n",
            "        [-1.8705,  4.3774, -2.1155, -1.1370,  1.1244, -1.1475, -2.4138,  0.7150],\n",
            "        [-1.8049,  1.3912, -0.4518, -1.7769,  1.4309, -0.5682, -0.7701,  1.5793],\n",
            "        [-1.9662,  3.5092, -1.7999, -2.1564,  2.1973, -0.7372, -1.6865,  0.8344],\n",
            "        [-1.0016, -0.6341, -1.5398,  4.6199,  0.5971, -0.8781, -0.7552, -1.0121],\n",
            "        [-0.6170, -0.0607, -0.0609, -1.3615,  1.3303,  0.4637, -0.8682,  0.5896]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.5935, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.3498,  0.5778, -0.9113, -1.4476,  1.4128, -0.2657, -1.5653,  2.4023],\n",
            "        [-1.1252, -1.2026,  1.6060, -1.1371,  0.4023,  2.2376, -0.4773, -0.1153],\n",
            "        [-1.9307,  0.1331,  1.2427, -0.2387,  0.1668,  1.8843,  0.0705, -0.5287],\n",
            "        [-1.6695,  2.8346, -1.2305, -1.4683,  1.6506, -0.6220, -1.5880,  0.9968],\n",
            "        [-2.0028, -0.1280,  0.4624, -0.3695,  1.1885,  0.8446, -0.5253,  0.1916],\n",
            "        [-0.2256, -0.6987, -0.3545, -1.1782,  1.5163,  0.6015, -0.8556,  0.5208],\n",
            "        [-0.4603, -0.9250,  0.8256, -0.3722,  0.7031,  1.6786, -0.7311, -0.7779],\n",
            "        [-2.0257,  2.4467, -0.6194, -1.0261,  0.9689, -0.4816, -1.3385,  1.0794],\n",
            "        [-1.0321, -0.5317, -0.0580, -1.4823,  1.7038,  1.1979, -1.1503,  0.9883],\n",
            "        [-1.1959,  2.8975, -1.4450, -1.3183,  1.9087, -0.3654, -1.9621,  0.3966],\n",
            "        [-0.8304, -1.0019, -0.0356, -1.9996,  5.0873, -0.0387, -0.2568, -0.9901],\n",
            "        [-2.1788,  3.0518, -2.6860, -2.4923,  3.3676, -0.6863, -1.8614,  1.4147],\n",
            "        [-0.9252, -0.2546, -0.8611, -0.6204,  1.9102,  0.1634, -0.8281,  1.1320],\n",
            "        [-0.6115,  1.3255, -0.5433, -1.1904,  1.2261,  0.1897, -1.4365,  0.4240],\n",
            "        [-1.2297,  0.3364, -0.3001, -1.1658,  1.9506,  0.4236, -0.5093,  0.1085],\n",
            "        [ 0.0903, -1.1084,  0.9044, -1.1352,  1.0620,  0.9438, -0.6970,  0.0471],\n",
            "        [-2.3017, -0.0652, -1.3950, -1.8530,  3.9274, -0.2082, -0.3997,  1.1782],\n",
            "        [-2.0904,  3.8731, -1.8644, -1.7000,  1.9589, -0.5948, -1.6885,  0.7243],\n",
            "        [-0.8566,  0.2497, -1.0887, -1.3357,  2.5528,  0.6031, -0.6988,  0.0491],\n",
            "        [ 0.4882, -0.0149,  0.7246, -0.7970,  0.3390,  1.1234, -0.4535, -1.1042],\n",
            "        [-0.9255, -0.5939,  0.3698, -0.8751,  1.3732,  1.2684, -0.4507,  0.0766],\n",
            "        [-1.0661, -1.3310,  0.1587, -1.9900,  5.8675,  0.1809, -0.7817, -1.2769],\n",
            "        [-1.6831, -0.7787, -0.4227, -1.3942,  2.2228,  0.6342, -1.1649,  1.8173],\n",
            "        [-1.1257, -0.9326,  1.5353, -0.9974, -0.1703,  2.6648, -0.5959, -0.3051],\n",
            "        [-1.8297, -0.0223, -1.3147, -2.4112,  5.1131,  0.2853, -0.7161, -0.2282],\n",
            "        [-1.5413,  3.6696, -1.7361, -1.5948,  1.9588, -0.7833, -1.8294,  0.4699],\n",
            "        [-1.3743, -0.0975, -0.6480, -1.2030,  2.1380,  0.1485, -0.7239,  0.8717],\n",
            "        [-0.4943, -0.9492,  0.5936, -1.4469,  1.4910,  0.1935, -0.8903,  0.8948],\n",
            "        [-1.1319, -0.5600, -0.9437, -1.6204,  2.2436, -0.5365, -0.7626,  2.5063],\n",
            "        [-1.1563, -0.6855,  0.6338, -1.4700,  1.8053,  0.3906, -0.6173,  0.7088],\n",
            "        [-2.1111,  0.5380, -0.6949, -1.3570,  2.4110, -0.1948, -0.7253,  0.8843],\n",
            "        [-2.7371,  3.4975, -2.8784, -2.4608,  1.8901, -0.8073, -2.6109,  3.6764]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0130, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.5724,  1.7519, -1.8705, -0.9393,  1.2622, -1.2307, -1.5901,  2.7033],\n",
            "        [-2.3088, -0.0464, -1.0801, -0.8982,  3.0874,  0.1329, -0.8908,  1.1502],\n",
            "        [-1.8905,  0.1095, -1.6053, -1.7371,  2.8303, -0.2648, -1.1856,  2.6829],\n",
            "        [-2.2713,  6.9018, -2.4047, -2.4407,  1.0653, -1.6017, -2.5574,  0.3024],\n",
            "        [-1.3437,  0.1492, -1.3054, -2.3426,  3.4736,  0.1388, -1.0098,  1.0906],\n",
            "        [-1.8669,  4.7533, -1.8145, -0.9794,  0.6307, -0.9333, -2.2363,  0.3112],\n",
            "        [-0.9876, -0.4107,  0.1761, -0.8281,  1.5937,  0.6467, -0.4290, -0.0559],\n",
            "        [-2.2211,  4.2154, -2.1517, -1.8567,  2.0126, -0.9826, -2.0193,  1.2732],\n",
            "        [-1.4360,  2.4600, -1.3058, -0.1028,  1.3456, -0.4325, -1.1597, -0.0714],\n",
            "        [-1.0100, -0.7998, -0.7030, -0.9479,  0.6859, -0.9501,  3.9712,  0.0906],\n",
            "        [-1.7510,  0.8705, -2.1864, -2.7125,  3.6666, -0.5779, -1.4927,  1.9348],\n",
            "        [-0.5475, -0.1198,  0.0627, -1.6402,  1.8204,  0.4073, -1.1827,  0.4367],\n",
            "        [-2.2472,  2.9174, -2.3584, -2.3585,  2.8594, -0.9807, -1.9741,  2.0391],\n",
            "        [-1.8762,  4.6501, -2.0821, -1.9735,  1.3751, -1.1197, -2.4483,  1.2392],\n",
            "        [-1.6539,  0.4775, -1.5768, -2.5872,  4.1438,  0.3724, -0.9702,  0.1457],\n",
            "        [-1.5943, -0.5198, -0.5877, -1.8521,  4.8745,  0.4546, -0.9535, -1.0155],\n",
            "        [-1.8503,  3.8501, -1.0248, -2.0813,  1.1341, -0.7867, -1.8462,  0.4806],\n",
            "        [-1.7399,  1.2646, -1.4178, -1.8114,  3.0997,  0.0238, -1.2722,  0.3749],\n",
            "        [ 0.2238,  1.8749, -1.5910, -0.4620,  0.7622, -0.3706, -1.8280,  0.3800],\n",
            "        [-1.5030, -0.4618, -0.2236, -1.1867,  2.0528,  0.5640, -0.5949,  0.7327],\n",
            "        [-0.8849, -0.6313,  1.0146, -0.8895,  1.0755,  1.4512, -0.5757, -0.3653],\n",
            "        [-1.1488,  2.0353, -1.0829, -1.2581,  1.0978, -0.0515, -1.7802,  1.1317],\n",
            "        [-1.9945, -0.1087,  0.2712, -1.6658,  0.3800,  5.2361, -1.5770, -0.2528],\n",
            "        [-0.3724, -0.6442,  1.4404, -0.8980, -0.2802,  2.4134, -0.5469, -0.8476],\n",
            "        [-1.4472, -0.4338, -0.9066, -1.1977,  0.1519, -0.8875, -1.5462,  5.3856],\n",
            "        [-0.8872,  0.9779, -0.2828, -1.4372,  1.1680, -0.0847, -0.2969,  0.1881],\n",
            "        [-1.3065,  0.4172, -0.8525, -1.0265,  1.9102,  0.2980, -0.8513,  0.3869],\n",
            "        [-2.3039,  2.4210, -1.4971,  0.7635,  1.1045, -1.0005, -0.7933,  0.7476],\n",
            "        [-0.1808, -0.6637,  0.3189, -1.0268,  1.7705,  1.1953, -0.7955, -0.3056],\n",
            "        [-1.0826,  1.7822, -1.8066, -1.9331,  2.1375,  0.0726, -1.7598,  0.7853],\n",
            "        [-1.6808,  6.9976, -1.7370, -1.4229, -0.8686, -1.2341, -1.7101,  0.2196],\n",
            "        [-1.3773, -0.3626, -0.5130, -0.8822,  2.4111,  0.0162, -0.7523,  0.6497]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.1063, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6623e-01, -1.0467e+00,  5.8976e-01, -5.7140e-01,  1.2883e+00,\n",
            "          1.5642e+00, -8.3904e-01, -1.9812e-01],\n",
            "        [-2.1326e+00,  6.5995e-01, -2.0676e+00, -2.9794e+00,  3.7328e+00,\n",
            "         -3.1060e-01, -1.1551e+00,  2.0788e+00],\n",
            "        [-2.2357e-02, -3.0543e-01,  6.2698e-01, -1.4121e-01,  6.2249e-01,\n",
            "          1.3971e+00, -6.1328e-01, -7.1073e-01],\n",
            "        [ 1.2673e+00, -7.5237e-01,  6.9350e-01, -1.3267e+00,  3.7726e-01,\n",
            "          1.8243e+00, -9.3280e-01, -1.0037e+00],\n",
            "        [-1.3484e+00,  7.8548e-01, -8.6584e-01, -1.5846e+00,  2.0810e+00,\n",
            "          8.4131e-01, -1.4457e+00,  9.3068e-01],\n",
            "        [-5.7292e-01, -1.0430e+00,  7.4030e-01, -9.2386e-01,  1.1043e+00,\n",
            "          1.4479e+00, -5.7657e-01, -3.5335e-01],\n",
            "        [-1.9678e+00,  5.8954e-02, -1.7789e+00, -1.7781e+00,  3.1681e+00,\n",
            "         -4.7773e-01, -1.4755e+00,  3.2676e+00],\n",
            "        [-2.0253e+00,  1.3648e+00, -1.9378e+00, -2.4323e+00,  3.2192e+00,\n",
            "         -5.0152e-01, -1.6433e+00,  2.1934e+00],\n",
            "        [-1.0767e+00,  1.8626e-02,  1.4378e-01, -9.1823e-01,  1.3027e+00,\n",
            "          7.8099e-01, -9.2710e-01,  3.5854e-01],\n",
            "        [-1.2202e+00,  4.6147e-01,  2.1660e-01, -1.9704e+00,  1.3195e+00,\n",
            "         -6.3938e-02, -1.0444e+00,  1.2990e+00],\n",
            "        [-3.6033e-02, -6.5838e-01,  7.2842e-01, -6.7462e-01,  1.0177e+00,\n",
            "          7.3134e-01, -2.3429e-01, -6.3517e-01],\n",
            "        [-1.0943e+00, -1.4827e+00,  1.5803e-01, -2.1053e+00,  5.7513e+00,\n",
            "          3.4792e-01, -6.2471e-01, -1.3714e+00],\n",
            "        [-1.3798e+00, -4.9807e-01, -1.7212e-01,  2.7458e+00,  2.0203e-01,\n",
            "          6.0984e-01, -5.5282e-01, -7.7228e-01],\n",
            "        [-2.2839e+00,  1.6332e+00, -2.2388e+00, -2.2704e+00,  3.5706e+00,\n",
            "         -6.8569e-01, -1.5581e+00,  1.8777e+00],\n",
            "        [-2.3269e+00, -3.5102e-01, -5.1493e-01, -6.0896e-01,  2.4957e+00,\n",
            "          4.0807e-01, -4.6716e-01,  1.1577e+00],\n",
            "        [-1.1796e+00, -6.5900e-01,  2.7842e-01, -1.4354e+00,  1.2139e+00,\n",
            "          1.0082e+00, -8.7990e-01,  1.1901e+00],\n",
            "        [-2.0927e+00, -7.7478e-01,  5.5754e+00, -1.2676e+00, -1.3045e+00,\n",
            "         -2.9039e-01, -4.3952e-01, -2.0015e-01],\n",
            "        [-1.5124e+00, -5.7820e-01, -1.4063e+00, -5.2831e-01, -1.7328e-03,\n",
            "         -9.8130e-01, -1.0923e+00,  5.2039e+00],\n",
            "        [-1.7677e+00,  7.2480e-02, -6.6006e-01, -1.5452e+00,  2.3645e+00,\n",
            "         -1.0954e-02, -6.9300e-01,  1.4789e+00],\n",
            "        [-2.3105e+00,  1.2733e+00, -1.8349e+00, -1.6637e+00,  3.3152e+00,\n",
            "         -7.7415e-01, -1.0426e+00,  1.3045e+00],\n",
            "        [-2.4555e+00,  5.8847e+00, -2.3859e+00, -2.5129e+00,  1.7285e+00,\n",
            "         -1.3064e+00, -2.2701e+00,  2.0501e-01],\n",
            "        [-1.1455e+00, -6.6921e-01,  6.3750e-01, -7.1634e-01,  1.1573e+00,\n",
            "          1.4241e+00, -3.5808e-01, -3.3729e-01],\n",
            "        [-2.0425e+00,  1.7704e-01, -1.9243e+00, -2.2023e+00,  4.1294e+00,\n",
            "         -3.0321e-01, -5.5727e-01,  1.2028e+00],\n",
            "        [-9.5109e-01,  1.4659e-01, -4.2511e-01, -8.5481e-01,  1.6773e+00,\n",
            "          3.4136e-01, -6.9462e-01,  4.5711e-01],\n",
            "        [-1.1795e+00, -1.5196e+00,  1.9072e-01, -1.7376e+00,  5.7411e+00,\n",
            "         -1.2880e-01, -6.0581e-01, -1.4782e+00],\n",
            "        [-1.4952e+00,  2.8422e-01, -8.6582e-01, -7.0219e-01,  2.3881e+00,\n",
            "          8.1200e-02, -9.7841e-01,  6.5749e-01],\n",
            "        [-1.3206e+00,  1.6600e+00, -1.5348e+00, -2.6034e+00,  4.1157e+00,\n",
            "          7.3012e-01, -1.7383e+00, -9.4273e-01],\n",
            "        [ 5.9443e+00, -6.1673e-01, -1.2311e+00, -1.6023e+00, -5.2210e-01,\n",
            "         -8.6983e-01, -6.2359e-01, -9.9730e-01],\n",
            "        [-1.0103e+00,  2.5738e-01, -6.2331e-01, -1.4536e+00,  2.2334e+00,\n",
            "          1.4394e-01, -9.4102e-01,  6.8558e-01],\n",
            "        [-1.8742e+00,  3.4184e-01, -1.8866e+00, -2.1742e+00,  1.8278e+00,\n",
            "         -1.1148e+00, -1.8468e+00,  5.1657e+00],\n",
            "        [-1.9102e+00,  1.7204e-01,  3.5462e-02, -1.6022e+00,  1.4234e+00,\n",
            "          3.3398e-01, -8.2254e-01,  1.4853e+00],\n",
            "        [-1.5126e+00,  2.4655e-01, -2.2991e-01, -1.3544e+00,  1.7206e+00,\n",
            "          3.6727e-01, -6.7926e-01,  7.9030e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2465, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.0500e+00,  3.4694e-02, -4.9596e-02, -3.2058e-01,  1.0815e+00,\n",
            "          5.4328e-01, -5.6952e-01,  4.8223e-02],\n",
            "        [-9.7336e-01,  5.3023e-01, -8.1120e-01, -7.3890e-01,  1.4551e+00,\n",
            "          2.7957e-01, -9.9046e-01,  5.3874e-01],\n",
            "        [-6.7645e-01, -1.3885e+00,  1.1928e+00, -1.0291e+00,  9.3882e-01,\n",
            "          1.7756e+00, -6.7295e-01, -1.9273e-01],\n",
            "        [-3.3590e-01, -4.8321e-01,  3.7695e-02, -7.6817e-01,  1.1984e+00,\n",
            "          1.7541e+00, -1.0527e+00, -1.4719e-01],\n",
            "        [-2.9942e-01, -4.8260e-01,  1.0772e-01, -1.1733e+00,  1.6161e+00,\n",
            "          1.3684e+00, -9.5533e-01, -1.3394e-01],\n",
            "        [-1.1176e+00,  4.4255e+00, -2.4775e+00, -5.2197e-01,  8.6977e-01,\n",
            "         -6.8777e-01, -2.8921e+00,  4.6028e-01],\n",
            "        [-2.3475e+00,  8.7157e-01, -1.9219e+00, -1.8317e+00,  3.2368e+00,\n",
            "         -4.1328e-01, -1.2792e+00,  2.3945e+00],\n",
            "        [-1.7324e+00,  7.2226e-02, -1.3395e+00, -1.7093e+00,  2.9489e+00,\n",
            "         -8.5802e-02, -4.5751e-01,  1.2945e+00],\n",
            "        [-1.5160e+00,  2.9979e-01, -1.3762e+00, -1.8780e+00,  2.3792e+00,\n",
            "         -4.7015e-01, -1.0587e+00,  2.9648e+00],\n",
            "        [-1.9156e+00,  6.8071e+00, -1.9359e+00, -1.7940e+00, -4.1242e-01,\n",
            "         -1.7863e+00, -2.0097e+00,  8.0450e-01],\n",
            "        [-9.8012e-01, -3.1305e-02, -1.3463e-01, -4.8280e-01,  1.6665e+00,\n",
            "          3.8983e-01, -1.0956e-01, -2.3284e-01],\n",
            "        [-6.4835e-02,  5.7412e-01, -2.0619e-01,  3.3419e-02,  1.2100e-01,\n",
            "          6.3416e-01, -1.1984e+00, -1.7121e-01],\n",
            "        [-2.2291e+00,  4.0010e+00, -2.2990e+00, -1.3028e+00,  1.8144e+00,\n",
            "         -9.3461e-01, -2.1013e+00,  1.0650e+00],\n",
            "        [-2.4217e+00,  1.2313e+00, -2.1562e+00, -1.7230e+00,  2.1941e+00,\n",
            "         -1.3970e+00, -1.3035e+00,  3.6323e+00],\n",
            "        [-2.0614e+00, -1.5924e-01, -9.7706e-01, -1.1970e+00,  2.7020e+00,\n",
            "          2.1467e-01, -7.9355e-01,  1.5186e+00],\n",
            "        [-3.1628e-01, -1.6313e-01, -5.7920e-01, -1.8179e+00,  2.2617e+00,\n",
            "          2.0341e-03, -8.3620e-01,  5.8795e-01],\n",
            "        [-2.5564e-02,  2.7253e-02,  1.6924e-01, -1.6325e+00,  1.2812e+00,\n",
            "          1.2531e-01, -1.4038e+00,  1.1408e+00],\n",
            "        [-1.8393e+00, -9.1971e-03,  1.6243e-01, -1.3580e+00, -4.0384e-01,\n",
            "          6.7757e+00, -1.3081e+00, -7.6346e-01],\n",
            "        [-1.3806e+00, -1.2352e-02, -5.8862e-01, -1.1343e+00,  2.2918e+00,\n",
            "          2.3085e-01, -8.2617e-01,  9.2141e-01],\n",
            "        [-1.5418e+00, -1.3690e-01, -8.0864e-01, -1.4415e+00,  3.0643e+00,\n",
            "          1.1374e-01, -5.1633e-01,  5.8581e-01],\n",
            "        [-2.3924e+00,  2.5993e+00, -1.8332e+00, -1.7893e+00,  2.1738e+00,\n",
            "         -6.7387e-01, -1.5443e+00,  1.6011e+00],\n",
            "        [-1.0088e+00, -6.7462e-01,  1.1971e+00, -8.5624e-01,  9.5559e-01,\n",
            "          9.1496e-01, -6.5107e-02, -2.1483e-01],\n",
            "        [-5.3977e-01, -5.7416e-01,  3.6933e-01, -1.2221e+00,  9.0592e-01,\n",
            "          1.2332e+00, -9.3008e-01,  7.5284e-01],\n",
            "        [-1.9915e+00, -8.5217e-01,  5.0384e-01,  7.1596e-01,  3.9956e-01,\n",
            "          9.9579e-01,  6.2925e-01, -7.5273e-01],\n",
            "        [-9.0303e-01,  5.4982e-01, -7.3647e-01, -1.0676e+00,  1.4982e+00,\n",
            "          3.7218e-01, -7.8088e-01,  6.1041e-01],\n",
            "        [-1.0210e+00, -9.6944e-01,  1.1376e+00, -1.0435e-01,  4.1082e-01,\n",
            "          2.0841e+00,  7.3648e-03, -8.4583e-01],\n",
            "        [-2.2161e+00, -2.6963e-01, -1.2476e-01, -1.4385e+00,  6.5543e-01,\n",
            "          5.2828e+00, -1.4922e+00, -4.4380e-01],\n",
            "        [-1.9537e+00,  2.2824e+00, -1.1243e+00, -2.0091e+00,  1.8443e+00,\n",
            "         -5.2489e-01, -1.3114e+00,  1.5951e+00],\n",
            "        [-1.4964e+00,  4.7769e-01, -1.2747e+00, -1.1193e+00,  2.3217e+00,\n",
            "          1.6036e-01, -7.7332e-01,  5.5630e-01],\n",
            "        [-1.8039e+00,  9.1121e-01,  1.3250e+00, -1.1169e+00, -3.9237e-01,\n",
            "          2.5048e+00, -8.3142e-01, -5.3128e-01],\n",
            "        [-1.2432e+00, -7.7929e-01,  6.4743e-01, -1.2914e+00,  1.6967e+00,\n",
            "          7.2328e-01, -8.4003e-02,  5.9871e-01],\n",
            "        [-7.5354e-01, -5.5318e-01,  1.1523e+00, -2.6079e-01,  1.1260e-01,\n",
            "          1.1438e+00,  2.9579e-01, -8.1045e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.2680, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5707e+00,  4.3928e+00, -1.3561e+00, -1.4645e+00,  6.2459e-01,\n",
            "         -6.3049e-01, -1.7960e+00,  9.7108e-01],\n",
            "        [-2.3784e+00,  5.2728e-01, -1.7833e+00, -2.0844e+00,  3.5974e+00,\n",
            "         -2.2846e-01, -1.3723e+00,  2.0834e+00],\n",
            "        [-9.2210e-01, -8.1257e-01,  1.0538e+00, -7.4690e-01,  9.2260e-01,\n",
            "          6.6323e-01,  9.8794e-02,  2.0115e-02],\n",
            "        [-2.4563e+00,  4.1484e+00, -1.5799e+00, -1.6541e+00,  8.0867e-01,\n",
            "         -2.5247e-02, -2.3107e+00,  9.8121e-01],\n",
            "        [-1.1074e+00, -1.4446e-01,  3.1299e-01, -8.6308e-01,  1.6736e+00,\n",
            "          3.0955e-01, -3.5510e-01,  1.7943e-01],\n",
            "        [ 7.1547e-02,  6.4947e-02, -2.9693e-02, -7.1731e-01,  1.0015e+00,\n",
            "          1.0392e+00, -1.2186e+00, -2.1280e-01],\n",
            "        [-2.5831e+00,  1.3780e+00, -2.1249e+00, -2.0209e+00,  3.9381e+00,\n",
            "         -7.1107e-01, -6.6297e-01,  9.6979e-01],\n",
            "        [-1.8777e+00, -6.5701e-01,  4.6376e+00, -1.4060e+00, -1.0152e+00,\n",
            "          3.1085e-01, -3.3616e-01, -3.9857e-01],\n",
            "        [-1.8608e+00, -2.4478e-01, -1.4744e+00, -1.6480e+00,  3.1929e+00,\n",
            "         -2.2289e-01, -9.7313e-01,  1.6945e+00],\n",
            "        [-1.4615e+00,  5.3581e-01, -6.4372e-01, -4.4221e-01,  1.4820e+00,\n",
            "          3.7067e-01, -8.3239e-01,  6.4570e-01],\n",
            "        [-1.9537e+00, -3.1899e-04, -2.2047e+00, -1.7600e+00,  2.3173e+00,\n",
            "         -6.4991e-01, -1.3228e+00,  3.9963e+00],\n",
            "        [-7.5947e-01, -7.0569e-01,  1.4533e+00, -6.1108e-01,  5.3938e-01,\n",
            "          6.4201e-01, -2.6886e-02, -6.7598e-01],\n",
            "        [-9.3133e-01,  8.5103e-01, -1.6847e+00, -1.4447e+00,  1.8543e+00,\n",
            "         -6.5077e-01, -1.2837e+00,  2.2340e+00],\n",
            "        [-1.6106e+00,  2.6371e+00, -1.2846e+00, -1.5948e+00,  1.6746e+00,\n",
            "         -1.3718e-01, -1.4114e+00,  9.4647e-01],\n",
            "        [-1.5362e+00,  5.4291e-02, -1.5224e+00, -2.2887e+00,  3.3303e+00,\n",
            "          4.2356e-01, -9.9569e-01,  1.3382e+00],\n",
            "        [-7.5451e-01, -6.3099e-01,  4.0980e-01, -1.0054e+00,  1.1781e+00,\n",
            "          1.2768e+00, -4.6036e-01, -7.6365e-03],\n",
            "        [-2.2268e+00,  1.8678e+00, -2.3548e+00, -2.4108e+00,  3.4287e+00,\n",
            "         -5.8073e-01, -1.8498e+00,  2.0640e+00],\n",
            "        [-1.5690e+00, -3.2423e-02, -3.8492e-01,  2.1068e+00,  1.2038e+00,\n",
            "         -5.9429e-01, -4.2078e-01, -7.2525e-02],\n",
            "        [-1.6736e+00,  5.5800e-01, -1.1672e+00, -1.2682e+00,  2.3874e+00,\n",
            "         -2.5996e-02, -3.4863e-01,  6.8472e-01],\n",
            "        [-2.0805e+00,  3.3343e+00, -1.6381e+00, -1.3505e+00,  1.2371e+00,\n",
            "         -8.3601e-01, -1.5326e+00,  8.6181e-01],\n",
            "        [-1.6921e+00,  1.4347e-01,  7.0404e-01,  4.3340e-02,  5.2963e-01,\n",
            "          1.0530e+00,  1.4011e-02, -6.6061e-01],\n",
            "        [-1.9271e+00,  1.3267e-01, -9.9672e-01, -1.1021e+00,  2.4559e+00,\n",
            "         -1.5987e-01, -6.3822e-01,  1.0993e+00],\n",
            "        [-2.6038e+00,  4.2843e+00, -2.4711e+00, -1.4104e+00,  8.8201e-01,\n",
            "         -1.1165e+00, -8.3243e-01,  1.0844e+00],\n",
            "        [-2.6690e+00,  1.8405e+00, -1.7208e+00, -8.8384e-01,  2.1903e+00,\n",
            "         -3.7199e-01, -1.2097e+00,  1.0354e+00],\n",
            "        [-3.2128e-01,  8.1623e-02, -1.1985e+00, -1.7819e+00,  2.5328e+00,\n",
            "         -1.2837e-01, -1.2318e+00,  1.1056e+00],\n",
            "        [-1.7037e+00,  4.0520e+00, -1.5492e+00, -9.9996e-01,  5.4697e-01,\n",
            "         -5.6288e-01, -2.3305e+00,  7.0931e-01],\n",
            "        [-1.5266e+00, -2.8495e-01, -1.5708e+00, -8.8760e-01,  1.8062e-01,\n",
            "         -9.8562e-01, -1.5883e+00,  5.5233e+00],\n",
            "        [-1.4800e+00,  1.1704e+00, -9.6066e-01, -1.2823e+00,  1.7435e+00,\n",
            "          2.0156e-01, -1.2877e+00,  1.0302e+00],\n",
            "        [-9.3233e-01,  1.3718e-04, -1.0814e+00, -1.5796e+00,  2.2768e+00,\n",
            "          1.0864e+00, -9.5672e-01,  7.0794e-01],\n",
            "        [-1.7686e+00,  7.5863e-01, -1.6342e+00, -2.2668e+00,  3.2061e+00,\n",
            "          3.0399e-01, -1.3232e+00,  1.2750e+00],\n",
            "        [-1.4243e+00,  9.5071e-01, -1.5342e+00, -1.6531e+00,  2.6404e+00,\n",
            "          6.4043e-02, -1.4864e+00,  1.2063e+00],\n",
            "        [-2.8493e-01, -1.0251e+00,  1.3673e+00, -7.9259e-01,  3.4371e-01,\n",
            "          1.6177e+00, -2.0957e-01, -5.8686e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.4572, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.9093, -0.2639, -0.3852, -0.4769,  1.3557,  1.1911, -1.0605,  0.5177],\n",
            "        [-2.1680,  2.4803, -1.9537, -1.4631,  1.9831, -0.5510, -1.6600,  1.7713],\n",
            "        [-1.8713,  0.5381, -0.6926, -1.2012,  2.1472, -0.0382, -0.2037,  0.3847],\n",
            "        [-1.3090,  1.4044, -0.9101, -1.2976,  2.2469, -0.0456, -0.8219,  0.0356],\n",
            "        [-1.5790,  1.6765, -0.6436, -1.0476,  1.0919,  0.0243, -1.0270,  0.0293],\n",
            "        [-1.8975,  2.3252, -1.6302, -0.5974,  1.5234, -0.8499, -1.4464,  1.2947],\n",
            "        [-0.9499,  0.2958, -0.3814, -1.0564,  1.5426,  0.5437, -0.9332,  0.3459],\n",
            "        [-2.3010,  1.3676, -1.3023, -1.4054,  2.0239, -0.0159, -0.8717,  1.5256],\n",
            "        [ 6.3687, -0.5359, -1.1808, -0.6758, -1.0280, -1.0266, -1.0027, -1.1058],\n",
            "        [-1.9015,  2.5963, -0.5372, -1.4047,  0.3596,  0.3461, -1.0279,  0.5007],\n",
            "        [-2.2933,  5.0178, -2.0346, -1.4570,  1.1520, -1.1946, -2.5362,  0.5393],\n",
            "        [-1.1789,  0.2816, -1.0909, -1.2256,  2.0952,  0.1674, -1.0614,  1.1757],\n",
            "        [-1.2125, -1.1848,  1.7973, -0.7100,  0.1147,  1.6561,  0.1559, -0.3323],\n",
            "        [-1.7002,  0.1154, -1.1644, -1.8023,  3.1287,  0.1276, -0.3919,  0.8184],\n",
            "        [-1.1701, -0.9878,  1.5091, -0.2504,  0.1495,  2.5475, -0.0619, -0.7527],\n",
            "        [-2.6751, -0.0195, -1.5845,  6.1579, -0.0137, -1.1756, -0.3322, -0.3916],\n",
            "        [-1.4286, -1.0824,  0.7717,  0.2951,  0.8828,  1.3751, -0.1002, -0.5712],\n",
            "        [-0.5117, -0.8051,  0.9888, -0.6066,  0.6916,  1.4732, -0.5046, -0.2753],\n",
            "        [-0.3741, -0.7998,  0.4634, -0.6154,  1.2049,  0.8615, -0.5218, -0.1268],\n",
            "        [-1.4006,  0.0433, -0.5138, -0.8419,  1.7942,  0.1236, -0.8348,  0.6062],\n",
            "        [-1.7052, -0.6165, -1.2864, -1.6979,  2.3985, -0.2866, -0.9804,  3.2644],\n",
            "        [-1.4236, -0.0469, -0.2332, -0.7647,  2.1124,  0.0512, -0.4109,  0.2673],\n",
            "        [-1.2294,  1.1669, -1.0365, -0.1181,  1.2931,  0.3743, -1.0462,  0.4809],\n",
            "        [-1.8979, -0.1969, -0.0737, -0.9101,  1.9268,  0.6650, -0.2155,  0.6348],\n",
            "        [-0.8314,  0.5486, -0.8336, -1.9231,  1.9458, -0.5030, -1.5259,  1.9941],\n",
            "        [-1.4632,  0.3960, -1.1598, -1.3905,  2.7833, -0.1158, -1.0191,  0.9406],\n",
            "        [-1.7421,  0.9243, -0.8370, -1.5047,  1.5902, -0.0183, -0.8563,  1.2251],\n",
            "        [-0.6959, -0.0519,  0.5060, -1.1595,  1.1802,  0.0848, -1.0211,  0.2675],\n",
            "        [-1.4261,  0.2606, -0.6089, -0.4400,  2.1112, -0.2701, -0.8405,  0.6214],\n",
            "        [-1.5624,  0.0787, -1.1789, -1.8923,  2.4742,  0.5667, -1.1476,  1.4989],\n",
            "        [-1.7400, -0.9048, -0.6288, -1.8064,  5.8138, -0.4183, -1.0536, -0.7425],\n",
            "        [-1.8063,  0.3397, -1.7395, -2.2121,  3.4699, -0.0627, -1.3686,  1.8501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "SequenceClassifierOutput(loss=tensor(1.0202, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2928e+00, -2.6169e-01, -1.0095e+00, -1.2821e+00,  1.2901e+00,\n",
            "          2.6469e-01, -8.5780e-01,  2.2359e+00],\n",
            "        [-1.5994e+00, -4.8766e-01,  9.3050e-01, -8.5317e-01,  1.2052e+00,\n",
            "          1.0737e+00, -1.6589e-01, -2.2142e-01],\n",
            "        [-1.6651e+00,  3.8076e+00, -1.9228e+00, -9.5695e-01,  1.4358e+00,\n",
            "         -8.6785e-01, -2.1453e+00,  4.2606e-01],\n",
            "        [-9.8353e-01, -9.3187e-01,  6.3597e-01, -1.8291e-01,  8.0633e-01,\n",
            "          1.6668e+00, -1.7613e-01, -5.3006e-01],\n",
            "        [-8.8233e-01, -1.4476e+00, -6.3612e-02, -1.8621e+00,  6.2459e+00,\n",
            "         -1.7291e-02, -1.0432e+00, -1.0103e+00],\n",
            "        [-1.9903e+00,  6.1564e-02, -7.5336e-01, -1.3173e+00,  2.5934e+00,\n",
            "          4.0699e-01, -7.3467e-01,  7.7155e-01],\n",
            "        [-2.3706e+00, -5.4554e-01,  1.0156e-02, -1.0536e+00,  2.0677e-01,\n",
            "          6.7996e+00, -1.1081e+00, -7.4483e-01],\n",
            "        [-5.4018e-01, -5.6077e-01,  5.2116e-01, -4.2425e-01,  7.5838e-01,\n",
            "          1.3016e+00, -9.0203e-01, -2.8658e-01],\n",
            "        [-1.8989e+00,  1.0570e+00, -1.8210e+00, -2.2808e+00,  3.8972e+00,\n",
            "          5.1356e-01, -1.3262e+00,  4.3451e-01],\n",
            "        [-2.0127e+00,  6.9975e+00, -2.0513e+00, -1.7326e+00, -6.7605e-02,\n",
            "         -1.3306e+00, -2.0114e+00,  3.6870e-01],\n",
            "        [-1.8694e+00, -7.8399e-01,  1.3457e+00, -7.2986e-01,  2.7426e-01,\n",
            "          1.8486e+00,  1.1366e-01,  1.0612e-01],\n",
            "        [-6.9870e-01, -4.4201e-01,  1.0478e-01,  5.9725e-02,  1.2770e+00,\n",
            "          6.4222e-01, -5.6459e-01, -2.8116e-01],\n",
            "        [-1.0087e+00, -9.8084e-01,  6.7028e-01, -7.3902e-01,  1.1870e+00,\n",
            "          1.7371e+00, -4.5205e-01, -1.7503e-01],\n",
            "        [-1.8027e+00, -1.1675e+00,  5.2459e+00, -1.7245e+00, -3.8387e-01,\n",
            "          3.9133e-01, -1.5234e-01, -8.0998e-01],\n",
            "        [-1.1786e+00, -5.7443e-01,  1.4745e-01, -8.5155e-01,  1.7688e+00,\n",
            "          5.9765e-01, -4.2091e-01,  1.4410e-01],\n",
            "        [-1.6532e+00,  2.0440e+00, -1.9729e+00, -1.4277e+00,  2.3063e+00,\n",
            "         -4.2376e-01, -1.2931e+00,  1.0716e+00],\n",
            "        [-2.0207e+00,  4.7497e-01, -1.7347e+00, -2.1774e+00,  1.2311e+00,\n",
            "         -1.1732e+00, -1.6117e+00,  5.7497e+00],\n",
            "        [-1.1262e+00,  1.9544e-01, -6.2459e-01, -1.3468e+00,  1.9122e+00,\n",
            "          6.9553e-01, -2.8173e-01,  3.5620e-01],\n",
            "        [-2.0460e+00,  1.3546e+00, -2.1682e+00, -2.2669e+00,  3.8933e+00,\n",
            "          5.7032e-01, -1.4866e+00,  3.6969e-01],\n",
            "        [-2.1633e+00, -6.6979e-01, -1.4175e+00, -1.6256e+00,  7.8265e-01,\n",
            "         -5.6609e-01, -8.5663e-01,  5.1899e+00],\n",
            "        [-2.1846e+00,  1.6567e+00, -2.4261e+00, -2.2088e+00,  4.0822e+00,\n",
            "         -3.4732e-01, -1.5020e+00,  8.1791e-01],\n",
            "        [-8.9432e-01, -1.1261e+00,  1.7437e+00, -3.4201e-01, -1.7369e-01,\n",
            "          2.3911e+00,  9.0200e-02, -9.9829e-01],\n",
            "        [-1.2805e+00, -3.9406e-01, -1.0743e-01, -8.7157e-01,  2.0340e+00,\n",
            "          6.2142e-01, -6.5732e-01,  3.4665e-01],\n",
            "        [-1.6066e+00,  2.3907e+00, -1.5370e+00, -1.4650e+00,  1.9491e+00,\n",
            "         -1.9493e-01, -1.5536e+00,  7.4572e-01],\n",
            "        [-1.1602e+00,  1.9408e+00, -1.1661e+00, -5.7164e-01,  8.8422e-01,\n",
            "         -2.1152e-01, -1.5449e+00,  8.2521e-01],\n",
            "        [-1.7400e+00,  2.5524e-01, -7.7421e-01, -1.3528e+00,  2.4780e+00,\n",
            "         -2.8579e-03, -8.8254e-01,  7.5336e-01],\n",
            "        [-2.2210e+00, -3.3896e-01, -3.6300e-02, -1.2668e+00,  4.6535e-01,\n",
            "          6.6388e+00, -1.2418e+00, -8.6857e-01],\n",
            "        [-1.4265e+00,  7.1483e-01, -1.0736e+00, -1.9126e+00,  2.7349e+00,\n",
            "         -2.7960e-02, -1.1418e+00,  8.0700e-01],\n",
            "        [-1.0480e+00, -1.4144e+00,  1.7163e+00, -4.3691e-01,  1.2318e-01,\n",
            "          2.1813e+00, -1.1679e-03, -4.8232e-01],\n",
            "        [-1.9580e+00, -1.7828e-01, -3.2006e-01, -7.3798e-01,  2.2262e+00,\n",
            "          2.8251e-01, -1.7104e-01,  3.4541e-01],\n",
            "        [ 9.0965e-01, -8.5562e-01,  6.9631e-01, -4.8076e-01,  1.2165e-01,\n",
            "          1.5817e+00, -4.4358e-01, -8.9643e-01],\n",
            "        [-1.4993e+00, -7.3899e-01, -4.7254e-01, -2.1980e+00,  5.9029e+00,\n",
            "          2.5416e-01, -6.9239e-01, -1.0919e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[key].shape"
      ],
      "metadata": {
        "id": "BfKk3xYB291c",
        "outputId": "81abe686-1367-45db-b5d8-f4f1877b9933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "9DwVckOS4oPA",
        "outputId": "da81da70-6b06-46ab-efd3-80517e6af0a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果紀錄\n",
        "- Proprocessing + TFIDF(max=0.9, 3000, tette.tokenizer) + RF 0.36895\n",
        "- TFIDF(3000) + RF 0.35301\n",
        "- TFIDF(1100) + RF 0.34696\n",
        "\n",
        "- Word2Vec + RF\n",
        "  - Original Tokens : 0.32351\n",
        "  - Preprocessing : 0.34046\n",
        "  \n",
        "- TFIDF(1000) + NN : 0.35494\n"
      ],
      "metadata": {
        "id": "eZ7VY8clrlnr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6703ccbf4328454eb8da2a9fb495f7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_182ff35d4be24861add60dc153a5e93d",
              "IPY_MODEL_c96438e5b002451a80b94e6683edcdd0",
              "IPY_MODEL_3b3131efd76b4fd0ba83c8275f48d390"
            ],
            "layout": "IPY_MODEL_e95a7add77b54a8e97ffc1c86423505f"
          }
        },
        "182ff35d4be24861add60dc153a5e93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a00141c0c2341c3940f61f703b634e4",
            "placeholder": "​",
            "style": "IPY_MODEL_2d115e544a3946238202785edaa6784b",
            "value": "  0%"
          }
        },
        "c96438e5b002451a80b94e6683edcdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c1d3fa81c14b759fa11b21c8f376dc",
            "max": 4549,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da825e65ca9c424096affe8c10d1e01b",
            "value": 1
          }
        },
        "3b3131efd76b4fd0ba83c8275f48d390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5381c92b0caa4583b937fd1d3a1f4ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_d0f7b01ec4d442418560ea5132c0430e",
            "value": " 1/4549 [00:06&lt;1:35:33,  1.26s/it]"
          }
        },
        "e95a7add77b54a8e97ffc1c86423505f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a00141c0c2341c3940f61f703b634e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d115e544a3946238202785edaa6784b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78c1d3fa81c14b759fa11b21c8f376dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da825e65ca9c424096affe8c10d1e01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5381c92b0caa4583b937fd1d3a1f4ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f7b01ec4d442418560ea5132c0430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4eecfed84af49e8a30b36b6a2c0db3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ecc45e1bf364ee9bfb8d9843b8a60c0",
              "IPY_MODEL_c6790381cee24193a3d869f48214e408",
              "IPY_MODEL_d762dd1be6ff47cd8ca6b337aa86d5d4"
            ],
            "layout": "IPY_MODEL_d796d2053d2840618961e3255d61143e"
          }
        },
        "1ecc45e1bf364ee9bfb8d9843b8a60c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea18ed9a9ba946ccbeba9da73ba47da9",
            "placeholder": "​",
            "style": "IPY_MODEL_1a8acd02a9af4a06b1a265cd095c1cc1",
            "value": "Epoch 0:   0%"
          }
        },
        "c6790381cee24193a3d869f48214e408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7dbe13e6f994bfcb58838744620356e",
            "max": 9098,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20dc5b1088d547c59021203e13bbeedd",
            "value": 0
          }
        },
        "d762dd1be6ff47cd8ca6b337aa86d5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5ef46325d64e66a4ccc81bc2c1148a",
            "placeholder": "​",
            "style": "IPY_MODEL_6f1f4806474c47d890a16b874154ac18",
            "value": " 0/9098 [53:07&lt;?, ?it/s, Loss=1.28]"
          }
        },
        "d796d2053d2840618961e3255d61143e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea18ed9a9ba946ccbeba9da73ba47da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8acd02a9af4a06b1a265cd095c1cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7dbe13e6f994bfcb58838744620356e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20dc5b1088d547c59021203e13bbeedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f5ef46325d64e66a4ccc81bc2c1148a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f1f4806474c47d890a16b874154ac18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}